{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_svae.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wali137/Big-data-/blob/master/main_svae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJqKRjbEmmbs",
        "colab_type": "text"
      },
      "source": [
        "# Sequential Variational Autoencoders for Collaborative Filtering\n",
        "\n",
        "**Noveen Sachdeva, Giuseppe Manco, Ettore Ritacco, and Vikram Pudi** - *12th International ACM Conference on Web Search and Data Mining - WSDM '19*\n",
        "\n",
        "The notebook provides PyTorch code for the proposed model, \"SVAE\" along with the data preprocessing for the Movielens-1M dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9kpWxFqmmbt",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wX5D4Epgmmbu",
        "colab_type": "code",
        "outputId": "01ab60dd-032d-48be-fedc-82644fc013f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import random\n",
        "import functools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLFOG4C_mmby",
        "colab_type": "text"
      },
      "source": [
        "# Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzyTfRt2mmbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### change `DATA_DIR` to the location where the dataset sits\n",
        "### compatible datasets: ML-1M, Netflix-full\n",
        "\n",
        "hyper_params = {\n",
        "    'data_base': '/content/drive/My Drive/thesis/data/ml-20m/', # Don't remove the '/' at the end please :)\n",
        "    'project_name': 'svae_ml20m',\n",
        "    # 'data_base': 'saved_data/netflix-full/',\n",
        "    # 'project_name': 'svae_netflix_full',\n",
        "    'model_file_name': '',\n",
        "    'log_file': '',\n",
        "    'history_split_test': [0.8, 0.2], # Part of test history to train on : Part of test history to test\n",
        "\n",
        "    'learning_rate': 0.01, # learning rate is required only if optimizer is adagrad\n",
        "    'optimizer': 'adam',\n",
        "    'weight_decay': float(5e-3),\n",
        "\n",
        "    'epochs': 25,\n",
        "    'batch_size': 1, # Needs to be 1, because we don't pack multiple sequences in the same batch\n",
        "    \n",
        "    'item_embed_size': 256,\n",
        "    'rnn_size': 200,\n",
        "    'hidden_size': 150,\n",
        "    'latent_size': 64,\n",
        "    'loss_type': 'next_k', # [predict_next, same, prefix, postfix, exp_decay, next_k]\n",
        "    'next_k': 4,\n",
        "\n",
        "    'number_users_to_keep': 1000000000,\n",
        "    'batch_log_interval': 1000,\n",
        "    'train_cp_users': 200,\n",
        "    'exploding_clip': 0.25,\n",
        "}\n",
        "\n",
        "file_name = '_optimizer_' + str(hyper_params['optimizer'])\n",
        "if hyper_params['optimizer'] == 'adagrad':\n",
        "    file_name += '_lr_' + str(hyper_params['learning_rate'])\n",
        "file_name += '_weight_decay_' + str(hyper_params['weight_decay'])\n",
        "file_name += '_loss_type_' + str(hyper_params['loss_type'])\n",
        "file_name += '_item_embed_size_' + str(hyper_params['item_embed_size'])\n",
        "file_name += '_rnn_size_' + str(hyper_params['rnn_size'])\n",
        "file_name += '_latent_size_' + str(hyper_params['latent_size'])\n",
        "\n",
        "log_file_root = \"saved_logs/\" # Don't remove the '/' at the end please :)\n",
        "model_file_root = \"saved_models/\" # Don't remove the '/' at the end please :)\n",
        "\n",
        "if not os.path.isdir(log_file_root): os.mkdir(log_file_root)\n",
        "if not os.path.isdir(model_file_root): os.mkdir(model_file_root)\n",
        "hyper_params['log_file'] = log_file_root + hyper_params['project_name'] + '_log' + file_name + '.txt'\n",
        "hyper_params['model_file_name'] = model_file_root + hyper_params['project_name'] + '_model' + file_name + '.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Qg9rA8mmb3",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "**Courtesy:** Dawen Liang et al. \"*Variational autoencoders for collaborative filtering*\" published at WWW '18. <br>\n",
        "**Link:** https://github.com/dawenl/vae_cf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDVWvmhfmmb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = hyper_params['data_base']\n",
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg') # Path where preprocessed data will be saved\n",
        "hyper_params['data_base'] += 'pro_sg/'\n",
        "\n",
        "if not os.path.isdir(pro_dir): # We don't want to keep preprocessing every time we run the notebook\n",
        "    cols = ['userId', 'movieId', 'rating', 'timestamp']\n",
        "    dtypes = {'userId': 'int', 'movieId': 'int', 'timestamp': 'int', 'rating': 'int'}\n",
        "    #raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), names=cols, parse_dates=['timestamp'])\n",
        "    raw_data =pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), header=0)\n",
        "\n",
        "    max_seq_len = 1000\n",
        "    n_heldout_users = 10000 # If total users = N; train_users = N - 2*heldout; test_users & val_users = heldout\n",
        "\n",
        "    # binarize the data (only keep ratings >= 4)\n",
        "    raw_data = raw_data[raw_data['rating'] > 3.5]\n",
        "\n",
        "    # Remove users with greater than $max_seq_len number of watched movies\n",
        "    #raw_data = raw_data.groupby([\"userId\"]).filter(lambda x: len(x) <= max_seq_len)\n",
        "\n",
        "    # Sort data values with the timestamp\n",
        "    raw_data = raw_data.groupby([\"userId\"]).apply(lambda x: x.sort_values([\"timestamp\"], ascending = True)).reset_index(drop=True)\n",
        "\n",
        "    raw_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qA6fGtrmmb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
        "    count = playcount_groupbyid.size()\n",
        "    return count\n",
        "\n",
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'movieId')\n",
        "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
        "    \n",
        "    # Only keep the triplets for users who clicked on at least min_uc items\n",
        "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'userId')\n",
        "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
        "    \n",
        "    # Update both usercount and itemcount after filtering\n",
        "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
        "    return tp, usercount, itemcount\n",
        "\n",
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('userId')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
        "        n_items_u = len(group)\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            # idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "            idx[int((1.0 - test_prop) * n_items_u):] = True\n",
        "            # print(idx)\n",
        "            \n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(\"%d users sampled\" % i)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "    \n",
        "    return data_tr, data_te\n",
        "\n",
        "def numerize(tp):\n",
        "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
        "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
        "    ra = list(map(lambda x: x, tp['rating']))\n",
        "    ret =  pd.DataFrame(data={'uid': uid, 'sid': sid, 'rating': ra}, columns=['uid', 'sid', 'rating'])\n",
        "    ret['rating'] = ret['rating'].apply(pd.to_numeric)\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJXaHmzzmmb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir(pro_dir): # We don't want to keep preprocessing every time we run the notebook\n",
        "\n",
        "    raw_data, user_activity, item_popularity = filter_triplets(raw_data)\n",
        "\n",
        "    sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
        "\n",
        "    print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
        "          (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))\n",
        "\n",
        "    unique_uid = user_activity.index\n",
        "\n",
        "    np.random.seed(98765)\n",
        "    idx_perm = np.random.permutation(unique_uid.size)\n",
        "    unique_uid = unique_uid[idx_perm]\n",
        "\n",
        "    # create train/validation/test users\n",
        "    n_users = unique_uid.size\n",
        "\n",
        "    tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "    vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
        "    te_users = unique_uid[(n_users - n_heldout_users):]\n",
        "\n",
        "    train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]\n",
        "\n",
        "    unique_sid = pd.unique(train_plays['movieId'])\n",
        "\n",
        "    show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "    profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
        "\n",
        "    if not os.path.exists(pro_dir):\n",
        "        os.makedirs(pro_dir)\n",
        "\n",
        "    with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "        for sid in unique_sid:\n",
        "            f.write('%s\\n' % sid)\n",
        "\n",
        "    vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
        "    vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]\n",
        "\n",
        "    vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n",
        "\n",
        "    test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
        "    test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]\n",
        "\n",
        "    test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n",
        "\n",
        "    train_data = numerize(train_plays)\n",
        "    train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n",
        "\n",
        "    vad_data_tr = numerize(vad_plays_tr)\n",
        "    vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n",
        "\n",
        "    vad_data_te = numerize(vad_plays_te)\n",
        "    vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n",
        "\n",
        "    test_data_tr = numerize(test_plays_tr)\n",
        "    test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n",
        "\n",
        "    test_data_te = numerize(test_plays_te)\n",
        "    test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r587lk6AFPVX",
        "colab_type": "code",
        "outputId": "8cda25d2-a822-42c0-c7cf-b69c8bb09d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pro_dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/thesis/data/ml-20m/pro_sg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiBIjA4QmmcA",
        "colab_type": "text"
      },
      "source": [
        "# Utlity functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xCKdtzWCmmcB",
        "colab_type": "code",
        "outputId": "d791ec12-0612-44e4-8bb7-a2609ac381df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "LongTensor = torch.LongTensor\n",
        "FloatTensor = torch.FloatTensor\n",
        "\n",
        "is_cuda_available = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda_available: \n",
        "    print(\"Using CUDA...\\n\")\n",
        "    LongTensor = torch.cuda.LongTensor\n",
        "    FloatTensor = torch.cuda.FloatTensor\n",
        "    \n",
        "def save_obj(obj, name):\n",
        "    with open(name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def save_obj_json(obj, name):\n",
        "    with open(name + '.json', 'w') as f:\n",
        "        json.dump(obj, f)\n",
        "\n",
        "def load_obj(name):\n",
        "    with open(name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def load_obj_json(name):\n",
        "    with open(name + '.json', 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def file_write(log_file, s):\n",
        "    print(s)\n",
        "    f = open(log_file, 'a')\n",
        "    f.write(s+'\\n')\n",
        "    f.close()\n",
        "\n",
        "def clear_log_file(log_file):\n",
        "    f = open(log_file, 'w')\n",
        "    f.write('')\n",
        "    f.close()\n",
        "\n",
        "def pretty_print(h):\n",
        "    print(\"{\")\n",
        "    for key in h:\n",
        "        print(' ' * 4 + str(key) + ': ' + h[key])\n",
        "    print('}\\n')\n",
        "    \n",
        "def plot_len_vs_ndcg(len_to_ndcg_at_100_map):\n",
        "    \n",
        "    lens = list(len_to_ndcg_at_100_map.keys())\n",
        "    lens.sort()\n",
        "    X, Y = [], []\n",
        "    \n",
        "    for le in lens:\n",
        "        X.append(le)\n",
        "        ans = 0.0\n",
        "        for i in len_to_ndcg_at_100_map[le]: ans += float(i)\n",
        "        ans = ans / float(len(len_to_ndcg_at_100_map[le]))\n",
        "        Y.append(ans * 100.0)\n",
        "    \n",
        "    # Smoothening\n",
        "    Y_mine = []\n",
        "    prev_5 = []\n",
        "    for i in Y:\n",
        "        prev_5.append(i)\n",
        "        if len(prev_5) > 5: del prev_5[0]\n",
        "\n",
        "        temp = 0.0\n",
        "        for j in prev_5: temp += float(j)\n",
        "        temp = float(temp) / float(len(prev_5))\n",
        "        Y_mine.append(temp)\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(X, Y_mine, label='SVAE')\n",
        "    plt.xlabel(\"Number of items in the fold-out set\")\n",
        "    plt.ylabel(\"Average NDCG@100\")\n",
        "    plt.title(hyper_params['project_name'])\n",
        "    if not os.path.isdir(\"saved_plots/\"): os.mkdir(\"saved_plots/\")\n",
        "    plt.savefig(\"saved_plots/seq_len_vs_ndcg_\" + hyper_params['project_name'] + \".pdf\")\n",
        "\n",
        "    leg = plt.legend(loc='best', ncol=2)\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHAA6500mmcG",
        "colab_type": "text"
      },
      "source": [
        "# Data Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zlru6TY6mmcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(hyper_params):\n",
        "    \n",
        "    file_write(hyper_params['log_file'], \"Started reading data file\")\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'train.csv')\n",
        "    lines_train = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'validation_tr.csv')\n",
        "    lines_val_tr = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'validation_te.csv')\n",
        "    lines_val_te = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'test_tr.csv')\n",
        "    lines_test_tr = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'test_te.csv')\n",
        "    lines_test_te = f.readlines()[1:]\n",
        "    \n",
        "    unique_sid = list()\n",
        "    with open(hyper_params['data_base'] + 'unique_sid.txt', 'r') as f:\n",
        "        for line in f:\n",
        "            unique_sid.append(line.strip())\n",
        "    num_items = len(unique_sid)\n",
        "    \n",
        "    file_write(hyper_params['log_file'], \"Data Files loaded!\")\n",
        "\n",
        "    train_reader = DataReader(hyper_params, lines_train, None, num_items, True)\n",
        "    val_reader = DataReader(hyper_params, lines_val_tr, lines_val_te, num_items, False)\n",
        "    test_reader = DataReader(hyper_params, lines_test_tr, lines_test_te, num_items, False)\n",
        "\n",
        "    return train_reader, val_reader, test_reader, num_items\n",
        "\n",
        "class DataReader:\n",
        "    def __init__(self, hyper_params, a, b, num_items, is_training):\n",
        "        self.hyper_params = hyper_params\n",
        "        self.batch_size = hyper_params['batch_size']\n",
        "        \n",
        "        num_users = 0\n",
        "        min_user = 1000000000000000000000000 # Infinity\n",
        "        for line in a:\n",
        "            line = line.strip().split(\",\")\n",
        "            num_users = max(num_users, int(line[0]))\n",
        "            min_user = min(min_user, int(line[0]))\n",
        "        num_users = num_users - min_user + 1\n",
        "        \n",
        "        self.num_users = num_users\n",
        "        self.min_user = min_user\n",
        "        self.num_items = num_items\n",
        "        \n",
        "        self.data_train = a\n",
        "        self.data_test = b\n",
        "        self.is_training = is_training\n",
        "        self.all_users = []\n",
        "        \n",
        "        self.prep()\n",
        "        self.number()\n",
        "\n",
        "    def prep(self):\n",
        "        self.data = []\n",
        "        for i in range(self.num_users): self.data.append([])\n",
        "            \n",
        "        for i in tqdm(range(len(self.data_train))):\n",
        "            line = self.data_train[i]\n",
        "            line = line.strip().split(\",\")\n",
        "            self.data[int(line[0]) - self.min_user].append([ int(line[1]), 1 ])\n",
        "        \n",
        "        if self.is_training == False:\n",
        "            self.data_te = []\n",
        "            for i in range(self.num_users): self.data_te.append([])\n",
        "                \n",
        "            for i in tqdm(range(len(self.data_test))):\n",
        "                line = self.data_test[i]\n",
        "                line = line.strip().split(\",\")\n",
        "                self.data_te[int(line[0]) - self.min_user].append([ int(line[1]), 1 ])\n",
        "        \n",
        "    def number(self):\n",
        "        self.num_b = int(min(len(self.data), self.hyper_params['number_users_to_keep']) / self.batch_size)\n",
        "    \n",
        "    def iter(self):\n",
        "        users_done = 0\n",
        "\n",
        "        x_batch = []\n",
        "        \n",
        "        user_iterate_order = list(range(len(self.data)))\n",
        "        \n",
        "        # Randomly shuffle the training order\n",
        "        np.random.shuffle(user_iterate_order)\n",
        "        \n",
        "        for user in user_iterate_order:\n",
        "\n",
        "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
        "            users_done += 1\n",
        "            \n",
        "            y_batch_s = torch.zeros(self.batch_size, len(self.data[user]) - 1, self.num_items)\n",
        "            if is_cuda_available: y_batch_s = y_batch_s.cuda()\n",
        "            \n",
        "            if self.hyper_params['loss_type'] == 'predict_next':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in [ self.data[user][timestep + 1] ] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'next_k':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in self.data[user][timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'postfix':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in self.data[user][timestep + 1:] ]), 1.0\n",
        "                    )\n",
        "            \n",
        "            x_batch.append([ i[0] for i in self.data[user][:-1] ])\n",
        "            \n",
        "            if len(x_batch) == self.batch_size: # batch_size always = 1\n",
        "            \n",
        "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False)\n",
        "                x_batch = []\n",
        "\n",
        "    def iter_eval(self):\n",
        "\n",
        "        x_batch = []\n",
        "        test_movies, test_movies_r = [], []\n",
        "        \n",
        "        users_done = 0\n",
        "        \n",
        "        for user in range(len(self.data)):\n",
        "            \n",
        "            users_done += 1\n",
        "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
        "            \n",
        "            if self.is_training == True: \n",
        "                split = float(self.hyper_params['history_split_test'][0])\n",
        "                base_predictions_on = self.data[user][:int(split * len(self.data[user]))]\n",
        "                heldout_movies = self.data[user][int(split * len(self.data[user])):]\n",
        "            else:\n",
        "                base_predictions_on = self.data[user]\n",
        "                heldout_movies = self.data_te[user]\n",
        "            \n",
        "            y_batch_s = torch.zeros(self.batch_size, len(base_predictions_on) - 1, self.num_items).cuda()\n",
        "            \n",
        "            if self.hyper_params['loss_type'] == 'predict_next':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in [ base_predictions_on[timestep + 1] ] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'next_k':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in base_predictions_on[timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'postfix':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in base_predictions_on[timestep + 1:] ]), 1.0\n",
        "                    )\n",
        "            \n",
        "            test_movies.append([ i[0] for i in heldout_movies ])\n",
        "            test_movies_r.append([ i[1] for i in heldout_movies ])\n",
        "            x_batch.append([ i[0] for i in base_predictions_on[:-1] ])\n",
        "            \n",
        "            if len(x_batch) == self.batch_size: # batch_size always = 1\n",
        "                \n",
        "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False), test_movies, test_movies_r\n",
        "                x_batch = []\n",
        "                test_movies, test_movies_r = [], []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdQXFgZkmmcJ",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1xaWIHpUmmcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, criterion, reader, hyper_params, is_train_set):\n",
        "    model.eval()\n",
        "\n",
        "    metrics = {}\n",
        "    metrics['loss'] = 0.0\n",
        "    Ks = [10, 100]\n",
        "    for k in Ks: \n",
        "        metrics['NDCG@' + str(k)] = 0.0\n",
        "        metrics['Rec@' + str(k)] = 0.0\n",
        "        metrics['Prec@' + str(k)] = 0.0\n",
        "\n",
        "    batch = 0\n",
        "    total_users = 0.0\n",
        "    \n",
        "    # For plotting the results (seq length vs. NDCG@100)\n",
        "    len_to_ndcg_at_100_map = {}\n",
        "\n",
        "    for x, y_s, test_movies, test_movies_r in reader.iter_eval():\n",
        "        batch += 1\n",
        "        if is_train_set == True and batch > hyper_params['train_cp_users']: break\n",
        "\n",
        "        decoder_output, z_mean, z_log_sigma = model(x)\n",
        "        \n",
        "        metrics['loss'] += criterion(decoder_output, z_mean, z_log_sigma, y_s, 0.2).data\n",
        "        \n",
        "        # Making the logits of previous items in the sequence to be \"- infinity\"\n",
        "        decoder_output = decoder_output.data\n",
        "        x_scattered = torch.zeros(decoder_output.shape[0], decoder_output.shape[2])\n",
        "        if is_cuda_available: x_scattered = x_scattered.cuda()\n",
        "        x_scattered[0, :].scatter_(0, x[0].data, 1.0)\n",
        "        last_predictions = decoder_output[:, -1, :] - (torch.abs(decoder_output[:, -1, :] * x_scattered) * 100000000)\n",
        "        \n",
        "        for batch_num in range(last_predictions.shape[0]): # batch_num is ideally only 0, since batch_size is enforced to be always 1\n",
        "            predicted_scores = last_predictions[batch_num]\n",
        "            actual_movies_watched = test_movies[batch_num]\n",
        "            actual_movies_ratings = test_movies_r[batch_num]\n",
        "                    \n",
        "            # Calculate NDCG\n",
        "            _, argsorted = torch.sort(-1.0 * predicted_scores)\n",
        "            for k in Ks:\n",
        "                best, now_at, dcg, hits = 0.0, 0.0, 0.0, 0.0\n",
        "                \n",
        "                rec_list = list(argsorted[:k].cpu().numpy())\n",
        "                for m in range(len(actual_movies_watched)):\n",
        "                    movie = actual_movies_watched[m]\n",
        "                    now_at += 1.0\n",
        "                    if now_at <= k: best += 1.0 / float(np.log2(now_at + 1))\n",
        "                    \n",
        "                    if movie not in rec_list: continue\n",
        "                    hits += 1.0\n",
        "                    dcg += 1.0 / float(np.log2(float(rec_list.index(movie) + 2)))\n",
        "                \n",
        "                metrics['NDCG@' + str(k)] += float(dcg) / float(best)\n",
        "                metrics['Rec@' + str(k)] += float(hits) / float(len(actual_movies_watched))\n",
        "                metrics['Prec@' + str(k)] += float(hits) / float(k)\n",
        "                \n",
        "                # Only for plotting the graph (seq length vs. NDCG@100)\n",
        "                if k == 100:\n",
        "                    seq_len = int(len(actual_movies_watched)) + int(x[batch_num].shape[0]) + 1\n",
        "                    if seq_len not in len_to_ndcg_at_100_map: len_to_ndcg_at_100_map[seq_len] = []\n",
        "                    len_to_ndcg_at_100_map[seq_len].append(float(dcg) / float(best))\n",
        "                \n",
        "            total_users += 1.0\n",
        "    \n",
        "    metrics['loss'] = float(metrics['loss']) / float(batch)\n",
        "    metrics['loss'] = round(metrics['loss'], 4)\n",
        "    \n",
        "    for k in Ks:\n",
        "        metrics['NDCG@' + str(k)] = round((100.0 * metrics['NDCG@' + str(k)]) / float(total_users), 4)\n",
        "        metrics['Rec@' + str(k)] = round((100.0 * metrics['Rec@' + str(k)]) / float(total_users), 4)\n",
        "        metrics['Prec@' + str(k)] = round((100.0 * metrics['Prec@' + str(k)]) / float(total_users), 4)\n",
        "        \n",
        "    return metrics, len_to_ndcg_at_100_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi1zfbNlmmcM",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "XZyBby8ZmmcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(\n",
        "            hyper_params['rnn_size'], hyper_params['hidden_size']\n",
        "        )\n",
        "        nn.init.xavier_normal(self.linear1.weight)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(hyper_params['latent_size'], hyper_params['hidden_size'])\n",
        "        self.linear2 = nn.Linear(hyper_params['hidden_size'], hyper_params['total_items'])\n",
        "        nn.init.xavier_normal(self.linear1.weight)\n",
        "        nn.init.xavier_normal(self.linear2.weight)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(Model, self).__init__()\n",
        "        self.hyper_params = hyper_params\n",
        "        \n",
        "        self.encoder = Encoder(hyper_params)\n",
        "        self.decoder = Decoder(hyper_params)\n",
        "        \n",
        "        # Since we don't need padding, our vocabulary size = \"hyper_params['total_items']\" and not \"hyper_params['total_items'] + 1\"\n",
        "        self.item_embed = nn.Embedding(hyper_params['total_items'], hyper_params['item_embed_size'])\n",
        "        \n",
        "        self.gru = nn.GRU(\n",
        "            hyper_params['item_embed_size'], hyper_params['rnn_size'], \n",
        "            batch_first = True, num_layers = 1\n",
        "        )\n",
        "        \n",
        "        self.linear1 = nn.Linear(hyper_params['hidden_size'], 2 * hyper_params['latent_size'])\n",
        "        nn.init.xavier_normal(self.linear1.weight)\n",
        "        \n",
        "        self.tanh = nn.Tanh()\n",
        "        \n",
        "    def sample_latent(self, h_enc):\n",
        "        \"\"\"\n",
        "        Return the latent normal sample z ~ N(mu, sigma^2)\n",
        "        \"\"\"\n",
        "        temp_out = self.linear1(h_enc)\n",
        "        \n",
        "        mu = temp_out[:, :self.hyper_params['latent_size']]\n",
        "        log_sigma = temp_out[:, self.hyper_params['latent_size']:]\n",
        "        \n",
        "        sigma = torch.exp(log_sigma)\n",
        "        std_z = torch.from_numpy(np.random.normal(0, 1, size=sigma.size())).float()\n",
        "        if is_cuda_available: std_z = std_z.cuda()\n",
        "\n",
        "        self.z_mean = mu\n",
        "        self.z_log_sigma = log_sigma\n",
        "\n",
        "        return mu + sigma * Variable(std_z, requires_grad=False)  # Reparameterization trick\n",
        "\n",
        "    def forward(self, x):\n",
        "        in_shape = x.shape                                      # [bsz x seq_len] = [1 x seq_len]\n",
        "        x = x.view(-1)                                          # [seq_len]\n",
        "        \n",
        "        x = self.item_embed(x)                                  # [seq_len x embed_size]\n",
        "        x = x.view(in_shape[0], in_shape[1], -1)                # [1 x seq_len x embed_size]\n",
        "        \n",
        "        rnn_out, _ = self.gru(x)                                # [1 x seq_len x rnn_size]\n",
        "        rnn_out = rnn_out.view(in_shape[0] * in_shape[1], -1)   # [seq_len x rnn_size]\n",
        "        \n",
        "        enc_out = self.encoder(rnn_out)                         # [seq_len x hidden_size]\n",
        "        sampled_z = self.sample_latent(enc_out)                 # [seq_len x latent_size]\n",
        "        \n",
        "        dec_out = self.decoder(sampled_z)                       # [seq_len x total_items]\n",
        "        dec_out = dec_out.view(in_shape[0], in_shape[1], -1)    # [1 x seq_len x total_items]\n",
        "                              \n",
        "        return dec_out, self.z_mean, self.z_log_sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTvsVBGommcQ",
        "colab_type": "text"
      },
      "source": [
        "# Custom loss\n",
        "\n",
        "$$ Loss \\; = \\; \\sum_{u \\in U} Loss_u $$ <br>\n",
        "$$ Loss_u \\; = \\; \\beta * KL( \\, \\phi(z \\vert x) \\, \\Vert \\, {\\rm I\\!N(0, I)} \\, ) \\; - \\; log( \\, P_{\\phi}(g_{\\theta}(x)) \\, ) $$ <br>\n",
        "$ g_{\\theta}(.)$ is the encoder ; $P_{\\phi}(.)$ is the decoded distribution; $ \\beta $ is the anneal factor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UgDM56VSmmcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAELoss(torch.nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(VAELoss,self).__init__()\n",
        "        self.hyper_params = hyper_params\n",
        "\n",
        "    def forward(self, decoder_output, mu_q, logvar_q, y_true_s, anneal):\n",
        "        # Calculate KL Divergence loss\n",
        "        kld = torch.mean(torch.sum(0.5 * (-logvar_q + torch.exp(logvar_q) + mu_q**2 - 1), -1))\n",
        "    \n",
        "        # Calculate Likelihood\n",
        "        dec_shape = decoder_output.shape # [batch_size x seq_len x total_items] = [1 x seq_len x total_items]\n",
        "\n",
        "        decoder_output = F.log_softmax(decoder_output, -1)\n",
        "        num_ones = float(torch.sum(y_true_s[0, 0]))\n",
        "        \n",
        "        likelihood = torch.sum(\n",
        "            -1.0 * y_true_s.view(dec_shape[0] * dec_shape[1], -1) * \\\n",
        "            decoder_output.view(dec_shape[0] * dec_shape[1], -1)\n",
        "        ) / (float(self.hyper_params['batch_size']) * num_ones)\n",
        "        \n",
        "        final = (anneal * kld) + (likelihood)\n",
        "        \n",
        "        return final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVZGlcAkmmcS",
        "colab_type": "text"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "arQz2HnxmmcS",
        "colab_type": "code",
        "outputId": "92daa909-f7f6-4281-a2db-f2f2255984ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train(reader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    batch = 0\n",
        "    batch_limit = int(train_reader.num_b)\n",
        "    total_anneal_steps = 200000\n",
        "    anneal = 0.0\n",
        "    update_count = 0.0\n",
        "    anneal_cap = 0.2\n",
        "\n",
        "    for x, y_s in reader.iter():\n",
        "        batch += 1\n",
        "        \n",
        "        # Empty the gradients\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "        # Forward pass\n",
        "        decoder_output, z_mean, z_log_sigma = model(x)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss = criterion(decoder_output, z_mean, z_log_sigma, y_s, anneal)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.data\n",
        "        \n",
        "        # Anneal logic\n",
        "        if total_anneal_steps > 0:\n",
        "            anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "        else:\n",
        "            anneal = anneal_cap\n",
        "        update_count += 1.0\n",
        "        \n",
        "        # Logging mechanism\n",
        "        if (batch % hyper_params['batch_log_interval'] == 0 and batch > 0) or batch == batch_limit:\n",
        "            div = hyper_params['batch_log_interval']\n",
        "            if batch == batch_limit: div = (batch_limit % hyper_params['batch_log_interval']) - 1\n",
        "            if div <= 0: div = 1\n",
        "\n",
        "            cur_loss = (total_loss / div)\n",
        "            elapsed = time.time() - start_time\n",
        "            \n",
        "            ss = '| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:5.4f}'.format(\n",
        "                    epoch, batch, batch_limit, (elapsed * 1000) / div, cur_loss\n",
        "            )\n",
        "            \n",
        "            file_write(hyper_params['log_file'], ss)\n",
        "\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "# Train It..\n",
        "train_reader, val_reader, test_reader, total_items = load_data(hyper_params)\n",
        "hyper_params['total_items'] = total_items\n",
        "hyper_params['testing_batch_limit'] = test_reader.num_b\n",
        "\n",
        "file_write(hyper_params['log_file'], \"\\n\\nSimulation run on: \" + str(dt.datetime.now()) + \"\\n\\n\")\n",
        "file_write(hyper_params['log_file'], \"Data reading complete!\")\n",
        "file_write(hyper_params['log_file'], \"Number of train batches: {:4d}\".format(train_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Number of validation batches: {:4d}\".format(val_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Number of test batches: {:4d}\".format(test_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Total Items: \" + str(total_items) + \"\\n\")\n",
        "\n",
        "model = Model(hyper_params)\n",
        "if is_cuda_available: model.cuda()\n",
        "\n",
        "criterion = VAELoss(hyper_params)\n",
        "\n",
        "if hyper_params['optimizer'] == 'adagrad':\n",
        "    optimizer = torch.optim.Adagrad(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay'], lr = hyper_params['learning_rate']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'adadelta':\n",
        "    optimizer = torch.optim.Adadelta(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'adam':\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'rmsprop':\n",
        "    optimizer = torch.optim.RMSprop(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "\n",
        "file_write(hyper_params['log_file'], str(model))\n",
        "file_write(hyper_params['log_file'], \"\\nModel Built!\\nStarting Training...\\n\")\n",
        "\n",
        "best_val_ndcg = None\n",
        "\n",
        "try:\n",
        "    for epoch in range(1, hyper_params['epochs'] + 1):\n",
        "        epoch_start_time = time.time()\n",
        "        \n",
        "        train(train_reader)\n",
        "        \n",
        "        # Calulating the metrics on the train set\n",
        "        metrics, _ = evaluate(model, criterion, train_reader, hyper_params, True)\n",
        "        string = \"\"\n",
        "        for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "        string += ' (TRAIN)'\n",
        "    \n",
        "        # Calulating the metrics on the validation set\n",
        "        metrics, _ = evaluate(model, criterion, val_reader, hyper_params, False)\n",
        "        string2 = \"\"\n",
        "        for m in metrics: string2 += \" | \" + m + ' = ' + str(metrics[m])\n",
        "        string2 += ' (VAL)'\n",
        "\n",
        "        ss  = '-' * 89\n",
        "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
        "        ss += string\n",
        "        ss += '\\n'\n",
        "        ss += '-' * 89\n",
        "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
        "        ss += string2\n",
        "        ss += '\\n'\n",
        "        ss += '-' * 89\n",
        "        file_write(hyper_params['log_file'], ss)\n",
        "        \n",
        "        if not best_val_ndcg or metrics['NDCG@100'] >= best_val_ndcg:\n",
        "            with open(hyper_params['model_file_name'], 'wb') as f: torch.save(model, f)\n",
        "            best_val_ndcg = metrics['NDCG@100']\n",
        "\n",
        "except KeyboardInterrupt: print('Exiting from training early')\n",
        "\n",
        "# Plot Traning graph\n",
        "f = open(model.hyper_params['log_file'])\n",
        "lines = f.readlines()\n",
        "lines.reverse()\n",
        "\n",
        "train = []\n",
        "test = []\n",
        "\n",
        "for line in lines:\n",
        "    if line[:10] == 'Simulation' and len(train) > 1: break\n",
        "    elif line[:10] == 'Simulation' and len(train) <= 1: train, test = [], []\n",
        "        \n",
        "    if line[2:5] == 'end' and line[-5:-2] == 'VAL': test.append(line.strip().split(\"|\"))\n",
        "    elif line[2:5] == 'end' and line[-7:-2] == 'TRAIN': train.append(line.strip().split(\"|\"))\n",
        "\n",
        "train.reverse()\n",
        "test.reverse()\n",
        "\n",
        "train_ndcg = []\n",
        "test_ndcg = []\n",
        "test_loss, train_loss = [], []\n",
        "\n",
        "for i in train:\n",
        "    for metric in i:\n",
        "        if metric.split(\"=\")[0] == \" NDCG@100 \":\n",
        "            train_ndcg.append(float(metric.split('=')[1].split(' ')[1]))\n",
        "        if metric.split(\"=\")[0] == \" loss \":\n",
        "            train_loss.append(float(metric.split(\"=\")[1].split(' ')[1]))\n",
        "\n",
        "total, avg_runtime = 0.0, 0.0\n",
        "for i in test:\n",
        "    avg_runtime += float(i[2].split(\" \")[2][:-1])\n",
        "    total += 1.0\n",
        "    \n",
        "    for metric in i:\n",
        "        if metric.split(\"=\")[0] == \" NDCG@100 \":\n",
        "            test_ndcg.append(float(metric.split('=')[1].split(' ')[1]))\n",
        "        if metric.split(\"=\")[0] == \" loss \":\n",
        "            test_loss.append(float(metric.split(\"=\")[1].split(' ')[1]))\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
        "ax1.set_title(hyper_params[\"project_name\"],fontweight=\"bold\", size=20)\n",
        "ax1.plot(test_ndcg, 'b-')\n",
        "ax1.set_xlabel('Epochs', fontsize = 20.0)\n",
        "ax1.set_ylabel('NDCG@100', color='b', fontsize = 20.0)\n",
        "ax1.tick_params('y', colors='b')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(test_loss, 'r--')\n",
        "ax2.set_ylabel('Loss', color='r')\n",
        "ax2.tick_params('y', colors='r')\n",
        "\n",
        "fig.tight_layout()\n",
        "if not os.path.isdir(\"saved_plots/\"): os.mkdir(\"saved_plots/\")\n",
        "fig.savefig(\"saved_plots/learning_curve_\" + hyper_params[\"project_name\"] + \".pdf\")\n",
        "plt.show()\n",
        "\n",
        "# Checking metrics for the test set on best saved model\n",
        "with open(hyper_params['model_file_name'], 'rb') as f: model = torch.load(f)\n",
        "metrics, len_to_ndcg_at_100_map = evaluate(model, criterion, test_reader, hyper_params, False)\n",
        "\n",
        "# Plot sequence length vs NDCG@100 graph\n",
        "plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
        "\n",
        "string = \"\"\n",
        "for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "\n",
        "ss  = '=' * 89\n",
        "ss += '\\n| End of training'\n",
        "ss += string + \" (TEST)\"\n",
        "ss += '\\n'\n",
        "ss += '=' * 89\n",
        "file_write(hyper_params['log_file'], ss)\n",
        "print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started reading data file\n",
            "Data Files loaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8538846/8538846 [00:20<00:00, 422359.75it/s]\n",
            "100%|██████████| 581927/581927 [00:00<00:00, 686078.77it/s]\n",
            "100%|██████████| 150474/150474 [00:00<00:00, 645126.49it/s]\n",
            "100%|██████████| 571057/571057 [00:00<00:00, 618042.35it/s]\n",
            "100%|██████████| 147726/147726 [00:00<00:00, 578112.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Simulation run on: 2019-07-09 09:10:34.520258\n",
            "\n",
            "\n",
            "Data reading complete!\n",
            "Number of train batches: 116677\n",
            "Number of validation batches: 10000\n",
            "Number of test batches: 10000\n",
            "Total Items: 20108\n",
            "\n",
            "Model(\n",
            "  (encoder): Encoder(\n",
            "    (linear1): Linear(in_features=200, out_features=150, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (linear1): Linear(in_features=64, out_features=150, bias=True)\n",
            "    (linear2): Linear(in_features=150, out_features=20108, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (item_embed): Embedding(20108, 256)\n",
            "  (gru): GRU(256, 200, batch_first=True)\n",
            "  (linear1): Linear(in_features=150, out_features=128, bias=True)\n",
            "  (tanh): Tanh()\n",
            ")\n",
            "\n",
            "Model Built!\n",
            "Starting Training...\n",
            "\n",
            "| epoch   1 |  1000/116677 batches | ms/batch 12.12 | loss 507.8502\n",
            "| epoch   1 |  2000/116677 batches | ms/batch 12.21 | loss 502.5545\n",
            "| epoch   1 |  3000/116677 batches | ms/batch 12.49 | loss 509.0059\n",
            "| epoch   1 |  4000/116677 batches | ms/batch 13.23 | loss 559.9900\n",
            "| epoch   1 |  5000/116677 batches | ms/batch 13.49 | loss 555.4860\n",
            "| epoch   1 |  6000/116677 batches | ms/batch 12.47 | loss 496.1825\n",
            "| epoch   1 |  7000/116677 batches | ms/batch 13.09 | loss 522.7651\n",
            "| epoch   1 |  8000/116677 batches | ms/batch 12.55 | loss 492.5338\n",
            "| epoch   1 |  9000/116677 batches | ms/batch 13.20 | loss 530.7421\n",
            "| epoch   1 | 10000/116677 batches | ms/batch 13.09 | loss 517.8604\n",
            "| epoch   1 | 11000/116677 batches | ms/batch 12.36 | loss 464.1829\n",
            "| epoch   1 | 12000/116677 batches | ms/batch 12.80 | loss 505.1163\n",
            "| epoch   1 | 13000/116677 batches | ms/batch 13.09 | loss 525.0345\n",
            "| epoch   1 | 14000/116677 batches | ms/batch 12.43 | loss 468.4816\n",
            "| epoch   1 | 15000/116677 batches | ms/batch 12.95 | loss 497.7253\n",
            "| epoch   1 | 16000/116677 batches | ms/batch 12.77 | loss 500.8283\n",
            "| epoch   1 | 17000/116677 batches | ms/batch 12.66 | loss 496.2675\n",
            "| epoch   1 | 18000/116677 batches | ms/batch 12.14 | loss 464.2430\n",
            "| epoch   1 | 19000/116677 batches | ms/batch 12.42 | loss 476.1974\n",
            "| epoch   1 | 20000/116677 batches | ms/batch 12.67 | loss 491.4103\n",
            "| epoch   1 | 21000/116677 batches | ms/batch 12.58 | loss 490.5437\n",
            "| epoch   1 | 22000/116677 batches | ms/batch 12.53 | loss 482.7834\n",
            "| epoch   1 | 23000/116677 batches | ms/batch 12.48 | loss 486.7081\n",
            "| epoch   1 | 24000/116677 batches | ms/batch 12.17 | loss 449.6037\n",
            "| epoch   1 | 25000/116677 batches | ms/batch 12.58 | loss 489.8521\n",
            "| epoch   1 | 26000/116677 batches | ms/batch 12.62 | loss 491.5161\n",
            "| epoch   1 | 27000/116677 batches | ms/batch 12.56 | loss 485.9232\n",
            "| epoch   1 | 28000/116677 batches | ms/batch 12.20 | loss 456.3416\n",
            "| epoch   1 | 29000/116677 batches | ms/batch 12.98 | loss 506.8130\n",
            "| epoch   1 | 30000/116677 batches | ms/batch 12.83 | loss 503.0565\n",
            "| epoch   1 | 31000/116677 batches | ms/batch 12.46 | loss 476.0615\n",
            "| epoch   1 | 32000/116677 batches | ms/batch 12.41 | loss 475.8907\n",
            "| epoch   1 | 33000/116677 batches | ms/batch 12.30 | loss 460.8563\n",
            "| epoch   1 | 34000/116677 batches | ms/batch 12.10 | loss 452.1837\n",
            "| epoch   1 | 35000/116677 batches | ms/batch 12.96 | loss 510.9066\n",
            "| epoch   1 | 36000/116677 batches | ms/batch 12.15 | loss 459.5508\n",
            "| epoch   1 | 37000/116677 batches | ms/batch 12.70 | loss 491.0144\n",
            "| epoch   1 | 38000/116677 batches | ms/batch 12.96 | loss 514.7012\n",
            "| epoch   1 | 39000/116677 batches | ms/batch 11.75 | loss 423.5845\n",
            "| epoch   1 | 40000/116677 batches | ms/batch 12.85 | loss 491.6522\n",
            "| epoch   1 | 41000/116677 batches | ms/batch 12.29 | loss 466.7451\n",
            "| epoch   1 | 42000/116677 batches | ms/batch 12.16 | loss 450.8091\n",
            "| epoch   1 | 43000/116677 batches | ms/batch 12.78 | loss 479.8547\n",
            "| epoch   1 | 44000/116677 batches | ms/batch 12.27 | loss 465.4115\n",
            "| epoch   1 | 45000/116677 batches | ms/batch 12.59 | loss 485.4117\n",
            "| epoch   1 | 46000/116677 batches | ms/batch 12.32 | loss 460.8883\n",
            "| epoch   1 | 47000/116677 batches | ms/batch 12.16 | loss 446.1697\n",
            "| epoch   1 | 48000/116677 batches | ms/batch 12.51 | loss 467.6321\n",
            "| epoch   1 | 49000/116677 batches | ms/batch 13.00 | loss 508.8963\n",
            "| epoch   1 | 50000/116677 batches | ms/batch 12.70 | loss 487.0769\n",
            "| epoch   1 | 51000/116677 batches | ms/batch 12.59 | loss 479.8549\n",
            "| epoch   1 | 52000/116677 batches | ms/batch 12.98 | loss 500.0383\n",
            "| epoch   1 | 53000/116677 batches | ms/batch 12.39 | loss 471.4969\n",
            "| epoch   1 | 54000/116677 batches | ms/batch 12.53 | loss 482.1124\n",
            "| epoch   1 | 55000/116677 batches | ms/batch 12.72 | loss 490.7574\n",
            "| epoch   1 | 56000/116677 batches | ms/batch 12.74 | loss 498.6358\n",
            "| epoch   1 | 57000/116677 batches | ms/batch 12.36 | loss 472.0246\n",
            "| epoch   1 | 58000/116677 batches | ms/batch 12.46 | loss 479.3841\n",
            "| epoch   1 | 59000/116677 batches | ms/batch 12.54 | loss 478.2798\n",
            "| epoch   1 | 60000/116677 batches | ms/batch 12.78 | loss 500.1922\n",
            "| epoch   1 | 61000/116677 batches | ms/batch 12.27 | loss 465.4023\n",
            "| epoch   1 | 62000/116677 batches | ms/batch 12.33 | loss 469.5662\n",
            "| epoch   1 | 63000/116677 batches | ms/batch 12.19 | loss 459.0758\n",
            "| epoch   1 | 64000/116677 batches | ms/batch 12.12 | loss 457.3168\n",
            "| epoch   1 | 65000/116677 batches | ms/batch 12.48 | loss 470.6386\n",
            "| epoch   1 | 66000/116677 batches | ms/batch 12.59 | loss 489.2610\n",
            "| epoch   1 | 67000/116677 batches | ms/batch 12.27 | loss 459.4070\n",
            "| epoch   1 | 68000/116677 batches | ms/batch 12.33 | loss 473.3307\n",
            "| epoch   1 | 69000/116677 batches | ms/batch 12.62 | loss 491.5625\n",
            "| epoch   1 | 70000/116677 batches | ms/batch 12.71 | loss 495.1567\n",
            "| epoch   1 | 71000/116677 batches | ms/batch 12.31 | loss 461.3627\n",
            "| epoch   1 | 72000/116677 batches | ms/batch 12.27 | loss 462.8262\n",
            "| epoch   1 | 73000/116677 batches | ms/batch 12.96 | loss 510.6314\n",
            "| epoch   1 | 74000/116677 batches | ms/batch 12.31 | loss 460.4470\n",
            "| epoch   1 | 75000/116677 batches | ms/batch 12.51 | loss 486.9827\n",
            "| epoch   1 | 76000/116677 batches | ms/batch 11.99 | loss 446.4770\n",
            "| epoch   1 | 77000/116677 batches | ms/batch 12.42 | loss 476.7004\n",
            "| epoch   1 | 78000/116677 batches | ms/batch 12.44 | loss 477.9424\n",
            "| epoch   1 | 79000/116677 batches | ms/batch 11.89 | loss 438.0586\n",
            "| epoch   1 | 80000/116677 batches | ms/batch 12.72 | loss 492.0002\n",
            "| epoch   1 | 81000/116677 batches | ms/batch 12.19 | loss 457.0261\n",
            "| epoch   1 | 82000/116677 batches | ms/batch 12.23 | loss 465.4905\n",
            "| epoch   1 | 83000/116677 batches | ms/batch 12.28 | loss 465.7509\n",
            "| epoch   1 | 84000/116677 batches | ms/batch 12.67 | loss 485.5872\n",
            "| epoch   1 | 85000/116677 batches | ms/batch 12.11 | loss 452.6833\n",
            "| epoch   1 | 86000/116677 batches | ms/batch 12.48 | loss 480.5632\n",
            "| epoch   1 | 87000/116677 batches | ms/batch 12.35 | loss 470.7261\n",
            "| epoch   1 | 88000/116677 batches | ms/batch 12.16 | loss 460.5254\n",
            "| epoch   1 | 89000/116677 batches | ms/batch 12.32 | loss 467.6997\n",
            "| epoch   1 | 90000/116677 batches | ms/batch 12.91 | loss 502.2162\n",
            "| epoch   1 | 91000/116677 batches | ms/batch 13.04 | loss 520.4473\n",
            "| epoch   1 | 92000/116677 batches | ms/batch 12.10 | loss 455.0854\n",
            "| epoch   1 | 93000/116677 batches | ms/batch 12.69 | loss 493.1692\n",
            "| epoch   1 | 94000/116677 batches | ms/batch 12.32 | loss 468.0238\n",
            "| epoch   1 | 95000/116677 batches | ms/batch 12.53 | loss 476.5924\n",
            "| epoch   1 | 96000/116677 batches | ms/batch 12.95 | loss 489.2491\n",
            "| epoch   1 | 97000/116677 batches | ms/batch 12.26 | loss 451.5998\n",
            "| epoch   1 | 98000/116677 batches | ms/batch 13.45 | loss 508.8385\n",
            "| epoch   1 | 99000/116677 batches | ms/batch 13.20 | loss 504.2739\n",
            "| epoch   1 | 100000/116677 batches | ms/batch 12.05 | loss 443.6837\n",
            "| epoch   1 | 101000/116677 batches | ms/batch 12.86 | loss 504.9114\n",
            "| epoch   1 | 102000/116677 batches | ms/batch 12.46 | loss 469.5081\n",
            "| epoch   1 | 103000/116677 batches | ms/batch 13.41 | loss 529.2451\n",
            "| epoch   1 | 104000/116677 batches | ms/batch 12.85 | loss 490.6165\n",
            "| epoch   1 | 105000/116677 batches | ms/batch 12.59 | loss 471.2781\n",
            "| epoch   1 | 106000/116677 batches | ms/batch 12.25 | loss 437.1411\n",
            "| epoch   1 | 107000/116677 batches | ms/batch 12.62 | loss 469.3852\n",
            "| epoch   1 | 108000/116677 batches | ms/batch 12.79 | loss 479.5753\n",
            "| epoch   1 | 109000/116677 batches | ms/batch 13.00 | loss 510.2701\n",
            "| epoch   1 | 110000/116677 batches | ms/batch 13.13 | loss 513.8799\n",
            "| epoch   1 | 111000/116677 batches | ms/batch 12.64 | loss 480.9154\n",
            "| epoch   1 | 112000/116677 batches | ms/batch 13.20 | loss 511.5143\n",
            "| epoch   1 | 113000/116677 batches | ms/batch 13.58 | loss 543.5619\n",
            "| epoch   1 | 114000/116677 batches | ms/batch 12.77 | loss 474.2574\n",
            "| epoch   1 | 115000/116677 batches | ms/batch 12.94 | loss 494.8719\n",
            "| epoch   1 | 116000/116677 batches | ms/batch 12.33 | loss 451.8402\n",
            "| epoch   1 | 116677/116677 batches | ms/batch 11.77 | loss 413.3049\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 1541.18s | loss = 392.9115 | NDCG@10 = 13.0449 | Rec@10 = 13.1984 | Prec@10 = 9.9 | NDCG@100 = 25.193 | Rec@100 = 48.7954 | Prec@100 = 5.33 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 1541.18s | loss = 365.8605 | NDCG@10 = 14.6138 | Rec@10 = 13.0111 | Prec@10 = 10.789 | NDCG@100 = 26.3137 | Rec@100 = 48.019 | Prec@100 = 5.0823 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |  1000/116677 batches | ms/batch 12.94 | loss 488.9225\n",
            "| epoch   2 |  2000/116677 batches | ms/batch 12.82 | loss 463.5959\n",
            "| epoch   2 |  3000/116677 batches | ms/batch 12.19 | loss 435.7451\n",
            "| epoch   2 |  4000/116677 batches | ms/batch 12.44 | loss 460.2213\n",
            "| epoch   2 |  5000/116677 batches | ms/batch 12.49 | loss 467.7404\n",
            "| epoch   2 |  6000/116677 batches | ms/batch 11.66 | loss 414.7900\n",
            "| epoch   2 |  7000/116677 batches | ms/batch 12.17 | loss 451.0201\n",
            "| epoch   2 |  8000/116677 batches | ms/batch 12.40 | loss 467.3136\n",
            "| epoch   2 |  9000/116677 batches | ms/batch 12.94 | loss 502.2820\n",
            "| epoch   2 | 10000/116677 batches | ms/batch 11.59 | loss 403.5209\n",
            "| epoch   2 | 11000/116677 batches | ms/batch 12.24 | loss 462.7105\n",
            "| epoch   2 | 12000/116677 batches | ms/batch 12.17 | loss 455.3428\n",
            "| epoch   2 | 13000/116677 batches | ms/batch 12.28 | loss 459.6741\n",
            "| epoch   2 | 14000/116677 batches | ms/batch 12.77 | loss 498.5833\n",
            "| epoch   2 | 15000/116677 batches | ms/batch 12.77 | loss 484.9580\n",
            "| epoch   2 | 16000/116677 batches | ms/batch 12.51 | loss 468.3071\n",
            "| epoch   2 | 17000/116677 batches | ms/batch 12.29 | loss 454.8823\n",
            "| epoch   2 | 18000/116677 batches | ms/batch 12.78 | loss 495.1979\n",
            "| epoch   2 | 19000/116677 batches | ms/batch 12.52 | loss 475.6154\n",
            "| epoch   2 | 20000/116677 batches | ms/batch 12.33 | loss 462.0365\n",
            "| epoch   2 | 21000/116677 batches | ms/batch 12.17 | loss 451.0490\n",
            "| epoch   2 | 22000/116677 batches | ms/batch 13.33 | loss 534.5431\n",
            "| epoch   2 | 23000/116677 batches | ms/batch 12.39 | loss 468.5822\n",
            "| epoch   2 | 24000/116677 batches | ms/batch 11.99 | loss 443.0151\n",
            "| epoch   2 | 25000/116677 batches | ms/batch 12.61 | loss 488.3889\n",
            "| epoch   2 | 26000/116677 batches | ms/batch 12.34 | loss 459.5793\n",
            "| epoch   2 | 27000/116677 batches | ms/batch 11.93 | loss 440.9973\n",
            "| epoch   2 | 28000/116677 batches | ms/batch 12.71 | loss 487.5712\n",
            "| epoch   2 | 29000/116677 batches | ms/batch 12.39 | loss 471.2038\n",
            "| epoch   2 | 30000/116677 batches | ms/batch 12.13 | loss 458.6977\n",
            "| epoch   2 | 31000/116677 batches | ms/batch 13.02 | loss 515.9073\n",
            "| epoch   2 | 32000/116677 batches | ms/batch 12.56 | loss 485.7229\n",
            "| epoch   2 | 33000/116677 batches | ms/batch 12.26 | loss 459.6502\n",
            "| epoch   2 | 34000/116677 batches | ms/batch 12.27 | loss 455.5974\n",
            "| epoch   2 | 35000/116677 batches | ms/batch 12.59 | loss 482.2688\n",
            "| epoch   2 | 36000/116677 batches | ms/batch 12.65 | loss 484.8211\n",
            "| epoch   2 | 37000/116677 batches | ms/batch 12.54 | loss 481.6669\n",
            "| epoch   2 | 38000/116677 batches | ms/batch 12.23 | loss 463.7461\n",
            "| epoch   2 | 39000/116677 batches | ms/batch 12.25 | loss 466.0346\n",
            "| epoch   2 | 40000/116677 batches | ms/batch 12.56 | loss 477.8146\n",
            "| epoch   2 | 41000/116677 batches | ms/batch 12.17 | loss 436.1470\n",
            "| epoch   2 | 42000/116677 batches | ms/batch 12.72 | loss 494.7380\n",
            "| epoch   2 | 43000/116677 batches | ms/batch 12.14 | loss 455.5434\n",
            "| epoch   2 | 44000/116677 batches | ms/batch 12.51 | loss 483.4052\n",
            "| epoch   2 | 45000/116677 batches | ms/batch 12.14 | loss 452.6743\n",
            "| epoch   2 | 46000/116677 batches | ms/batch 12.99 | loss 519.4594\n",
            "| epoch   2 | 47000/116677 batches | ms/batch 12.54 | loss 478.3026\n",
            "| epoch   2 | 48000/116677 batches | ms/batch 12.69 | loss 499.5393\n",
            "| epoch   2 | 49000/116677 batches | ms/batch 12.22 | loss 463.2912\n",
            "| epoch   2 | 50000/116677 batches | ms/batch 12.72 | loss 491.4032\n",
            "| epoch   2 | 51000/116677 batches | ms/batch 11.90 | loss 439.1953\n",
            "| epoch   2 | 52000/116677 batches | ms/batch 12.32 | loss 467.9910\n",
            "| epoch   2 | 53000/116677 batches | ms/batch 12.12 | loss 452.7971\n",
            "| epoch   2 | 54000/116677 batches | ms/batch 12.95 | loss 515.8149\n",
            "| epoch   2 | 55000/116677 batches | ms/batch 12.46 | loss 477.4474\n",
            "| epoch   2 | 56000/116677 batches | ms/batch 12.26 | loss 467.1983\n",
            "| epoch   2 | 57000/116677 batches | ms/batch 12.35 | loss 468.5918\n",
            "| epoch   2 | 58000/116677 batches | ms/batch 12.49 | loss 482.1043\n",
            "| epoch   2 | 59000/116677 batches | ms/batch 12.65 | loss 486.8046\n",
            "| epoch   2 | 60000/116677 batches | ms/batch 11.90 | loss 434.2233\n",
            "| epoch   2 | 61000/116677 batches | ms/batch 11.98 | loss 443.4968\n",
            "| epoch   2 | 62000/116677 batches | ms/batch 12.58 | loss 486.4410\n",
            "| epoch   2 | 63000/116677 batches | ms/batch 12.19 | loss 461.2352\n",
            "| epoch   2 | 64000/116677 batches | ms/batch 12.15 | loss 461.6163\n",
            "| epoch   2 | 65000/116677 batches | ms/batch 12.28 | loss 461.8023\n",
            "| epoch   2 | 66000/116677 batches | ms/batch 11.90 | loss 431.0793\n",
            "| epoch   2 | 67000/116677 batches | ms/batch 12.48 | loss 468.6406\n",
            "| epoch   2 | 68000/116677 batches | ms/batch 12.78 | loss 499.6919\n",
            "| epoch   2 | 69000/116677 batches | ms/batch 12.51 | loss 476.3563\n",
            "| epoch   2 | 70000/116677 batches | ms/batch 12.67 | loss 485.4610\n",
            "| epoch   2 | 71000/116677 batches | ms/batch 12.30 | loss 462.9831\n",
            "| epoch   2 | 72000/116677 batches | ms/batch 11.92 | loss 433.6390\n",
            "| epoch   2 | 73000/116677 batches | ms/batch 12.04 | loss 445.8009\n",
            "| epoch   2 | 74000/116677 batches | ms/batch 12.32 | loss 461.8332\n",
            "| epoch   2 | 75000/116677 batches | ms/batch 12.47 | loss 478.5880\n",
            "| epoch   2 | 76000/116677 batches | ms/batch 11.59 | loss 418.8365\n",
            "| epoch   2 | 77000/116677 batches | ms/batch 11.98 | loss 448.7826\n",
            "| epoch   2 | 78000/116677 batches | ms/batch 12.08 | loss 449.9295\n",
            "| epoch   2 | 79000/116677 batches | ms/batch 12.02 | loss 440.9488\n",
            "| epoch   2 | 80000/116677 batches | ms/batch 13.11 | loss 519.3354\n",
            "| epoch   2 | 81000/116677 batches | ms/batch 12.52 | loss 482.9088\n",
            "| epoch   2 | 82000/116677 batches | ms/batch 12.41 | loss 468.0431\n",
            "| epoch   2 | 83000/116677 batches | ms/batch 12.34 | loss 460.8703\n",
            "| epoch   2 | 84000/116677 batches | ms/batch 11.91 | loss 423.8949\n",
            "| epoch   2 | 85000/116677 batches | ms/batch 12.66 | loss 477.3249\n",
            "| epoch   2 | 86000/116677 batches | ms/batch 13.87 | loss 556.9423\n",
            "| epoch   2 | 87000/116677 batches | ms/batch 12.47 | loss 465.5843\n",
            "| epoch   2 | 88000/116677 batches | ms/batch 12.80 | loss 495.6428\n",
            "| epoch   2 | 89000/116677 batches | ms/batch 12.47 | loss 465.3074\n",
            "| epoch   2 | 90000/116677 batches | ms/batch 12.21 | loss 451.5361\n",
            "| epoch   2 | 91000/116677 batches | ms/batch 12.53 | loss 465.5925\n",
            "| epoch   2 | 92000/116677 batches | ms/batch 12.57 | loss 472.0638\n",
            "| epoch   2 | 93000/116677 batches | ms/batch 12.92 | loss 494.4196\n",
            "| epoch   2 | 94000/116677 batches | ms/batch 12.18 | loss 451.1952\n",
            "| epoch   2 | 95000/116677 batches | ms/batch 12.84 | loss 492.1043\n",
            "| epoch   2 | 96000/116677 batches | ms/batch 11.96 | loss 432.1936\n",
            "| epoch   2 | 97000/116677 batches | ms/batch 12.40 | loss 466.9295\n",
            "| epoch   2 | 98000/116677 batches | ms/batch 13.20 | loss 516.3436\n",
            "| epoch   2 | 99000/116677 batches | ms/batch 12.62 | loss 479.5525\n",
            "| epoch   2 | 100000/116677 batches | ms/batch 12.57 | loss 474.3029\n",
            "| epoch   2 | 101000/116677 batches | ms/batch 13.14 | loss 517.1805\n",
            "| epoch   2 | 102000/116677 batches | ms/batch 13.11 | loss 519.1639\n",
            "| epoch   2 | 103000/116677 batches | ms/batch 12.32 | loss 456.2702\n",
            "| epoch   2 | 104000/116677 batches | ms/batch 12.55 | loss 475.2498\n",
            "| epoch   2 | 105000/116677 batches | ms/batch 12.68 | loss 479.4494\n",
            "| epoch   2 | 106000/116677 batches | ms/batch 12.68 | loss 483.3683\n",
            "| epoch   2 | 107000/116677 batches | ms/batch 12.42 | loss 473.0575\n",
            "| epoch   2 | 108000/116677 batches | ms/batch 12.50 | loss 464.8979\n",
            "| epoch   2 | 109000/116677 batches | ms/batch 12.85 | loss 500.1252\n",
            "| epoch   2 | 110000/116677 batches | ms/batch 13.07 | loss 517.6107\n",
            "| epoch   2 | 111000/116677 batches | ms/batch 12.63 | loss 483.0584\n",
            "| epoch   2 | 112000/116677 batches | ms/batch 12.52 | loss 463.0332\n",
            "| epoch   2 | 113000/116677 batches | ms/batch 12.34 | loss 450.8138\n",
            "| epoch   2 | 114000/116677 batches | ms/batch 12.49 | loss 465.0007\n",
            "| epoch   2 | 115000/116677 batches | ms/batch 12.86 | loss 506.5970\n",
            "| epoch   2 | 116000/116677 batches | ms/batch 12.56 | loss 466.8992\n",
            "| epoch   2 | 116677/116677 batches | ms/batch 12.60 | loss 479.0906\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 1527.10s | loss = 391.2623 | NDCG@10 = 16.637 | Rec@10 = 13.0286 | Prec@10 = 11.1 | NDCG@100 = 27.2859 | Rec@100 = 48.3997 | Prec@100 = 5.325 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 1527.10s | loss = 363.8175 | NDCG@10 = 14.6975 | Rec@10 = 13.0819 | Prec@10 = 10.833 | NDCG@100 = 26.264 | Rec@100 = 47.8333 | Prec@100 = 5.0351 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |  1000/116677 batches | ms/batch 12.28 | loss 452.0480\n",
            "| epoch   3 |  2000/116677 batches | ms/batch 12.85 | loss 492.2903\n",
            "| epoch   3 |  3000/116677 batches | ms/batch 12.87 | loss 488.5441\n",
            "| epoch   3 |  4000/116677 batches | ms/batch 11.94 | loss 430.9938\n",
            "| epoch   3 |  5000/116677 batches | ms/batch 12.31 | loss 461.3862\n",
            "| epoch   3 |  6000/116677 batches | ms/batch 13.43 | loss 538.6601\n",
            "| epoch   3 |  7000/116677 batches | ms/batch 12.83 | loss 456.1716\n",
            "| epoch   3 |  8000/116677 batches | ms/batch 12.03 | loss 434.8564\n",
            "| epoch   3 |  9000/116677 batches | ms/batch 12.39 | loss 459.3251\n",
            "| epoch   3 | 10000/116677 batches | ms/batch 12.61 | loss 479.4390\n",
            "| epoch   3 | 11000/116677 batches | ms/batch 11.83 | loss 426.4137\n",
            "| epoch   3 | 12000/116677 batches | ms/batch 13.28 | loss 531.6538\n",
            "| epoch   3 | 13000/116677 batches | ms/batch 12.55 | loss 480.9060\n",
            "| epoch   3 | 14000/116677 batches | ms/batch 12.89 | loss 498.7292\n",
            "| epoch   3 | 15000/116677 batches | ms/batch 12.72 | loss 486.0956\n",
            "| epoch   3 | 16000/116677 batches | ms/batch 11.70 | loss 422.1599\n",
            "| epoch   3 | 17000/116677 batches | ms/batch 12.30 | loss 461.0322\n",
            "| epoch   3 | 18000/116677 batches | ms/batch 13.38 | loss 528.7631\n",
            "| epoch   3 | 19000/116677 batches | ms/batch 12.09 | loss 442.7315\n",
            "| epoch   3 | 20000/116677 batches | ms/batch 12.31 | loss 462.4282\n",
            "| epoch   3 | 21000/116677 batches | ms/batch 12.88 | loss 504.1698\n",
            "| epoch   3 | 22000/116677 batches | ms/batch 12.68 | loss 485.0504\n",
            "| epoch   3 | 23000/116677 batches | ms/batch 12.31 | loss 464.9142\n",
            "| epoch   3 | 24000/116677 batches | ms/batch 12.18 | loss 453.7660\n",
            "| epoch   3 | 25000/116677 batches | ms/batch 12.14 | loss 450.0461\n",
            "| epoch   3 | 26000/116677 batches | ms/batch 12.52 | loss 481.2332\n",
            "| epoch   3 | 27000/116677 batches | ms/batch 12.34 | loss 465.4054\n",
            "| epoch   3 | 28000/116677 batches | ms/batch 12.53 | loss 475.9221\n",
            "| epoch   3 | 29000/116677 batches | ms/batch 11.74 | loss 418.9384\n",
            "| epoch   3 | 30000/116677 batches | ms/batch 12.30 | loss 464.2306\n",
            "| epoch   3 | 31000/116677 batches | ms/batch 12.15 | loss 452.7332\n",
            "| epoch   3 | 32000/116677 batches | ms/batch 12.31 | loss 463.8871\n",
            "| epoch   3 | 33000/116677 batches | ms/batch 12.09 | loss 447.3888\n",
            "| epoch   3 | 34000/116677 batches | ms/batch 12.23 | loss 450.7552\n",
            "| epoch   3 | 35000/116677 batches | ms/batch 12.20 | loss 462.4554\n",
            "| epoch   3 | 36000/116677 batches | ms/batch 13.13 | loss 529.2427\n",
            "| epoch   3 | 37000/116677 batches | ms/batch 12.95 | loss 515.7635\n",
            "| epoch   3 | 38000/116677 batches | ms/batch 12.41 | loss 470.2993\n",
            "| epoch   3 | 39000/116677 batches | ms/batch 12.59 | loss 484.8031\n",
            "| epoch   3 | 40000/116677 batches | ms/batch 12.83 | loss 499.8996\n",
            "| epoch   3 | 41000/116677 batches | ms/batch 12.98 | loss 507.3472\n",
            "| epoch   3 | 42000/116677 batches | ms/batch 12.08 | loss 447.4663\n",
            "| epoch   3 | 43000/116677 batches | ms/batch 12.38 | loss 451.7037\n",
            "| epoch   3 | 44000/116677 batches | ms/batch 11.96 | loss 429.7872\n",
            "| epoch   3 | 45000/116677 batches | ms/batch 12.20 | loss 459.3672\n",
            "| epoch   3 | 46000/116677 batches | ms/batch 12.14 | loss 453.6749\n",
            "| epoch   3 | 47000/116677 batches | ms/batch 12.27 | loss 461.4149\n",
            "| epoch   3 | 48000/116677 batches | ms/batch 12.47 | loss 476.6334\n",
            "| epoch   3 | 49000/116677 batches | ms/batch 12.03 | loss 444.2647\n",
            "| epoch   3 | 50000/116677 batches | ms/batch 12.12 | loss 451.1658\n",
            "| epoch   3 | 51000/116677 batches | ms/batch 12.39 | loss 471.3624\n",
            "| epoch   3 | 52000/116677 batches | ms/batch 12.00 | loss 439.3010\n",
            "| epoch   3 | 53000/116677 batches | ms/batch 11.81 | loss 429.1504\n",
            "| epoch   3 | 54000/116677 batches | ms/batch 12.37 | loss 463.6272\n",
            "| epoch   3 | 55000/116677 batches | ms/batch 11.79 | loss 424.8011\n",
            "| epoch   3 | 56000/116677 batches | ms/batch 12.18 | loss 455.3022\n",
            "| epoch   3 | 57000/116677 batches | ms/batch 12.67 | loss 499.9073\n",
            "| epoch   3 | 58000/116677 batches | ms/batch 12.36 | loss 470.6172\n",
            "| epoch   3 | 59000/116677 batches | ms/batch 12.73 | loss 492.9801\n",
            "| epoch   3 | 60000/116677 batches | ms/batch 12.01 | loss 441.9797\n",
            "| epoch   3 | 61000/116677 batches | ms/batch 12.52 | loss 482.8645\n",
            "| epoch   3 | 62000/116677 batches | ms/batch 12.51 | loss 483.9313\n",
            "| epoch   3 | 63000/116677 batches | ms/batch 12.84 | loss 509.1750\n",
            "| epoch   3 | 64000/116677 batches | ms/batch 12.31 | loss 468.4040\n",
            "| epoch   3 | 65000/116677 batches | ms/batch 12.37 | loss 473.4996\n",
            "| epoch   3 | 66000/116677 batches | ms/batch 12.33 | loss 472.7175\n",
            "| epoch   3 | 67000/116677 batches | ms/batch 12.20 | loss 452.6911\n",
            "| epoch   3 | 68000/116677 batches | ms/batch 12.40 | loss 466.1147\n",
            "| epoch   3 | 69000/116677 batches | ms/batch 12.96 | loss 503.4385\n",
            "| epoch   3 | 70000/116677 batches | ms/batch 12.45 | loss 475.3941\n",
            "| epoch   3 | 71000/116677 batches | ms/batch 13.04 | loss 520.2632\n",
            "| epoch   3 | 72000/116677 batches | ms/batch 11.95 | loss 441.5822\n",
            "| epoch   3 | 73000/116677 batches | ms/batch 11.93 | loss 437.7741\n",
            "| epoch   3 | 74000/116677 batches | ms/batch 12.79 | loss 501.5040\n",
            "| epoch   3 | 75000/116677 batches | ms/batch 12.24 | loss 465.5247\n",
            "| epoch   3 | 76000/116677 batches | ms/batch 12.20 | loss 464.6407\n",
            "| epoch   3 | 77000/116677 batches | ms/batch 13.24 | loss 526.4307\n",
            "| epoch   3 | 78000/116677 batches | ms/batch 12.73 | loss 498.2538\n",
            "| epoch   3 | 79000/116677 batches | ms/batch 11.87 | loss 437.3759\n",
            "| epoch   3 | 80000/116677 batches | ms/batch 12.35 | loss 467.9809\n",
            "| epoch   3 | 81000/116677 batches | ms/batch 12.15 | loss 458.3792\n",
            "| epoch   3 | 82000/116677 batches | ms/batch 12.55 | loss 483.8308\n",
            "| epoch   3 | 83000/116677 batches | ms/batch 11.95 | loss 438.3106\n",
            "| epoch   3 | 84000/116677 batches | ms/batch 12.42 | loss 468.3741\n",
            "| epoch   3 | 85000/116677 batches | ms/batch 12.76 | loss 498.1105\n",
            "| epoch   3 | 86000/116677 batches | ms/batch 12.61 | loss 484.5258\n",
            "| epoch   3 | 87000/116677 batches | ms/batch 12.48 | loss 472.5035\n",
            "| epoch   3 | 88000/116677 batches | ms/batch 12.49 | loss 479.9356\n",
            "| epoch   3 | 89000/116677 batches | ms/batch 12.09 | loss 452.0018\n",
            "| epoch   3 | 90000/116677 batches | ms/batch 12.35 | loss 475.5355\n",
            "| epoch   3 | 91000/116677 batches | ms/batch 12.41 | loss 473.6774\n",
            "| epoch   3 | 92000/116677 batches | ms/batch 11.67 | loss 424.8012\n",
            "| epoch   3 | 93000/116677 batches | ms/batch 12.31 | loss 459.8817\n",
            "| epoch   3 | 94000/116677 batches | ms/batch 12.16 | loss 451.2509\n",
            "| epoch   3 | 95000/116677 batches | ms/batch 13.32 | loss 542.1442\n",
            "| epoch   3 | 96000/116677 batches | ms/batch 11.83 | loss 433.7484\n",
            "| epoch   3 | 97000/116677 batches | ms/batch 12.11 | loss 453.8656\n",
            "| epoch   3 | 98000/116677 batches | ms/batch 12.70 | loss 498.3360\n",
            "| epoch   3 | 99000/116677 batches | ms/batch 12.17 | loss 448.6866\n",
            "| epoch   3 | 100000/116677 batches | ms/batch 12.39 | loss 469.3365\n",
            "| epoch   3 | 101000/116677 batches | ms/batch 12.36 | loss 467.4789\n",
            "| epoch   3 | 102000/116677 batches | ms/batch 12.35 | loss 469.5811\n",
            "| epoch   3 | 103000/116677 batches | ms/batch 12.36 | loss 471.1453\n",
            "| epoch   3 | 104000/116677 batches | ms/batch 12.82 | loss 501.4790\n",
            "| epoch   3 | 105000/116677 batches | ms/batch 12.69 | loss 492.7893\n",
            "| epoch   3 | 106000/116677 batches | ms/batch 12.05 | loss 446.3815\n",
            "| epoch   3 | 107000/116677 batches | ms/batch 12.05 | loss 446.3595\n",
            "| epoch   3 | 108000/116677 batches | ms/batch 12.44 | loss 469.6244\n",
            "| epoch   3 | 109000/116677 batches | ms/batch 12.12 | loss 457.5638\n",
            "| epoch   3 | 110000/116677 batches | ms/batch 11.96 | loss 440.8772\n",
            "| epoch   3 | 111000/116677 batches | ms/batch 12.98 | loss 518.5688\n",
            "| epoch   3 | 112000/116677 batches | ms/batch 11.98 | loss 436.4029\n",
            "| epoch   3 | 113000/116677 batches | ms/batch 12.61 | loss 489.0339\n",
            "| epoch   3 | 114000/116677 batches | ms/batch 11.89 | loss 435.1021\n",
            "| epoch   3 | 115000/116677 batches | ms/batch 12.69 | loss 493.1531\n",
            "| epoch   3 | 116000/116677 batches | ms/batch 12.93 | loss 514.5677\n",
            "| epoch   3 | 116677/116677 batches | ms/batch 11.64 | loss 420.9852\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 1518.99s | loss = 388.3876 | NDCG@10 = 16.2061 | Rec@10 = 14.5832 | Prec@10 = 11.65 | NDCG@100 = 27.2619 | Rec@100 = 49.578 | Prec@100 = 5.5 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 1518.99s | loss = 362.7611 | NDCG@10 = 14.567 | Rec@10 = 12.9267 | Prec@10 = 10.786 | NDCG@100 = 26.3725 | Rec@100 = 48.3732 | Prec@100 = 5.1087 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |  1000/116677 batches | ms/batch 12.52 | loss 472.1240\n",
            "| epoch   4 |  2000/116677 batches | ms/batch 12.35 | loss 461.7957\n",
            "| epoch   4 |  3000/116677 batches | ms/batch 12.16 | loss 444.6205\n",
            "| epoch   4 |  4000/116677 batches | ms/batch 12.33 | loss 463.2177\n",
            "| epoch   4 |  5000/116677 batches | ms/batch 12.53 | loss 473.5444\n",
            "| epoch   4 |  6000/116677 batches | ms/batch 12.77 | loss 495.2776\n",
            "| epoch   4 |  7000/116677 batches | ms/batch 11.90 | loss 431.0802\n",
            "| epoch   4 |  8000/116677 batches | ms/batch 12.82 | loss 496.2238\n",
            "| epoch   4 |  9000/116677 batches | ms/batch 12.50 | loss 474.2924\n",
            "| epoch   4 | 10000/116677 batches | ms/batch 12.84 | loss 494.3591\n",
            "| epoch   4 | 11000/116677 batches | ms/batch 12.49 | loss 476.0517\n",
            "| epoch   4 | 12000/116677 batches | ms/batch 12.85 | loss 504.3199\n",
            "| epoch   4 | 13000/116677 batches | ms/batch 12.52 | loss 480.3664\n",
            "| epoch   4 | 14000/116677 batches | ms/batch 12.07 | loss 447.9846\n",
            "| epoch   4 | 15000/116677 batches | ms/batch 12.28 | loss 460.3469\n",
            "| epoch   4 | 16000/116677 batches | ms/batch 12.17 | loss 450.3957\n",
            "| epoch   4 | 17000/116677 batches | ms/batch 12.34 | loss 465.4914\n",
            "| epoch   4 | 18000/116677 batches | ms/batch 12.47 | loss 472.2390\n",
            "| epoch   4 | 19000/116677 batches | ms/batch 12.07 | loss 449.5017\n",
            "| epoch   4 | 20000/116677 batches | ms/batch 12.15 | loss 458.5688\n",
            "| epoch   4 | 21000/116677 batches | ms/batch 12.46 | loss 465.9983\n",
            "| epoch   4 | 22000/116677 batches | ms/batch 12.68 | loss 482.1328\n",
            "| epoch   4 | 23000/116677 batches | ms/batch 12.43 | loss 474.6826\n",
            "| epoch   4 | 24000/116677 batches | ms/batch 12.43 | loss 463.0855\n",
            "| epoch   4 | 25000/116677 batches | ms/batch 12.42 | loss 467.3631\n",
            "| epoch   4 | 26000/116677 batches | ms/batch 12.72 | loss 486.8971\n",
            "| epoch   4 | 27000/116677 batches | ms/batch 11.84 | loss 426.8607\n",
            "| epoch   4 | 28000/116677 batches | ms/batch 12.44 | loss 471.5623\n",
            "| epoch   4 | 29000/116677 batches | ms/batch 12.67 | loss 484.8122\n",
            "| epoch   4 | 30000/116677 batches | ms/batch 11.98 | loss 442.2352\n",
            "| epoch   4 | 31000/116677 batches | ms/batch 12.22 | loss 462.7313\n",
            "| epoch   4 | 32000/116677 batches | ms/batch 12.19 | loss 454.8122\n",
            "| epoch   4 | 33000/116677 batches | ms/batch 12.34 | loss 469.9100\n",
            "| epoch   4 | 34000/116677 batches | ms/batch 12.71 | loss 494.3575\n",
            "| epoch   4 | 35000/116677 batches | ms/batch 12.01 | loss 432.2984\n",
            "| epoch   4 | 36000/116677 batches | ms/batch 12.02 | loss 443.1743\n",
            "| epoch   4 | 37000/116677 batches | ms/batch 12.37 | loss 465.6957\n",
            "| epoch   4 | 38000/116677 batches | ms/batch 11.75 | loss 426.0756\n",
            "| epoch   4 | 39000/116677 batches | ms/batch 12.40 | loss 474.9116\n",
            "| epoch   4 | 40000/116677 batches | ms/batch 11.89 | loss 433.7430\n",
            "| epoch   4 | 41000/116677 batches | ms/batch 12.47 | loss 484.2008\n",
            "| epoch   4 | 42000/116677 batches | ms/batch 12.42 | loss 463.5833\n",
            "| epoch   4 | 43000/116677 batches | ms/batch 12.56 | loss 486.4917\n",
            "| epoch   4 | 44000/116677 batches | ms/batch 12.14 | loss 454.6455\n",
            "| epoch   4 | 45000/116677 batches | ms/batch 12.23 | loss 456.6618\n",
            "| epoch   4 | 46000/116677 batches | ms/batch 12.84 | loss 491.0291\n",
            "| epoch   4 | 47000/116677 batches | ms/batch 12.25 | loss 462.0071\n",
            "| epoch   4 | 48000/116677 batches | ms/batch 11.98 | loss 438.5864\n",
            "| epoch   4 | 49000/116677 batches | ms/batch 12.26 | loss 460.8377\n",
            "| epoch   4 | 50000/116677 batches | ms/batch 12.91 | loss 510.0958\n",
            "| epoch   4 | 51000/116677 batches | ms/batch 12.17 | loss 456.6102\n",
            "| epoch   4 | 52000/116677 batches | ms/batch 12.50 | loss 482.2050\n",
            "| epoch   4 | 53000/116677 batches | ms/batch 12.27 | loss 465.8495\n",
            "| epoch   4 | 54000/116677 batches | ms/batch 12.04 | loss 446.6363\n",
            "| epoch   4 | 55000/116677 batches | ms/batch 12.00 | loss 441.3854\n",
            "| epoch   4 | 56000/116677 batches | ms/batch 12.10 | loss 455.5064\n",
            "| epoch   4 | 57000/116677 batches | ms/batch 12.27 | loss 460.5060\n",
            "| epoch   4 | 58000/116677 batches | ms/batch 13.58 | loss 564.6375\n",
            "| epoch   4 | 59000/116677 batches | ms/batch 12.55 | loss 480.4458\n",
            "| epoch   4 | 60000/116677 batches | ms/batch 12.52 | loss 475.5260\n",
            "| epoch   4 | 61000/116677 batches | ms/batch 12.59 | loss 477.7622\n",
            "| epoch   4 | 62000/116677 batches | ms/batch 12.95 | loss 507.6171\n",
            "| epoch   4 | 63000/116677 batches | ms/batch 12.09 | loss 452.1104\n",
            "| epoch   4 | 64000/116677 batches | ms/batch 12.60 | loss 486.7782\n",
            "| epoch   4 | 65000/116677 batches | ms/batch 12.19 | loss 457.6104\n",
            "| epoch   4 | 66000/116677 batches | ms/batch 12.47 | loss 470.1108\n",
            "| epoch   4 | 67000/116677 batches | ms/batch 11.79 | loss 424.9973\n",
            "| epoch   4 | 68000/116677 batches | ms/batch 12.16 | loss 450.5176\n",
            "| epoch   4 | 69000/116677 batches | ms/batch 12.29 | loss 463.1123\n",
            "| epoch   4 | 70000/116677 batches | ms/batch 12.28 | loss 459.2092\n",
            "| epoch   4 | 71000/116677 batches | ms/batch 12.77 | loss 485.4021\n",
            "| epoch   4 | 72000/116677 batches | ms/batch 12.88 | loss 480.5635\n",
            "| epoch   4 | 73000/116677 batches | ms/batch 11.96 | loss 439.5434\n",
            "| epoch   4 | 74000/116677 batches | ms/batch 12.14 | loss 448.3207\n",
            "| epoch   4 | 75000/116677 batches | ms/batch 12.92 | loss 505.7313\n",
            "| epoch   4 | 76000/116677 batches | ms/batch 12.43 | loss 475.2525\n",
            "| epoch   4 | 77000/116677 batches | ms/batch 12.65 | loss 497.2428\n",
            "| epoch   4 | 78000/116677 batches | ms/batch 11.96 | loss 438.8654\n",
            "| epoch   4 | 79000/116677 batches | ms/batch 12.50 | loss 482.5852\n",
            "| epoch   4 | 80000/116677 batches | ms/batch 12.68 | loss 492.7708\n",
            "| epoch   4 | 81000/116677 batches | ms/batch 12.05 | loss 441.8444\n",
            "| epoch   4 | 82000/116677 batches | ms/batch 11.90 | loss 441.7869\n",
            "| epoch   4 | 83000/116677 batches | ms/batch 12.27 | loss 464.6082\n",
            "| epoch   4 | 84000/116677 batches | ms/batch 13.06 | loss 516.3586\n",
            "| epoch   4 | 85000/116677 batches | ms/batch 13.13 | loss 521.7413\n",
            "| epoch   4 | 86000/116677 batches | ms/batch 12.95 | loss 515.9018\n",
            "| epoch   4 | 87000/116677 batches | ms/batch 12.41 | loss 467.7997\n",
            "| epoch   4 | 88000/116677 batches | ms/batch 12.33 | loss 465.2265\n",
            "| epoch   4 | 89000/116677 batches | ms/batch 11.83 | loss 431.5274\n",
            "| epoch   4 | 90000/116677 batches | ms/batch 12.84 | loss 506.6685\n",
            "| epoch   4 | 91000/116677 batches | ms/batch 12.45 | loss 473.4123\n",
            "| epoch   4 | 92000/116677 batches | ms/batch 12.36 | loss 470.8622\n",
            "| epoch   4 | 93000/116677 batches | ms/batch 12.21 | loss 459.2173\n",
            "| epoch   4 | 94000/116677 batches | ms/batch 12.69 | loss 493.2807\n",
            "| epoch   4 | 95000/116677 batches | ms/batch 12.08 | loss 448.4358\n",
            "| epoch   4 | 96000/116677 batches | ms/batch 12.18 | loss 451.0270\n",
            "| epoch   4 | 97000/116677 batches | ms/batch 12.55 | loss 481.4888\n",
            "| epoch   4 | 98000/116677 batches | ms/batch 12.44 | loss 478.2336\n",
            "| epoch   4 | 99000/116677 batches | ms/batch 12.26 | loss 461.9046\n",
            "| epoch   4 | 100000/116677 batches | ms/batch 12.18 | loss 450.3827\n",
            "| epoch   4 | 101000/116677 batches | ms/batch 11.91 | loss 440.6800\n",
            "| epoch   4 | 102000/116677 batches | ms/batch 12.70 | loss 496.8972\n",
            "| epoch   4 | 103000/116677 batches | ms/batch 12.39 | loss 476.3422\n",
            "| epoch   4 | 104000/116677 batches | ms/batch 12.62 | loss 487.3792\n",
            "| epoch   4 | 105000/116677 batches | ms/batch 12.30 | loss 464.8553\n",
            "| epoch   4 | 106000/116677 batches | ms/batch 12.12 | loss 457.2934\n",
            "| epoch   4 | 107000/116677 batches | ms/batch 12.58 | loss 479.3474\n",
            "| epoch   4 | 108000/116677 batches | ms/batch 12.15 | loss 459.7420\n",
            "| epoch   4 | 109000/116677 batches | ms/batch 12.07 | loss 444.2882\n",
            "| epoch   4 | 110000/116677 batches | ms/batch 12.55 | loss 484.5927\n",
            "| epoch   4 | 111000/116677 batches | ms/batch 12.33 | loss 471.4147\n",
            "| epoch   4 | 112000/116677 batches | ms/batch 12.70 | loss 497.0291\n",
            "| epoch   4 | 113000/116677 batches | ms/batch 12.98 | loss 513.4471\n",
            "| epoch   4 | 114000/116677 batches | ms/batch 11.83 | loss 430.2626\n",
            "| epoch   4 | 115000/116677 batches | ms/batch 11.95 | loss 439.6595\n",
            "| epoch   4 | 116000/116677 batches | ms/batch 12.53 | loss 487.2711\n",
            "| epoch   4 | 116677/116677 batches | ms/batch 12.08 | loss 450.3572\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 1517.48s | loss = 390.6317 | NDCG@10 = 16.4565 | Rec@10 = 14.1948 | Prec@10 = 11.5 | NDCG@100 = 27.6397 | Rec@100 = 50.1141 | Prec@100 = 5.51 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 1517.48s | loss = 362.6049 | NDCG@10 = 15.2968 | Rec@10 = 13.5885 | Prec@10 = 11.398 | NDCG@100 = 27.0217 | Rec@100 = 49.0069 | Prec@100 = 5.2051 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |  1000/116677 batches | ms/batch 12.38 | loss 461.0485\n",
            "| epoch   5 |  2000/116677 batches | ms/batch 12.54 | loss 472.9322\n",
            "| epoch   5 |  3000/116677 batches | ms/batch 11.23 | loss 377.7381\n",
            "| epoch   5 |  4000/116677 batches | ms/batch 11.78 | loss 417.4659\n",
            "| epoch   5 |  5000/116677 batches | ms/batch 12.18 | loss 449.0744\n",
            "| epoch   5 |  6000/116677 batches | ms/batch 12.60 | loss 479.6579\n",
            "| epoch   5 |  7000/116677 batches | ms/batch 12.78 | loss 501.2958\n",
            "| epoch   5 |  8000/116677 batches | ms/batch 12.57 | loss 478.8340\n",
            "| epoch   5 |  9000/116677 batches | ms/batch 12.25 | loss 458.9558\n",
            "| epoch   5 | 10000/116677 batches | ms/batch 12.40 | loss 466.0326\n",
            "| epoch   5 | 11000/116677 batches | ms/batch 12.70 | loss 482.6347\n",
            "| epoch   5 | 12000/116677 batches | ms/batch 12.91 | loss 502.7734\n",
            "| epoch   5 | 13000/116677 batches | ms/batch 11.86 | loss 437.1576\n",
            "| epoch   5 | 14000/116677 batches | ms/batch 12.23 | loss 456.8878\n",
            "| epoch   5 | 15000/116677 batches | ms/batch 11.81 | loss 429.9077\n",
            "| epoch   5 | 16000/116677 batches | ms/batch 11.88 | loss 429.6847\n",
            "| epoch   5 | 17000/116677 batches | ms/batch 11.92 | loss 434.7717\n",
            "| epoch   5 | 18000/116677 batches | ms/batch 12.30 | loss 463.1029\n",
            "| epoch   5 | 19000/116677 batches | ms/batch 13.41 | loss 542.4583\n",
            "| epoch   5 | 20000/116677 batches | ms/batch 11.99 | loss 442.9731\n",
            "| epoch   5 | 21000/116677 batches | ms/batch 12.38 | loss 466.5743\n",
            "| epoch   5 | 22000/116677 batches | ms/batch 12.48 | loss 475.6198\n",
            "| epoch   5 | 23000/116677 batches | ms/batch 12.53 | loss 476.9135\n",
            "| epoch   5 | 24000/116677 batches | ms/batch 12.57 | loss 469.0851\n",
            "| epoch   5 | 25000/116677 batches | ms/batch 12.02 | loss 443.2175\n",
            "| epoch   5 | 26000/116677 batches | ms/batch 11.92 | loss 439.4332\n",
            "| epoch   5 | 27000/116677 batches | ms/batch 12.55 | loss 481.1640\n",
            "| epoch   5 | 28000/116677 batches | ms/batch 12.21 | loss 453.0768\n",
            "| epoch   5 | 29000/116677 batches | ms/batch 12.25 | loss 459.8735\n",
            "| epoch   5 | 30000/116677 batches | ms/batch 12.09 | loss 442.4380\n",
            "| epoch   5 | 31000/116677 batches | ms/batch 12.61 | loss 481.8849\n",
            "| epoch   5 | 32000/116677 batches | ms/batch 12.27 | loss 466.6122\n",
            "| epoch   5 | 33000/116677 batches | ms/batch 12.01 | loss 444.6072\n",
            "| epoch   5 | 34000/116677 batches | ms/batch 12.33 | loss 465.3803\n",
            "| epoch   5 | 35000/116677 batches | ms/batch 12.11 | loss 448.2963\n",
            "| epoch   5 | 36000/116677 batches | ms/batch 12.66 | loss 482.8961\n",
            "| epoch   5 | 37000/116677 batches | ms/batch 12.84 | loss 500.9420\n",
            "| epoch   5 | 38000/116677 batches | ms/batch 12.11 | loss 451.8961\n",
            "| epoch   5 | 39000/116677 batches | ms/batch 12.60 | loss 483.6393\n",
            "| epoch   5 | 40000/116677 batches | ms/batch 12.36 | loss 468.0916\n",
            "| epoch   5 | 41000/116677 batches | ms/batch 12.82 | loss 500.9930\n",
            "| epoch   5 | 42000/116677 batches | ms/batch 12.39 | loss 478.6599\n",
            "| epoch   5 | 43000/116677 batches | ms/batch 12.25 | loss 451.9110\n",
            "| epoch   5 | 44000/116677 batches | ms/batch 12.69 | loss 493.6085\n",
            "| epoch   5 | 45000/116677 batches | ms/batch 12.41 | loss 466.0802\n",
            "| epoch   5 | 46000/116677 batches | ms/batch 12.83 | loss 502.3506\n",
            "| epoch   5 | 47000/116677 batches | ms/batch 12.12 | loss 451.2823\n",
            "| epoch   5 | 48000/116677 batches | ms/batch 12.94 | loss 513.7188\n",
            "| epoch   5 | 49000/116677 batches | ms/batch 12.40 | loss 465.2574\n",
            "| epoch   5 | 50000/116677 batches | ms/batch 12.37 | loss 458.6989\n",
            "| epoch   5 | 51000/116677 batches | ms/batch 12.10 | loss 446.0493\n",
            "| epoch   5 | 52000/116677 batches | ms/batch 12.14 | loss 452.9254\n",
            "| epoch   5 | 53000/116677 batches | ms/batch 12.57 | loss 481.0107\n",
            "| epoch   5 | 54000/116677 batches | ms/batch 11.91 | loss 436.1743\n",
            "| epoch   5 | 55000/116677 batches | ms/batch 11.58 | loss 413.3791\n",
            "| epoch   5 | 56000/116677 batches | ms/batch 12.57 | loss 475.6317\n",
            "| epoch   5 | 57000/116677 batches | ms/batch 12.95 | loss 509.9255\n",
            "| epoch   5 | 58000/116677 batches | ms/batch 12.73 | loss 498.2025\n",
            "| epoch   5 | 59000/116677 batches | ms/batch 12.52 | loss 482.5730\n",
            "| epoch   5 | 60000/116677 batches | ms/batch 12.81 | loss 498.3956\n",
            "| epoch   5 | 61000/116677 batches | ms/batch 11.84 | loss 430.3867\n",
            "| epoch   5 | 62000/116677 batches | ms/batch 12.69 | loss 486.8525\n",
            "| epoch   5 | 63000/116677 batches | ms/batch 12.04 | loss 445.2818\n",
            "| epoch   5 | 64000/116677 batches | ms/batch 12.40 | loss 470.6858\n",
            "| epoch   5 | 65000/116677 batches | ms/batch 12.92 | loss 508.7388\n",
            "| epoch   5 | 66000/116677 batches | ms/batch 12.68 | loss 497.2637\n",
            "| epoch   5 | 67000/116677 batches | ms/batch 12.55 | loss 480.7845\n",
            "| epoch   5 | 68000/116677 batches | ms/batch 11.52 | loss 410.4634\n",
            "| epoch   5 | 69000/116677 batches | ms/batch 12.38 | loss 467.8500\n",
            "| epoch   5 | 70000/116677 batches | ms/batch 12.40 | loss 473.8195\n",
            "| epoch   5 | 71000/116677 batches | ms/batch 12.02 | loss 447.8019\n",
            "| epoch   5 | 72000/116677 batches | ms/batch 12.54 | loss 482.6751\n",
            "| epoch   5 | 73000/116677 batches | ms/batch 12.51 | loss 482.1357\n",
            "| epoch   5 | 74000/116677 batches | ms/batch 12.55 | loss 470.0930\n",
            "| epoch   5 | 75000/116677 batches | ms/batch 12.67 | loss 480.2884\n",
            "| epoch   5 | 76000/116677 batches | ms/batch 12.47 | loss 482.6190\n",
            "| epoch   5 | 77000/116677 batches | ms/batch 12.37 | loss 466.1067\n",
            "| epoch   5 | 78000/116677 batches | ms/batch 12.06 | loss 449.8683\n",
            "| epoch   5 | 79000/116677 batches | ms/batch 12.42 | loss 477.4179\n",
            "| epoch   5 | 80000/116677 batches | ms/batch 12.48 | loss 480.3708\n",
            "| epoch   5 | 81000/116677 batches | ms/batch 12.73 | loss 497.4369\n",
            "| epoch   5 | 82000/116677 batches | ms/batch 11.98 | loss 446.1186\n",
            "| epoch   5 | 83000/116677 batches | ms/batch 11.89 | loss 443.6753\n",
            "| epoch   5 | 84000/116677 batches | ms/batch 12.49 | loss 481.0950\n",
            "| epoch   5 | 85000/116677 batches | ms/batch 12.80 | loss 494.9133\n",
            "| epoch   5 | 86000/116677 batches | ms/batch 12.18 | loss 458.3983\n",
            "| epoch   5 | 87000/116677 batches | ms/batch 12.02 | loss 441.1360\n",
            "| epoch   5 | 88000/116677 batches | ms/batch 12.63 | loss 489.6385\n",
            "| epoch   5 | 89000/116677 batches | ms/batch 11.83 | loss 424.9592\n",
            "| epoch   5 | 90000/116677 batches | ms/batch 13.07 | loss 523.0648\n",
            "| epoch   5 | 91000/116677 batches | ms/batch 11.77 | loss 426.1342\n",
            "| epoch   5 | 92000/116677 batches | ms/batch 11.85 | loss 436.4035\n",
            "| epoch   5 | 93000/116677 batches | ms/batch 12.27 | loss 468.8800\n",
            "| epoch   5 | 94000/116677 batches | ms/batch 12.44 | loss 477.7055\n",
            "| epoch   5 | 95000/116677 batches | ms/batch 11.71 | loss 422.7361\n",
            "| epoch   5 | 96000/116677 batches | ms/batch 12.31 | loss 468.2374\n",
            "| epoch   5 | 97000/116677 batches | ms/batch 13.25 | loss 530.5186\n",
            "| epoch   5 | 98000/116677 batches | ms/batch 12.33 | loss 466.6862\n",
            "| epoch   5 | 99000/116677 batches | ms/batch 12.95 | loss 498.8839\n",
            "| epoch   5 | 100000/116677 batches | ms/batch 12.63 | loss 479.7058\n",
            "| epoch   5 | 101000/116677 batches | ms/batch 12.96 | loss 504.6393\n",
            "| epoch   5 | 102000/116677 batches | ms/batch 12.42 | loss 476.6057\n",
            "| epoch   5 | 103000/116677 batches | ms/batch 12.38 | loss 472.9372\n",
            "| epoch   5 | 104000/116677 batches | ms/batch 12.51 | loss 481.5251\n",
            "| epoch   5 | 105000/116677 batches | ms/batch 12.38 | loss 468.9806\n",
            "| epoch   5 | 106000/116677 batches | ms/batch 12.92 | loss 510.6591\n",
            "| epoch   5 | 107000/116677 batches | ms/batch 12.31 | loss 468.1892\n",
            "| epoch   5 | 108000/116677 batches | ms/batch 12.60 | loss 486.3102\n",
            "| epoch   5 | 109000/116677 batches | ms/batch 12.15 | loss 455.9649\n",
            "| epoch   5 | 110000/116677 batches | ms/batch 12.54 | loss 481.7511\n",
            "| epoch   5 | 111000/116677 batches | ms/batch 11.83 | loss 430.1139\n",
            "| epoch   5 | 112000/116677 batches | ms/batch 12.19 | loss 461.5895\n",
            "| epoch   5 | 113000/116677 batches | ms/batch 12.54 | loss 482.8088\n",
            "| epoch   5 | 114000/116677 batches | ms/batch 12.81 | loss 493.7104\n",
            "| epoch   5 | 115000/116677 batches | ms/batch 12.16 | loss 453.1628\n",
            "| epoch   5 | 116000/116677 batches | ms/batch 12.39 | loss 477.0184\n",
            "| epoch   5 | 116677/116677 batches | ms/batch 12.26 | loss 467.3040\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 1516.41s | loss = 390.0056 | NDCG@10 = 15.5832 | Rec@10 = 13.5864 | Prec@10 = 11.1 | NDCG@100 = 27.1133 | Rec@100 = 50.1823 | Prec@100 = 5.5 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 1516.41s | loss = 362.5249 | NDCG@10 = 15.0842 | Rec@10 = 13.3249 | Prec@10 = 11.208 | NDCG@100 = 26.7902 | Rec@100 = 48.7668 | Prec@100 = 5.1744 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |  1000/116677 batches | ms/batch 12.51 | loss 462.5714\n",
            "| epoch   6 |  2000/116677 batches | ms/batch 12.86 | loss 481.7464\n",
            "| epoch   6 |  3000/116677 batches | ms/batch 11.92 | loss 428.9318\n",
            "| epoch   6 |  4000/116677 batches | ms/batch 12.66 | loss 478.8154\n",
            "| epoch   6 |  5000/116677 batches | ms/batch 12.45 | loss 465.7143\n",
            "| epoch   6 |  6000/116677 batches | ms/batch 11.88 | loss 423.4468\n",
            "| epoch   6 |  7000/116677 batches | ms/batch 12.67 | loss 479.9250\n",
            "| epoch   6 |  8000/116677 batches | ms/batch 12.07 | loss 448.7045\n",
            "| epoch   6 |  9000/116677 batches | ms/batch 12.27 | loss 457.0683\n",
            "| epoch   6 | 10000/116677 batches | ms/batch 12.39 | loss 467.6472\n",
            "| epoch   6 | 11000/116677 batches | ms/batch 12.58 | loss 471.2203\n",
            "| epoch   6 | 12000/116677 batches | ms/batch 12.80 | loss 486.2561\n",
            "| epoch   6 | 13000/116677 batches | ms/batch 12.84 | loss 500.1369\n",
            "| epoch   6 | 14000/116677 batches | ms/batch 12.30 | loss 459.9260\n",
            "| epoch   6 | 15000/116677 batches | ms/batch 12.27 | loss 455.7634\n",
            "| epoch   6 | 16000/116677 batches | ms/batch 12.61 | loss 482.7576\n",
            "| epoch   6 | 17000/116677 batches | ms/batch 12.49 | loss 474.4446\n",
            "| epoch   6 | 18000/116677 batches | ms/batch 11.94 | loss 432.5398\n",
            "| epoch   6 | 19000/116677 batches | ms/batch 12.78 | loss 492.3733\n",
            "| epoch   6 | 20000/116677 batches | ms/batch 12.19 | loss 451.2400\n",
            "| epoch   6 | 21000/116677 batches | ms/batch 12.26 | loss 456.9457\n",
            "| epoch   6 | 22000/116677 batches | ms/batch 12.50 | loss 474.3947\n",
            "| epoch   6 | 23000/116677 batches | ms/batch 11.88 | loss 429.7694\n",
            "| epoch   6 | 24000/116677 batches | ms/batch 12.08 | loss 436.4619\n",
            "| epoch   6 | 25000/116677 batches | ms/batch 12.74 | loss 493.2245\n",
            "| epoch   6 | 26000/116677 batches | ms/batch 12.41 | loss 469.9690\n",
            "| epoch   6 | 27000/116677 batches | ms/batch 12.45 | loss 459.4630\n",
            "| epoch   6 | 28000/116677 batches | ms/batch 12.43 | loss 466.5194\n",
            "| epoch   6 | 29000/116677 batches | ms/batch 11.97 | loss 436.4187\n",
            "| epoch   6 | 30000/116677 batches | ms/batch 12.35 | loss 462.5879\n",
            "| epoch   6 | 31000/116677 batches | ms/batch 13.28 | loss 526.7652\n",
            "| epoch   6 | 32000/116677 batches | ms/batch 12.56 | loss 483.2255\n",
            "| epoch   6 | 33000/116677 batches | ms/batch 12.49 | loss 474.8055\n",
            "| epoch   6 | 34000/116677 batches | ms/batch 11.96 | loss 435.3745\n",
            "| epoch   6 | 35000/116677 batches | ms/batch 12.24 | loss 454.9445\n",
            "| epoch   6 | 36000/116677 batches | ms/batch 12.49 | loss 472.1764\n",
            "| epoch   6 | 37000/116677 batches | ms/batch 12.62 | loss 477.5628\n",
            "| epoch   6 | 38000/116677 batches | ms/batch 12.25 | loss 458.7411\n",
            "| epoch   6 | 39000/116677 batches | ms/batch 12.47 | loss 478.4185\n",
            "| epoch   6 | 40000/116677 batches | ms/batch 12.24 | loss 457.5817\n",
            "| epoch   6 | 41000/116677 batches | ms/batch 12.03 | loss 445.1029\n",
            "| epoch   6 | 42000/116677 batches | ms/batch 12.69 | loss 496.1067\n",
            "| epoch   6 | 43000/116677 batches | ms/batch 11.84 | loss 430.2389\n",
            "| epoch   6 | 44000/116677 batches | ms/batch 12.35 | loss 461.6168\n",
            "| epoch   6 | 45000/116677 batches | ms/batch 11.76 | loss 426.4905\n",
            "| epoch   6 | 46000/116677 batches | ms/batch 12.51 | loss 482.4935\n",
            "| epoch   6 | 47000/116677 batches | ms/batch 12.54 | loss 480.6602\n",
            "| epoch   6 | 48000/116677 batches | ms/batch 11.97 | loss 442.9003\n",
            "| epoch   6 | 49000/116677 batches | ms/batch 12.07 | loss 447.8568\n",
            "| epoch   6 | 50000/116677 batches | ms/batch 12.11 | loss 442.6894\n",
            "| epoch   6 | 51000/116677 batches | ms/batch 12.81 | loss 502.2377\n",
            "| epoch   6 | 52000/116677 batches | ms/batch 12.53 | loss 463.2132\n",
            "| epoch   6 | 53000/116677 batches | ms/batch 12.54 | loss 480.3946\n",
            "| epoch   6 | 54000/116677 batches | ms/batch 12.67 | loss 489.8203\n",
            "| epoch   6 | 55000/116677 batches | ms/batch 12.37 | loss 470.7282\n",
            "| epoch   6 | 56000/116677 batches | ms/batch 12.42 | loss 470.0418\n",
            "| epoch   6 | 57000/116677 batches | ms/batch 13.09 | loss 513.9786\n",
            "| epoch   6 | 58000/116677 batches | ms/batch 12.17 | loss 454.7860\n",
            "| epoch   6 | 59000/116677 batches | ms/batch 12.32 | loss 462.8563\n",
            "| epoch   6 | 60000/116677 batches | ms/batch 12.28 | loss 460.8525\n",
            "| epoch   6 | 61000/116677 batches | ms/batch 12.48 | loss 473.8121\n",
            "| epoch   6 | 62000/116677 batches | ms/batch 12.25 | loss 460.4771\n",
            "| epoch   6 | 63000/116677 batches | ms/batch 13.04 | loss 509.2843\n",
            "| epoch   6 | 64000/116677 batches | ms/batch 12.55 | loss 479.6732\n",
            "| epoch   6 | 65000/116677 batches | ms/batch 12.24 | loss 461.4460\n",
            "| epoch   6 | 66000/116677 batches | ms/batch 12.19 | loss 455.5650\n",
            "| epoch   6 | 67000/116677 batches | ms/batch 12.03 | loss 439.1519\n",
            "| epoch   6 | 68000/116677 batches | ms/batch 12.24 | loss 464.9662\n",
            "| epoch   6 | 69000/116677 batches | ms/batch 12.17 | loss 454.4714\n",
            "| epoch   6 | 70000/116677 batches | ms/batch 12.63 | loss 481.8284\n",
            "| epoch   6 | 71000/116677 batches | ms/batch 12.56 | loss 482.6036\n",
            "| epoch   6 | 72000/116677 batches | ms/batch 11.93 | loss 441.0634\n",
            "| epoch   6 | 73000/116677 batches | ms/batch 12.66 | loss 487.9035\n",
            "| epoch   6 | 74000/116677 batches | ms/batch 12.61 | loss 489.1082\n",
            "| epoch   6 | 75000/116677 batches | ms/batch 12.52 | loss 479.9593\n",
            "| epoch   6 | 76000/116677 batches | ms/batch 12.13 | loss 444.5017\n",
            "| epoch   6 | 77000/116677 batches | ms/batch 12.88 | loss 492.8811\n",
            "| epoch   6 | 78000/116677 batches | ms/batch 12.34 | loss 473.3066\n",
            "| epoch   6 | 79000/116677 batches | ms/batch 12.78 | loss 504.8893\n",
            "| epoch   6 | 80000/116677 batches | ms/batch 11.88 | loss 434.3726\n",
            "| epoch   6 | 81000/116677 batches | ms/batch 12.17 | loss 455.5586\n",
            "| epoch   6 | 82000/116677 batches | ms/batch 12.41 | loss 468.2797\n",
            "| epoch   6 | 83000/116677 batches | ms/batch 12.24 | loss 455.6832\n",
            "| epoch   6 | 84000/116677 batches | ms/batch 12.15 | loss 454.2522\n",
            "| epoch   6 | 85000/116677 batches | ms/batch 12.39 | loss 474.0638\n",
            "| epoch   6 | 86000/116677 batches | ms/batch 11.95 | loss 439.5756\n",
            "| epoch   6 | 87000/116677 batches | ms/batch 12.57 | loss 485.6671\n",
            "| epoch   6 | 88000/116677 batches | ms/batch 12.64 | loss 491.5085\n",
            "| epoch   6 | 89000/116677 batches | ms/batch 12.38 | loss 467.0513\n",
            "| epoch   6 | 90000/116677 batches | ms/batch 12.22 | loss 462.7060\n",
            "| epoch   6 | 91000/116677 batches | ms/batch 12.83 | loss 509.4472\n",
            "| epoch   6 | 92000/116677 batches | ms/batch 12.42 | loss 472.8415\n",
            "| epoch   6 | 93000/116677 batches | ms/batch 11.71 | loss 424.1049\n",
            "| epoch   6 | 94000/116677 batches | ms/batch 12.38 | loss 476.9303\n",
            "| epoch   6 | 95000/116677 batches | ms/batch 12.05 | loss 446.9576\n",
            "| epoch   6 | 96000/116677 batches | ms/batch 13.29 | loss 532.1848\n",
            "| epoch   6 | 97000/116677 batches | ms/batch 12.17 | loss 454.9671\n",
            "| epoch   6 | 98000/116677 batches | ms/batch 12.35 | loss 471.4571\n",
            "| epoch   6 | 99000/116677 batches | ms/batch 12.66 | loss 491.1640\n",
            "| epoch   6 | 100000/116677 batches | ms/batch 12.66 | loss 498.0774\n",
            "| epoch   6 | 101000/116677 batches | ms/batch 12.36 | loss 471.4756\n",
            "| epoch   6 | 102000/116677 batches | ms/batch 12.52 | loss 461.4651\n",
            "| epoch   6 | 103000/116677 batches | ms/batch 12.70 | loss 496.8805\n",
            "| epoch   6 | 104000/116677 batches | ms/batch 12.23 | loss 462.1472\n",
            "| epoch   6 | 105000/116677 batches | ms/batch 12.19 | loss 454.0612\n",
            "| epoch   6 | 106000/116677 batches | ms/batch 12.57 | loss 483.6274\n",
            "| epoch   6 | 107000/116677 batches | ms/batch 12.65 | loss 489.1772\n",
            "| epoch   6 | 108000/116677 batches | ms/batch 12.03 | loss 443.3638\n",
            "| epoch   6 | 109000/116677 batches | ms/batch 12.92 | loss 511.8463\n",
            "| epoch   6 | 110000/116677 batches | ms/batch 12.46 | loss 474.6127\n",
            "| epoch   6 | 111000/116677 batches | ms/batch 12.82 | loss 500.4573\n",
            "| epoch   6 | 112000/116677 batches | ms/batch 11.90 | loss 435.5071\n",
            "| epoch   6 | 113000/116677 batches | ms/batch 12.40 | loss 472.2396\n",
            "| epoch   6 | 114000/116677 batches | ms/batch 12.60 | loss 484.5978\n",
            "| epoch   6 | 115000/116677 batches | ms/batch 12.02 | loss 442.5741\n",
            "| epoch   6 | 116000/116677 batches | ms/batch 11.83 | loss 431.4756\n",
            "| epoch   6 | 116677/116677 batches | ms/batch 12.64 | loss 488.0351\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 1518.19s | loss = 389.8163 | NDCG@10 = 16.6946 | Rec@10 = 14.4813 | Prec@10 = 12.0 | NDCG@100 = 27.1778 | Rec@100 = 48.9754 | Prec@100 = 5.41 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 1518.19s | loss = 361.9805 | NDCG@10 = 14.7198 | Rec@10 = 13.1348 | Prec@10 = 10.878 | NDCG@100 = 26.689 | Rec@100 = 48.8681 | Prec@100 = 5.1338 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |  1000/116677 batches | ms/batch 12.65 | loss 480.4045\n",
            "| epoch   7 |  2000/116677 batches | ms/batch 12.17 | loss 451.2731\n",
            "| epoch   7 |  3000/116677 batches | ms/batch 12.43 | loss 470.2179\n",
            "| epoch   7 |  4000/116677 batches | ms/batch 12.15 | loss 444.4392\n",
            "| epoch   7 |  5000/116677 batches | ms/batch 12.68 | loss 475.9916\n",
            "| epoch   7 |  6000/116677 batches | ms/batch 11.94 | loss 435.5707\n",
            "| epoch   7 |  7000/116677 batches | ms/batch 12.21 | loss 455.3586\n",
            "| epoch   7 |  8000/116677 batches | ms/batch 12.73 | loss 489.4763\n",
            "| epoch   7 |  9000/116677 batches | ms/batch 12.32 | loss 459.7195\n",
            "| epoch   7 | 10000/116677 batches | ms/batch 12.20 | loss 449.3396\n",
            "| epoch   7 | 11000/116677 batches | ms/batch 12.26 | loss 456.9654\n",
            "| epoch   7 | 12000/116677 batches | ms/batch 12.55 | loss 471.4498\n",
            "| epoch   7 | 13000/116677 batches | ms/batch 11.73 | loss 413.6680\n",
            "| epoch   7 | 14000/116677 batches | ms/batch 11.91 | loss 423.4726\n",
            "| epoch   7 | 15000/116677 batches | ms/batch 13.08 | loss 510.7934\n",
            "| epoch   7 | 16000/116677 batches | ms/batch 12.20 | loss 451.9445\n",
            "| epoch   7 | 17000/116677 batches | ms/batch 12.63 | loss 472.7905\n",
            "| epoch   7 | 18000/116677 batches | ms/batch 12.48 | loss 459.9572\n",
            "| epoch   7 | 19000/116677 batches | ms/batch 12.13 | loss 432.2938\n",
            "| epoch   7 | 20000/116677 batches | ms/batch 12.65 | loss 479.7565\n",
            "| epoch   7 | 21000/116677 batches | ms/batch 11.93 | loss 431.9725\n",
            "| epoch   7 | 22000/116677 batches | ms/batch 11.94 | loss 430.5951\n",
            "| epoch   7 | 23000/116677 batches | ms/batch 11.83 | loss 428.4404\n",
            "| epoch   7 | 24000/116677 batches | ms/batch 11.73 | loss 416.7594\n",
            "| epoch   7 | 25000/116677 batches | ms/batch 12.60 | loss 481.3236\n",
            "| epoch   7 | 26000/116677 batches | ms/batch 12.42 | loss 470.8596\n",
            "| epoch   7 | 27000/116677 batches | ms/batch 12.55 | loss 478.1512\n",
            "| epoch   7 | 28000/116677 batches | ms/batch 12.64 | loss 477.5668\n",
            "| epoch   7 | 29000/116677 batches | ms/batch 12.80 | loss 492.8767\n",
            "| epoch   7 | 30000/116677 batches | ms/batch 12.86 | loss 484.7825\n",
            "| epoch   7 | 31000/116677 batches | ms/batch 13.22 | loss 521.8386\n",
            "| epoch   7 | 32000/116677 batches | ms/batch 12.58 | loss 482.1498\n",
            "| epoch   7 | 33000/116677 batches | ms/batch 12.36 | loss 462.7215\n",
            "| epoch   7 | 34000/116677 batches | ms/batch 12.02 | loss 439.6355\n",
            "| epoch   7 | 35000/116677 batches | ms/batch 12.30 | loss 460.3203\n",
            "| epoch   7 | 36000/116677 batches | ms/batch 12.12 | loss 447.9662\n",
            "| epoch   7 | 37000/116677 batches | ms/batch 12.25 | loss 450.1147\n",
            "| epoch   7 | 38000/116677 batches | ms/batch 12.90 | loss 495.2537\n",
            "| epoch   7 | 39000/116677 batches | ms/batch 12.09 | loss 437.9898\n",
            "| epoch   7 | 40000/116677 batches | ms/batch 12.89 | loss 496.5799\n",
            "| epoch   7 | 41000/116677 batches | ms/batch 12.75 | loss 494.5512\n",
            "| epoch   7 | 42000/116677 batches | ms/batch 12.39 | loss 457.3307\n",
            "| epoch   7 | 43000/116677 batches | ms/batch 12.85 | loss 482.7028\n",
            "| epoch   7 | 44000/116677 batches | ms/batch 13.50 | loss 540.9232\n",
            "| epoch   7 | 45000/116677 batches | ms/batch 12.32 | loss 453.6645\n",
            "| epoch   7 | 46000/116677 batches | ms/batch 12.59 | loss 469.9088\n",
            "| epoch   7 | 47000/116677 batches | ms/batch 12.13 | loss 430.4078\n",
            "| epoch   7 | 48000/116677 batches | ms/batch 12.41 | loss 465.2840\n",
            "| epoch   7 | 49000/116677 batches | ms/batch 12.85 | loss 496.7568\n",
            "| epoch   7 | 50000/116677 batches | ms/batch 11.99 | loss 437.3862\n",
            "| epoch   7 | 51000/116677 batches | ms/batch 12.57 | loss 471.7280\n",
            "| epoch   7 | 52000/116677 batches | ms/batch 12.50 | loss 476.8402\n",
            "| epoch   7 | 53000/116677 batches | ms/batch 12.31 | loss 466.9725\n",
            "| epoch   7 | 54000/116677 batches | ms/batch 12.90 | loss 494.5847\n",
            "| epoch   7 | 55000/116677 batches | ms/batch 12.23 | loss 448.9326\n",
            "| epoch   7 | 56000/116677 batches | ms/batch 12.05 | loss 445.5628\n",
            "| epoch   7 | 57000/116677 batches | ms/batch 12.70 | loss 476.0391\n",
            "| epoch   7 | 58000/116677 batches | ms/batch 12.71 | loss 484.8669\n",
            "| epoch   7 | 59000/116677 batches | ms/batch 12.81 | loss 490.2621\n",
            "| epoch   7 | 60000/116677 batches | ms/batch 12.58 | loss 475.7031\n",
            "| epoch   7 | 61000/116677 batches | ms/batch 13.12 | loss 511.7599\n",
            "| epoch   7 | 62000/116677 batches | ms/batch 12.64 | loss 481.1148\n",
            "| epoch   7 | 63000/116677 batches | ms/batch 12.23 | loss 452.3054\n",
            "| epoch   7 | 64000/116677 batches | ms/batch 12.21 | loss 443.6682\n",
            "| epoch   7 | 65000/116677 batches | ms/batch 12.55 | loss 469.5286\n",
            "| epoch   7 | 66000/116677 batches | ms/batch 12.50 | loss 450.8206\n",
            "| epoch   7 | 67000/116677 batches | ms/batch 12.91 | loss 493.3545\n",
            "| epoch   7 | 68000/116677 batches | ms/batch 12.75 | loss 484.3834\n",
            "| epoch   7 | 69000/116677 batches | ms/batch 12.02 | loss 436.4214\n",
            "| epoch   7 | 70000/116677 batches | ms/batch 13.15 | loss 516.8480\n",
            "| epoch   7 | 71000/116677 batches | ms/batch 12.60 | loss 476.0557\n",
            "| epoch   7 | 72000/116677 batches | ms/batch 12.49 | loss 470.8797\n",
            "| epoch   7 | 73000/116677 batches | ms/batch 12.48 | loss 468.9011\n",
            "| epoch   7 | 74000/116677 batches | ms/batch 12.45 | loss 466.2585\n",
            "| epoch   7 | 75000/116677 batches | ms/batch 12.69 | loss 484.7827\n",
            "| epoch   7 | 76000/116677 batches | ms/batch 12.50 | loss 467.9309\n",
            "| epoch   7 | 77000/116677 batches | ms/batch 12.63 | loss 481.7289\n",
            "| epoch   7 | 78000/116677 batches | ms/batch 12.18 | loss 451.4534\n",
            "| epoch   7 | 79000/116677 batches | ms/batch 12.56 | loss 463.7909\n",
            "| epoch   7 | 80000/116677 batches | ms/batch 12.41 | loss 468.2444\n",
            "| epoch   7 | 81000/116677 batches | ms/batch 12.31 | loss 466.4135\n",
            "| epoch   7 | 82000/116677 batches | ms/batch 12.44 | loss 469.9451\n",
            "| epoch   7 | 83000/116677 batches | ms/batch 12.33 | loss 459.3820\n",
            "| epoch   7 | 84000/116677 batches | ms/batch 12.43 | loss 469.4066\n",
            "| epoch   7 | 85000/116677 batches | ms/batch 12.67 | loss 467.6167\n",
            "| epoch   7 | 86000/116677 batches | ms/batch 11.86 | loss 418.5812\n",
            "| epoch   7 | 87000/116677 batches | ms/batch 12.76 | loss 487.9322\n",
            "| epoch   7 | 88000/116677 batches | ms/batch 12.46 | loss 472.6176\n",
            "| epoch   7 | 89000/116677 batches | ms/batch 12.75 | loss 482.9918\n",
            "| epoch   7 | 90000/116677 batches | ms/batch 12.49 | loss 470.1115\n",
            "| epoch   7 | 91000/116677 batches | ms/batch 12.29 | loss 458.5356\n",
            "| epoch   7 | 92000/116677 batches | ms/batch 12.42 | loss 470.4824\n",
            "| epoch   7 | 93000/116677 batches | ms/batch 11.87 | loss 431.2799\n",
            "| epoch   7 | 94000/116677 batches | ms/batch 12.57 | loss 482.4208\n",
            "| epoch   7 | 95000/116677 batches | ms/batch 12.56 | loss 472.2190\n",
            "| epoch   7 | 96000/116677 batches | ms/batch 12.33 | loss 441.8795\n",
            "| epoch   7 | 97000/116677 batches | ms/batch 12.52 | loss 469.5896\n",
            "| epoch   7 | 98000/116677 batches | ms/batch 13.43 | loss 534.3206\n",
            "| epoch   7 | 99000/116677 batches | ms/batch 12.29 | loss 453.3678\n",
            "| epoch   7 | 100000/116677 batches | ms/batch 12.83 | loss 495.8843\n",
            "| epoch   7 | 101000/116677 batches | ms/batch 12.28 | loss 459.9228\n",
            "| epoch   7 | 102000/116677 batches | ms/batch 12.49 | loss 465.9947\n",
            "| epoch   7 | 103000/116677 batches | ms/batch 12.08 | loss 442.7783\n",
            "| epoch   7 | 104000/116677 batches | ms/batch 12.69 | loss 465.7092\n",
            "| epoch   7 | 105000/116677 batches | ms/batch 12.52 | loss 472.2358\n",
            "| epoch   7 | 106000/116677 batches | ms/batch 12.44 | loss 467.2903\n",
            "| epoch   7 | 107000/116677 batches | ms/batch 12.65 | loss 483.6051\n",
            "| epoch   7 | 108000/116677 batches | ms/batch 12.88 | loss 503.4405\n",
            "| epoch   7 | 109000/116677 batches | ms/batch 12.32 | loss 466.6174\n",
            "| epoch   7 | 110000/116677 batches | ms/batch 12.60 | loss 475.9301\n",
            "| epoch   7 | 111000/116677 batches | ms/batch 12.25 | loss 455.7946\n",
            "| epoch   7 | 112000/116677 batches | ms/batch 12.08 | loss 449.8104\n",
            "| epoch   7 | 113000/116677 batches | ms/batch 12.64 | loss 489.2516\n",
            "| epoch   7 | 114000/116677 batches | ms/batch 12.68 | loss 492.1660\n",
            "| epoch   7 | 115000/116677 batches | ms/batch 12.07 | loss 441.5208\n",
            "| epoch   7 | 116000/116677 batches | ms/batch 12.45 | loss 472.8835\n",
            "| epoch   7 | 116677/116677 batches | ms/batch 12.89 | loss 504.4331\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 1527.63s | loss = 389.137 | NDCG@10 = 15.9889 | Rec@10 = 12.9265 | Prec@10 = 11.1 | NDCG@100 = 28.0541 | Rec@100 = 51.525 | Prec@100 = 5.685 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 1527.63s | loss = 361.5775 | NDCG@10 = 15.1039 | Rec@10 = 13.5925 | Prec@10 = 11.264 | NDCG@100 = 26.9346 | Rec@100 = 49.1108 | Prec@100 = 5.1967 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |  1000/116677 batches | ms/batch 12.10 | loss 444.5916\n",
            "| epoch   8 |  2000/116677 batches | ms/batch 12.38 | loss 470.0760\n",
            "| epoch   8 |  3000/116677 batches | ms/batch 12.31 | loss 455.8079\n",
            "| epoch   8 |  4000/116677 batches | ms/batch 12.72 | loss 486.4418\n",
            "| epoch   8 |  5000/116677 batches | ms/batch 12.31 | loss 454.2823\n",
            "| epoch   8 |  6000/116677 batches | ms/batch 12.39 | loss 451.7978\n",
            "| epoch   8 |  7000/116677 batches | ms/batch 12.18 | loss 443.1480\n",
            "| epoch   8 |  8000/116677 batches | ms/batch 12.02 | loss 437.1209\n",
            "| epoch   8 |  9000/116677 batches | ms/batch 12.31 | loss 455.4259\n",
            "| epoch   8 | 10000/116677 batches | ms/batch 12.09 | loss 442.6190\n",
            "| epoch   8 | 11000/116677 batches | ms/batch 12.13 | loss 446.4326\n",
            "| epoch   8 | 12000/116677 batches | ms/batch 12.94 | loss 496.7444\n",
            "| epoch   8 | 13000/116677 batches | ms/batch 13.11 | loss 510.7317\n",
            "| epoch   8 | 14000/116677 batches | ms/batch 12.16 | loss 448.7330\n",
            "| epoch   8 | 15000/116677 batches | ms/batch 12.23 | loss 451.6328\n",
            "| epoch   8 | 16000/116677 batches | ms/batch 12.49 | loss 474.4080\n",
            "| epoch   8 | 17000/116677 batches | ms/batch 12.36 | loss 462.1364\n",
            "| epoch   8 | 18000/116677 batches | ms/batch 13.02 | loss 508.9643\n",
            "| epoch   8 | 19000/116677 batches | ms/batch 12.24 | loss 453.5881\n",
            "| epoch   8 | 20000/116677 batches | ms/batch 12.04 | loss 440.8905\n",
            "| epoch   8 | 21000/116677 batches | ms/batch 12.45 | loss 471.6109\n",
            "| epoch   8 | 22000/116677 batches | ms/batch 13.28 | loss 525.0574\n",
            "| epoch   8 | 23000/116677 batches | ms/batch 12.46 | loss 469.0518\n",
            "| epoch   8 | 24000/116677 batches | ms/batch 12.85 | loss 501.2680\n",
            "| epoch   8 | 25000/116677 batches | ms/batch 12.69 | loss 483.8655\n",
            "| epoch   8 | 26000/116677 batches | ms/batch 12.38 | loss 468.8438\n",
            "| epoch   8 | 27000/116677 batches | ms/batch 12.11 | loss 447.6790\n",
            "| epoch   8 | 28000/116677 batches | ms/batch 12.37 | loss 468.3945\n",
            "| epoch   8 | 29000/116677 batches | ms/batch 12.48 | loss 476.8103\n",
            "| epoch   8 | 30000/116677 batches | ms/batch 12.09 | loss 440.4121\n",
            "| epoch   8 | 31000/116677 batches | ms/batch 12.43 | loss 465.8780\n",
            "| epoch   8 | 32000/116677 batches | ms/batch 12.53 | loss 468.3790\n",
            "| epoch   8 | 33000/116677 batches | ms/batch 12.78 | loss 494.0470\n",
            "| epoch   8 | 34000/116677 batches | ms/batch 12.27 | loss 453.9331\n",
            "| epoch   8 | 35000/116677 batches | ms/batch 12.32 | loss 463.6853\n",
            "| epoch   8 | 36000/116677 batches | ms/batch 12.36 | loss 466.9377\n",
            "| epoch   8 | 37000/116677 batches | ms/batch 12.47 | loss 458.0728\n",
            "| epoch   8 | 38000/116677 batches | ms/batch 12.78 | loss 484.1367\n",
            "| epoch   8 | 39000/116677 batches | ms/batch 13.03 | loss 509.4813\n",
            "| epoch   8 | 40000/116677 batches | ms/batch 12.97 | loss 507.9822\n",
            "| epoch   8 | 41000/116677 batches | ms/batch 12.06 | loss 441.8903\n",
            "| epoch   8 | 42000/116677 batches | ms/batch 12.79 | loss 499.5626\n",
            "| epoch   8 | 43000/116677 batches | ms/batch 12.88 | loss 504.2123\n",
            "| epoch   8 | 44000/116677 batches | ms/batch 12.62 | loss 479.1538\n",
            "| epoch   8 | 45000/116677 batches | ms/batch 12.41 | loss 470.8923\n",
            "| epoch   8 | 46000/116677 batches | ms/batch 13.05 | loss 519.9426\n",
            "| epoch   8 | 47000/116677 batches | ms/batch 12.41 | loss 472.9762\n",
            "| epoch   8 | 48000/116677 batches | ms/batch 12.09 | loss 444.3449\n",
            "| epoch   8 | 49000/116677 batches | ms/batch 12.28 | loss 462.2798\n",
            "| epoch   8 | 50000/116677 batches | ms/batch 12.71 | loss 492.3022\n",
            "| epoch   8 | 51000/116677 batches | ms/batch 12.27 | loss 455.0080\n",
            "| epoch   8 | 52000/116677 batches | ms/batch 12.35 | loss 468.5635\n",
            "| epoch   8 | 53000/116677 batches | ms/batch 12.59 | loss 484.0338\n",
            "| epoch   8 | 54000/116677 batches | ms/batch 11.97 | loss 442.9889\n",
            "| epoch   8 | 55000/116677 batches | ms/batch 12.55 | loss 483.6075\n",
            "| epoch   8 | 56000/116677 batches | ms/batch 12.66 | loss 478.7603\n",
            "| epoch   8 | 57000/116677 batches | ms/batch 13.05 | loss 507.8170\n",
            "| epoch   8 | 58000/116677 batches | ms/batch 11.95 | loss 438.6267\n",
            "| epoch   8 | 59000/116677 batches | ms/batch 12.17 | loss 456.4702\n",
            "| epoch   8 | 60000/116677 batches | ms/batch 12.44 | loss 474.3712\n",
            "| epoch   8 | 61000/116677 batches | ms/batch 12.56 | loss 471.5845\n",
            "| epoch   8 | 62000/116677 batches | ms/batch 11.51 | loss 406.9557\n",
            "| epoch   8 | 63000/116677 batches | ms/batch 11.50 | loss 400.9263\n",
            "| epoch   8 | 64000/116677 batches | ms/batch 12.23 | loss 454.1510\n",
            "| epoch   8 | 65000/116677 batches | ms/batch 12.52 | loss 481.3007\n",
            "| epoch   8 | 66000/116677 batches | ms/batch 12.36 | loss 466.6212\n",
            "| epoch   8 | 67000/116677 batches | ms/batch 12.58 | loss 484.6203\n",
            "| epoch   8 | 68000/116677 batches | ms/batch 12.40 | loss 472.9673\n",
            "| epoch   8 | 69000/116677 batches | ms/batch 12.54 | loss 485.0676\n",
            "| epoch   8 | 70000/116677 batches | ms/batch 12.24 | loss 453.3887\n",
            "| epoch   8 | 71000/116677 batches | ms/batch 12.29 | loss 463.4246\n",
            "| epoch   8 | 72000/116677 batches | ms/batch 12.48 | loss 473.7514\n",
            "| epoch   8 | 73000/116677 batches | ms/batch 12.77 | loss 493.2562\n",
            "| epoch   8 | 74000/116677 batches | ms/batch 12.58 | loss 483.2675\n",
            "| epoch   8 | 75000/116677 batches | ms/batch 12.48 | loss 473.3467\n",
            "| epoch   8 | 76000/116677 batches | ms/batch 11.94 | loss 434.7583\n",
            "| epoch   8 | 77000/116677 batches | ms/batch 12.31 | loss 459.0484\n",
            "| epoch   8 | 78000/116677 batches | ms/batch 12.53 | loss 479.3486\n",
            "| epoch   8 | 79000/116677 batches | ms/batch 13.02 | loss 511.2992\n",
            "| epoch   8 | 80000/116677 batches | ms/batch 12.21 | loss 457.8505\n",
            "| epoch   8 | 81000/116677 batches | ms/batch 12.53 | loss 467.0441\n",
            "| epoch   8 | 82000/116677 batches | ms/batch 12.02 | loss 432.6159\n",
            "| epoch   8 | 83000/116677 batches | ms/batch 12.11 | loss 441.1562\n",
            "| epoch   8 | 84000/116677 batches | ms/batch 12.08 | loss 447.7601\n",
            "| epoch   8 | 85000/116677 batches | ms/batch 12.12 | loss 451.5053\n",
            "| epoch   8 | 86000/116677 batches | ms/batch 12.50 | loss 467.8028\n",
            "| epoch   8 | 87000/116677 batches | ms/batch 11.64 | loss 419.2516\n",
            "| epoch   8 | 88000/116677 batches | ms/batch 12.62 | loss 486.2475\n",
            "| epoch   8 | 89000/116677 batches | ms/batch 11.81 | loss 429.6744\n",
            "| epoch   8 | 90000/116677 batches | ms/batch 12.81 | loss 495.2721\n",
            "| epoch   8 | 91000/116677 batches | ms/batch 11.94 | loss 438.7338\n",
            "| epoch   8 | 92000/116677 batches | ms/batch 12.32 | loss 464.7010\n",
            "| epoch   8 | 93000/116677 batches | ms/batch 11.93 | loss 436.2730\n",
            "| epoch   8 | 94000/116677 batches | ms/batch 12.09 | loss 447.3432\n",
            "| epoch   8 | 95000/116677 batches | ms/batch 11.95 | loss 441.3478\n",
            "| epoch   8 | 96000/116677 batches | ms/batch 12.15 | loss 444.5091\n",
            "| epoch   8 | 97000/116677 batches | ms/batch 12.20 | loss 452.3747\n",
            "| epoch   8 | 98000/116677 batches | ms/batch 12.63 | loss 487.0405\n",
            "| epoch   8 | 99000/116677 batches | ms/batch 11.93 | loss 436.2149\n",
            "| epoch   8 | 100000/116677 batches | ms/batch 12.15 | loss 455.6432\n",
            "| epoch   8 | 101000/116677 batches | ms/batch 12.33 | loss 468.2214\n",
            "| epoch   8 | 102000/116677 batches | ms/batch 12.89 | loss 503.8004\n",
            "| epoch   8 | 103000/116677 batches | ms/batch 12.21 | loss 457.9072\n",
            "| epoch   8 | 104000/116677 batches | ms/batch 12.36 | loss 472.1498\n",
            "| epoch   8 | 105000/116677 batches | ms/batch 12.16 | loss 451.2141\n",
            "| epoch   8 | 106000/116677 batches | ms/batch 12.48 | loss 475.8163\n",
            "| epoch   8 | 107000/116677 batches | ms/batch 12.98 | loss 503.9361\n",
            "| epoch   8 | 108000/116677 batches | ms/batch 12.51 | loss 485.1357\n",
            "| epoch   8 | 109000/116677 batches | ms/batch 12.83 | loss 500.9567\n",
            "| epoch   8 | 110000/116677 batches | ms/batch 12.67 | loss 489.1147\n",
            "| epoch   8 | 111000/116677 batches | ms/batch 12.68 | loss 480.6548\n",
            "| epoch   8 | 112000/116677 batches | ms/batch 12.93 | loss 506.0905\n",
            "| epoch   8 | 113000/116677 batches | ms/batch 12.55 | loss 476.7455\n",
            "| epoch   8 | 114000/116677 batches | ms/batch 11.78 | loss 419.9606\n",
            "| epoch   8 | 115000/116677 batches | ms/batch 12.30 | loss 449.4433\n",
            "| epoch   8 | 116000/116677 batches | ms/batch 12.81 | loss 494.1189\n",
            "| epoch   8 | 116677/116677 batches | ms/batch 13.01 | loss 513.2472\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 1520.74s | loss = 388.7197 | NDCG@10 = 15.588 | Rec@10 = 13.9129 | Prec@10 = 11.25 | NDCG@100 = 27.4175 | Rec@100 = 51.6047 | Prec@100 = 5.505 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 1520.74s | loss = 361.259 | NDCG@10 = 15.419 | Rec@10 = 13.7947 | Prec@10 = 11.4 | NDCG@100 = 27.2121 | Rec@100 = 49.2552 | Prec@100 = 5.2002 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |  1000/116677 batches | ms/batch 12.36 | loss 456.3720\n",
            "| epoch   9 |  2000/116677 batches | ms/batch 11.83 | loss 418.1935\n",
            "| epoch   9 |  3000/116677 batches | ms/batch 12.27 | loss 453.7962\n",
            "| epoch   9 |  4000/116677 batches | ms/batch 12.11 | loss 438.3811\n",
            "| epoch   9 |  5000/116677 batches | ms/batch 13.06 | loss 503.6773\n",
            "| epoch   9 |  6000/116677 batches | ms/batch 12.64 | loss 482.2819\n",
            "| epoch   9 |  7000/116677 batches | ms/batch 11.77 | loss 420.6771\n",
            "| epoch   9 |  8000/116677 batches | ms/batch 12.44 | loss 475.2457\n",
            "| epoch   9 |  9000/116677 batches | ms/batch 12.75 | loss 478.6771\n",
            "| epoch   9 | 10000/116677 batches | ms/batch 13.37 | loss 533.7587\n",
            "| epoch   9 | 11000/116677 batches | ms/batch 12.45 | loss 477.9863\n",
            "| epoch   9 | 12000/116677 batches | ms/batch 12.50 | loss 473.4399\n",
            "| epoch   9 | 13000/116677 batches | ms/batch 12.80 | loss 496.9295\n",
            "| epoch   9 | 14000/116677 batches | ms/batch 11.79 | loss 423.7451\n",
            "| epoch   9 | 15000/116677 batches | ms/batch 12.20 | loss 452.4437\n",
            "| epoch   9 | 16000/116677 batches | ms/batch 11.92 | loss 431.8629\n",
            "| epoch   9 | 17000/116677 batches | ms/batch 11.98 | loss 436.2931\n",
            "| epoch   9 | 18000/116677 batches | ms/batch 12.85 | loss 503.2317\n",
            "| epoch   9 | 19000/116677 batches | ms/batch 12.18 | loss 453.4203\n",
            "| epoch   9 | 20000/116677 batches | ms/batch 13.05 | loss 514.6796\n",
            "| epoch   9 | 21000/116677 batches | ms/batch 12.06 | loss 444.5692\n",
            "| epoch   9 | 22000/116677 batches | ms/batch 12.40 | loss 471.7991\n",
            "| epoch   9 | 23000/116677 batches | ms/batch 12.56 | loss 482.7552\n",
            "| epoch   9 | 24000/116677 batches | ms/batch 12.23 | loss 456.0068\n",
            "| epoch   9 | 25000/116677 batches | ms/batch 12.51 | loss 476.9879\n",
            "| epoch   9 | 26000/116677 batches | ms/batch 12.39 | loss 468.0191\n",
            "| epoch   9 | 27000/116677 batches | ms/batch 12.49 | loss 480.1365\n",
            "| epoch   9 | 28000/116677 batches | ms/batch 12.00 | loss 445.8875\n",
            "| epoch   9 | 29000/116677 batches | ms/batch 12.09 | loss 451.6447\n",
            "| epoch   9 | 30000/116677 batches | ms/batch 12.33 | loss 472.4459\n",
            "| epoch   9 | 31000/116677 batches | ms/batch 11.74 | loss 424.1141\n",
            "| epoch   9 | 32000/116677 batches | ms/batch 12.53 | loss 478.6082\n",
            "| epoch   9 | 33000/116677 batches | ms/batch 11.95 | loss 442.1805\n",
            "| epoch   9 | 34000/116677 batches | ms/batch 12.17 | loss 446.1156\n",
            "| epoch   9 | 35000/116677 batches | ms/batch 12.22 | loss 453.4932\n",
            "| epoch   9 | 36000/116677 batches | ms/batch 12.35 | loss 475.5976\n",
            "| epoch   9 | 37000/116677 batches | ms/batch 11.70 | loss 420.2537\n",
            "| epoch   9 | 38000/116677 batches | ms/batch 12.24 | loss 448.8874\n",
            "| epoch   9 | 39000/116677 batches | ms/batch 12.02 | loss 442.5123\n",
            "| epoch   9 | 40000/116677 batches | ms/batch 12.07 | loss 449.7135\n",
            "| epoch   9 | 41000/116677 batches | ms/batch 12.50 | loss 477.0686\n",
            "| epoch   9 | 42000/116677 batches | ms/batch 12.73 | loss 497.7186\n",
            "| epoch   9 | 43000/116677 batches | ms/batch 12.15 | loss 451.7559\n",
            "| epoch   9 | 44000/116677 batches | ms/batch 12.42 | loss 475.5674\n",
            "| epoch   9 | 45000/116677 batches | ms/batch 12.74 | loss 489.5239\n",
            "| epoch   9 | 46000/116677 batches | ms/batch 13.21 | loss 534.1558\n",
            "| epoch   9 | 47000/116677 batches | ms/batch 12.73 | loss 494.7180\n",
            "| epoch   9 | 48000/116677 batches | ms/batch 12.36 | loss 475.5251\n",
            "| epoch   9 | 49000/116677 batches | ms/batch 12.45 | loss 477.7500\n",
            "| epoch   9 | 50000/116677 batches | ms/batch 12.19 | loss 463.0785\n",
            "| epoch   9 | 51000/116677 batches | ms/batch 12.18 | loss 451.0596\n",
            "| epoch   9 | 52000/116677 batches | ms/batch 12.78 | loss 497.1165\n",
            "| epoch   9 | 53000/116677 batches | ms/batch 13.04 | loss 508.1959\n",
            "| epoch   9 | 54000/116677 batches | ms/batch 12.52 | loss 474.1782\n",
            "| epoch   9 | 55000/116677 batches | ms/batch 12.41 | loss 472.1700\n",
            "| epoch   9 | 56000/116677 batches | ms/batch 12.03 | loss 443.1627\n",
            "| epoch   9 | 57000/116677 batches | ms/batch 12.45 | loss 471.5395\n",
            "| epoch   9 | 58000/116677 batches | ms/batch 12.57 | loss 479.1705\n",
            "| epoch   9 | 59000/116677 batches | ms/batch 11.95 | loss 428.5856\n",
            "| epoch   9 | 60000/116677 batches | ms/batch 12.22 | loss 456.5633\n",
            "| epoch   9 | 61000/116677 batches | ms/batch 12.22 | loss 456.2331\n",
            "| epoch   9 | 62000/116677 batches | ms/batch 12.54 | loss 476.6948\n",
            "| epoch   9 | 63000/116677 batches | ms/batch 12.35 | loss 469.3167\n",
            "| epoch   9 | 64000/116677 batches | ms/batch 12.42 | loss 470.7361\n",
            "| epoch   9 | 65000/116677 batches | ms/batch 12.27 | loss 456.1313\n",
            "| epoch   9 | 66000/116677 batches | ms/batch 13.00 | loss 512.9570\n",
            "| epoch   9 | 67000/116677 batches | ms/batch 11.91 | loss 439.3678\n",
            "| epoch   9 | 68000/116677 batches | ms/batch 12.92 | loss 511.5807\n",
            "| epoch   9 | 69000/116677 batches | ms/batch 12.77 | loss 498.4298\n",
            "| epoch   9 | 70000/116677 batches | ms/batch 13.22 | loss 529.0930\n",
            "| epoch   9 | 71000/116677 batches | ms/batch 12.53 | loss 477.4893\n",
            "| epoch   9 | 72000/116677 batches | ms/batch 12.76 | loss 499.9889\n",
            "| epoch   9 | 73000/116677 batches | ms/batch 12.23 | loss 454.9710\n",
            "| epoch   9 | 74000/116677 batches | ms/batch 12.76 | loss 497.0962\n",
            "| epoch   9 | 75000/116677 batches | ms/batch 12.60 | loss 488.5268\n",
            "| epoch   9 | 76000/116677 batches | ms/batch 12.06 | loss 444.6013\n",
            "| epoch   9 | 77000/116677 batches | ms/batch 11.89 | loss 429.4648\n",
            "| epoch   9 | 78000/116677 batches | ms/batch 12.67 | loss 491.6601\n",
            "| epoch   9 | 79000/116677 batches | ms/batch 12.70 | loss 495.0183\n",
            "| epoch   9 | 80000/116677 batches | ms/batch 12.54 | loss 481.8798\n",
            "| epoch   9 | 81000/116677 batches | ms/batch 12.11 | loss 450.1532\n",
            "| epoch   9 | 82000/116677 batches | ms/batch 12.19 | loss 452.4356\n",
            "| epoch   9 | 83000/116677 batches | ms/batch 12.08 | loss 449.6337\n",
            "| epoch   9 | 84000/116677 batches | ms/batch 12.26 | loss 449.4706\n",
            "| epoch   9 | 85000/116677 batches | ms/batch 11.73 | loss 420.8758\n",
            "| epoch   9 | 86000/116677 batches | ms/batch 12.16 | loss 455.9813\n",
            "| epoch   9 | 87000/116677 batches | ms/batch 12.20 | loss 451.4701\n",
            "| epoch   9 | 88000/116677 batches | ms/batch 12.43 | loss 471.9030\n",
            "| epoch   9 | 89000/116677 batches | ms/batch 12.40 | loss 472.7276\n",
            "| epoch   9 | 90000/116677 batches | ms/batch 12.40 | loss 470.1797\n",
            "| epoch   9 | 91000/116677 batches | ms/batch 12.91 | loss 505.8156\n",
            "| epoch   9 | 92000/116677 batches | ms/batch 12.70 | loss 493.5445\n",
            "| epoch   9 | 93000/116677 batches | ms/batch 12.06 | loss 449.3679\n",
            "| epoch   9 | 94000/116677 batches | ms/batch 12.35 | loss 467.8309\n",
            "| epoch   9 | 95000/116677 batches | ms/batch 12.46 | loss 475.6520\n",
            "| epoch   9 | 96000/116677 batches | ms/batch 11.92 | loss 437.1978\n",
            "| epoch   9 | 97000/116677 batches | ms/batch 12.20 | loss 456.9490\n",
            "| epoch   9 | 98000/116677 batches | ms/batch 12.62 | loss 497.6183\n",
            "| epoch   9 | 99000/116677 batches | ms/batch 12.25 | loss 461.2996\n",
            "| epoch   9 | 100000/116677 batches | ms/batch 13.34 | loss 538.7704\n",
            "| epoch   9 | 101000/116677 batches | ms/batch 12.16 | loss 458.4438\n",
            "| epoch   9 | 102000/116677 batches | ms/batch 12.54 | loss 486.8480\n",
            "| epoch   9 | 103000/116677 batches | ms/batch 12.33 | loss 460.5173\n",
            "| epoch   9 | 104000/116677 batches | ms/batch 12.28 | loss 464.2066\n",
            "| epoch   9 | 105000/116677 batches | ms/batch 12.55 | loss 486.0096\n",
            "| epoch   9 | 106000/116677 batches | ms/batch 11.97 | loss 443.3257\n",
            "| epoch   9 | 107000/116677 batches | ms/batch 11.94 | loss 439.5515\n",
            "| epoch   9 | 108000/116677 batches | ms/batch 11.98 | loss 445.4334\n",
            "| epoch   9 | 109000/116677 batches | ms/batch 12.66 | loss 482.8047\n",
            "| epoch   9 | 110000/116677 batches | ms/batch 12.40 | loss 461.2460\n",
            "| epoch   9 | 111000/116677 batches | ms/batch 12.43 | loss 472.0863\n",
            "| epoch   9 | 112000/116677 batches | ms/batch 12.09 | loss 447.6378\n",
            "| epoch   9 | 113000/116677 batches | ms/batch 12.23 | loss 459.0802\n",
            "| epoch   9 | 114000/116677 batches | ms/batch 12.29 | loss 465.7163\n",
            "| epoch   9 | 115000/116677 batches | ms/batch 11.71 | loss 424.5446\n",
            "| epoch   9 | 116000/116677 batches | ms/batch 12.26 | loss 459.4568\n",
            "| epoch   9 | 116677/116677 batches | ms/batch 12.08 | loss 449.1524\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 1515.62s | loss = 388.9599 | NDCG@10 = 14.8695 | Rec@10 = 13.8844 | Prec@10 = 11.2 | NDCG@100 = 26.7033 | Rec@100 = 50.9727 | Prec@100 = 5.505 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 1515.62s | loss = 362.2903 | NDCG@10 = 15.3919 | Rec@10 = 13.7807 | Prec@10 = 11.375 | NDCG@100 = 27.1451 | Rec@100 = 49.0937 | Prec@100 = 5.2081 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |  1000/116677 batches | ms/batch 11.98 | loss 433.3984\n",
            "| epoch  10 |  2000/116677 batches | ms/batch 11.96 | loss 436.9243\n",
            "| epoch  10 |  3000/116677 batches | ms/batch 12.43 | loss 469.9092\n",
            "| epoch  10 |  4000/116677 batches | ms/batch 12.40 | loss 464.9880\n",
            "| epoch  10 |  5000/116677 batches | ms/batch 12.37 | loss 462.8764\n",
            "| epoch  10 |  6000/116677 batches | ms/batch 11.95 | loss 438.0103\n",
            "| epoch  10 |  7000/116677 batches | ms/batch 11.81 | loss 418.8469\n",
            "| epoch  10 |  8000/116677 batches | ms/batch 12.04 | loss 446.3484\n",
            "| epoch  10 |  9000/116677 batches | ms/batch 12.81 | loss 497.7365\n",
            "| epoch  10 | 10000/116677 batches | ms/batch 12.46 | loss 474.5156\n",
            "| epoch  10 | 11000/116677 batches | ms/batch 12.13 | loss 446.8187\n",
            "| epoch  10 | 12000/116677 batches | ms/batch 12.16 | loss 438.5229\n",
            "| epoch  10 | 13000/116677 batches | ms/batch 12.77 | loss 489.2849\n",
            "| epoch  10 | 14000/116677 batches | ms/batch 12.94 | loss 499.4943\n",
            "| epoch  10 | 15000/116677 batches | ms/batch 12.98 | loss 505.0194\n",
            "| epoch  10 | 16000/116677 batches | ms/batch 12.36 | loss 466.3037\n",
            "| epoch  10 | 17000/116677 batches | ms/batch 12.39 | loss 472.6668\n",
            "| epoch  10 | 18000/116677 batches | ms/batch 12.46 | loss 476.6371\n",
            "| epoch  10 | 19000/116677 batches | ms/batch 12.15 | loss 450.6336\n",
            "| epoch  10 | 20000/116677 batches | ms/batch 12.53 | loss 471.0728\n",
            "| epoch  10 | 21000/116677 batches | ms/batch 12.00 | loss 440.2682\n",
            "| epoch  10 | 22000/116677 batches | ms/batch 12.47 | loss 477.1751\n",
            "| epoch  10 | 23000/116677 batches | ms/batch 12.55 | loss 477.4164\n",
            "| epoch  10 | 24000/116677 batches | ms/batch 12.25 | loss 462.1544\n",
            "| epoch  10 | 25000/116677 batches | ms/batch 12.70 | loss 494.6458\n",
            "| epoch  10 | 26000/116677 batches | ms/batch 12.39 | loss 464.9650\n",
            "| epoch  10 | 27000/116677 batches | ms/batch 11.71 | loss 420.4835\n",
            "| epoch  10 | 28000/116677 batches | ms/batch 12.18 | loss 452.1006\n",
            "| epoch  10 | 29000/116677 batches | ms/batch 11.53 | loss 412.5208\n",
            "| epoch  10 | 30000/116677 batches | ms/batch 12.00 | loss 446.0329\n",
            "| epoch  10 | 31000/116677 batches | ms/batch 11.55 | loss 413.7644\n",
            "| epoch  10 | 32000/116677 batches | ms/batch 12.65 | loss 488.9555\n",
            "| epoch  10 | 33000/116677 batches | ms/batch 12.42 | loss 468.5288\n",
            "| epoch  10 | 34000/116677 batches | ms/batch 12.22 | loss 463.3406\n",
            "| epoch  10 | 35000/116677 batches | ms/batch 12.91 | loss 515.5242\n",
            "| epoch  10 | 36000/116677 batches | ms/batch 12.57 | loss 487.4448\n",
            "| epoch  10 | 37000/116677 batches | ms/batch 12.18 | loss 449.6774\n",
            "| epoch  10 | 38000/116677 batches | ms/batch 12.68 | loss 485.5149\n",
            "| epoch  10 | 39000/116677 batches | ms/batch 12.23 | loss 457.9877\n",
            "| epoch  10 | 40000/116677 batches | ms/batch 12.27 | loss 460.8423\n",
            "| epoch  10 | 41000/116677 batches | ms/batch 12.32 | loss 467.5502\n",
            "| epoch  10 | 42000/116677 batches | ms/batch 12.76 | loss 496.5545\n",
            "| epoch  10 | 43000/116677 batches | ms/batch 13.00 | loss 515.7600\n",
            "| epoch  10 | 44000/116677 batches | ms/batch 12.45 | loss 476.1290\n",
            "| epoch  10 | 45000/116677 batches | ms/batch 12.19 | loss 461.2429\n",
            "| epoch  10 | 46000/116677 batches | ms/batch 12.35 | loss 461.9818\n",
            "| epoch  10 | 47000/116677 batches | ms/batch 12.19 | loss 460.0644\n",
            "| epoch  10 | 48000/116677 batches | ms/batch 12.43 | loss 479.9217\n",
            "| epoch  10 | 49000/116677 batches | ms/batch 12.25 | loss 463.2137\n",
            "| epoch  10 | 50000/116677 batches | ms/batch 12.25 | loss 466.7841\n",
            "| epoch  10 | 51000/116677 batches | ms/batch 12.54 | loss 479.2422\n",
            "| epoch  10 | 52000/116677 batches | ms/batch 12.18 | loss 452.7925\n",
            "| epoch  10 | 53000/116677 batches | ms/batch 12.28 | loss 457.8267\n",
            "| epoch  10 | 54000/116677 batches | ms/batch 12.57 | loss 486.6133\n",
            "| epoch  10 | 55000/116677 batches | ms/batch 11.96 | loss 439.0423\n",
            "| epoch  10 | 56000/116677 batches | ms/batch 12.45 | loss 474.7464\n",
            "| epoch  10 | 57000/116677 batches | ms/batch 12.80 | loss 499.0070\n",
            "| epoch  10 | 58000/116677 batches | ms/batch 11.99 | loss 439.8227\n",
            "| epoch  10 | 59000/116677 batches | ms/batch 12.38 | loss 463.9208\n",
            "| epoch  10 | 60000/116677 batches | ms/batch 12.46 | loss 475.3557\n",
            "| epoch  10 | 61000/116677 batches | ms/batch 12.47 | loss 479.2490\n",
            "| epoch  10 | 62000/116677 batches | ms/batch 12.19 | loss 450.7002\n",
            "| epoch  10 | 63000/116677 batches | ms/batch 12.27 | loss 452.3875\n",
            "| epoch  10 | 64000/116677 batches | ms/batch 11.92 | loss 442.1768\n",
            "| epoch  10 | 65000/116677 batches | ms/batch 12.17 | loss 454.6787\n",
            "| epoch  10 | 66000/116677 batches | ms/batch 12.88 | loss 504.7224\n",
            "| epoch  10 | 67000/116677 batches | ms/batch 12.34 | loss 466.1810\n",
            "| epoch  10 | 68000/116677 batches | ms/batch 13.13 | loss 524.0748\n",
            "| epoch  10 | 69000/116677 batches | ms/batch 12.29 | loss 462.0546\n",
            "| epoch  10 | 70000/116677 batches | ms/batch 12.76 | loss 498.6114\n",
            "| epoch  10 | 71000/116677 batches | ms/batch 12.42 | loss 473.8294\n",
            "| epoch  10 | 72000/116677 batches | ms/batch 12.05 | loss 446.0185\n",
            "| epoch  10 | 73000/116677 batches | ms/batch 12.95 | loss 514.2112\n",
            "| epoch  10 | 74000/116677 batches | ms/batch 11.99 | loss 442.7421\n",
            "| epoch  10 | 75000/116677 batches | ms/batch 12.14 | loss 454.9238\n",
            "| epoch  10 | 76000/116677 batches | ms/batch 12.94 | loss 512.1559\n",
            "| epoch  10 | 77000/116677 batches | ms/batch 12.53 | loss 483.1288\n",
            "| epoch  10 | 78000/116677 batches | ms/batch 12.77 | loss 493.6638\n",
            "| epoch  10 | 79000/116677 batches | ms/batch 12.25 | loss 464.0730\n",
            "| epoch  10 | 80000/116677 batches | ms/batch 11.97 | loss 447.1601\n",
            "| epoch  10 | 81000/116677 batches | ms/batch 12.05 | loss 446.3554\n",
            "| epoch  10 | 82000/116677 batches | ms/batch 12.70 | loss 492.0938\n",
            "| epoch  10 | 83000/116677 batches | ms/batch 12.29 | loss 469.4393\n",
            "| epoch  10 | 84000/116677 batches | ms/batch 12.09 | loss 456.2831\n",
            "| epoch  10 | 85000/116677 batches | ms/batch 12.79 | loss 496.6864\n",
            "| epoch  10 | 86000/116677 batches | ms/batch 11.97 | loss 444.2214\n",
            "| epoch  10 | 87000/116677 batches | ms/batch 12.27 | loss 459.5392\n",
            "| epoch  10 | 88000/116677 batches | ms/batch 12.85 | loss 490.1013\n",
            "| epoch  10 | 89000/116677 batches | ms/batch 12.35 | loss 472.2598\n",
            "| epoch  10 | 90000/116677 batches | ms/batch 12.32 | loss 468.5973\n",
            "| epoch  10 | 91000/116677 batches | ms/batch 12.49 | loss 476.4059\n",
            "| epoch  10 | 92000/116677 batches | ms/batch 12.40 | loss 471.0287\n",
            "| epoch  10 | 93000/116677 batches | ms/batch 12.02 | loss 450.1971\n",
            "| epoch  10 | 94000/116677 batches | ms/batch 12.79 | loss 500.4084\n",
            "| epoch  10 | 95000/116677 batches | ms/batch 12.88 | loss 511.0828\n",
            "| epoch  10 | 96000/116677 batches | ms/batch 12.30 | loss 464.7532\n",
            "| epoch  10 | 97000/116677 batches | ms/batch 12.28 | loss 464.1201\n",
            "| epoch  10 | 98000/116677 batches | ms/batch 12.41 | loss 464.7043\n",
            "| epoch  10 | 99000/116677 batches | ms/batch 12.35 | loss 467.3615\n",
            "| epoch  10 | 100000/116677 batches | ms/batch 12.44 | loss 471.1936\n",
            "| epoch  10 | 101000/116677 batches | ms/batch 12.06 | loss 443.4778\n",
            "| epoch  10 | 102000/116677 batches | ms/batch 12.50 | loss 485.0809\n",
            "| epoch  10 | 103000/116677 batches | ms/batch 12.20 | loss 460.1473\n",
            "| epoch  10 | 104000/116677 batches | ms/batch 12.86 | loss 499.8819\n",
            "| epoch  10 | 105000/116677 batches | ms/batch 11.89 | loss 430.8838\n",
            "| epoch  10 | 106000/116677 batches | ms/batch 12.52 | loss 475.9827\n",
            "| epoch  10 | 107000/116677 batches | ms/batch 12.42 | loss 477.8063\n",
            "| epoch  10 | 108000/116677 batches | ms/batch 12.31 | loss 469.4640\n",
            "| epoch  10 | 109000/116677 batches | ms/batch 12.08 | loss 452.3896\n",
            "| epoch  10 | 110000/116677 batches | ms/batch 11.92 | loss 435.5921\n",
            "| epoch  10 | 111000/116677 batches | ms/batch 11.91 | loss 433.1201\n",
            "| epoch  10 | 112000/116677 batches | ms/batch 12.37 | loss 469.5600\n",
            "| epoch  10 | 113000/116677 batches | ms/batch 12.39 | loss 462.5929\n",
            "| epoch  10 | 114000/116677 batches | ms/batch 12.11 | loss 453.3397\n",
            "| epoch  10 | 115000/116677 batches | ms/batch 12.29 | loss 464.6744\n",
            "| epoch  10 | 116000/116677 batches | ms/batch 12.52 | loss 483.3642\n",
            "| epoch  10 | 116677/116677 batches | ms/batch 12.50 | loss 478.2094\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 1514.11s | loss = 389.1369 | NDCG@10 = 15.7082 | Rec@10 = 14.3622 | Prec@10 = 11.15 | NDCG@100 = 27.3117 | Rec@100 = 50.4512 | Prec@100 = 5.475 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 1514.11s | loss = 361.494 | NDCG@10 = 15.2746 | Rec@10 = 13.5482 | Prec@10 = 11.243 | NDCG@100 = 27.2553 | Rec@100 = 49.3941 | Prec@100 = 5.2454 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  11 |  1000/116677 batches | ms/batch 12.27 | loss 451.9896\n",
            "| epoch  11 |  2000/116677 batches | ms/batch 12.37 | loss 466.8387\n",
            "| epoch  11 |  3000/116677 batches | ms/batch 11.94 | loss 433.5874\n",
            "| epoch  11 |  4000/116677 batches | ms/batch 12.79 | loss 489.5102\n",
            "| epoch  11 |  5000/116677 batches | ms/batch 12.73 | loss 484.8357\n",
            "| epoch  11 |  6000/116677 batches | ms/batch 12.83 | loss 500.0293\n",
            "| epoch  11 |  7000/116677 batches | ms/batch 12.31 | loss 465.0850\n",
            "| epoch  11 |  8000/116677 batches | ms/batch 12.25 | loss 445.8040\n",
            "| epoch  11 |  9000/116677 batches | ms/batch 12.20 | loss 452.2386\n",
            "| epoch  11 | 10000/116677 batches | ms/batch 12.49 | loss 474.8881\n",
            "| epoch  11 | 11000/116677 batches | ms/batch 12.45 | loss 474.1458\n",
            "| epoch  11 | 12000/116677 batches | ms/batch 12.12 | loss 448.6999\n",
            "| epoch  11 | 13000/116677 batches | ms/batch 11.83 | loss 431.1392\n",
            "| epoch  11 | 14000/116677 batches | ms/batch 12.12 | loss 447.3564\n",
            "| epoch  11 | 15000/116677 batches | ms/batch 12.63 | loss 476.5688\n",
            "| epoch  11 | 16000/116677 batches | ms/batch 12.09 | loss 446.9136\n",
            "| epoch  11 | 17000/116677 batches | ms/batch 12.22 | loss 453.8167\n",
            "| epoch  11 | 18000/116677 batches | ms/batch 11.92 | loss 440.6306\n",
            "| epoch  11 | 19000/116677 batches | ms/batch 11.85 | loss 429.5182\n",
            "| epoch  11 | 20000/116677 batches | ms/batch 12.59 | loss 481.9587\n",
            "| epoch  11 | 21000/116677 batches | ms/batch 12.43 | loss 465.7839\n",
            "| epoch  11 | 22000/116677 batches | ms/batch 12.31 | loss 467.7488\n",
            "| epoch  11 | 23000/116677 batches | ms/batch 12.57 | loss 478.7944\n",
            "| epoch  11 | 24000/116677 batches | ms/batch 11.97 | loss 434.5641\n",
            "| epoch  11 | 25000/116677 batches | ms/batch 13.20 | loss 528.8277\n",
            "| epoch  11 | 26000/116677 batches | ms/batch 12.59 | loss 482.5863\n",
            "| epoch  11 | 27000/116677 batches | ms/batch 12.25 | loss 454.5392\n",
            "| epoch  11 | 28000/116677 batches | ms/batch 12.06 | loss 442.8124\n",
            "| epoch  11 | 29000/116677 batches | ms/batch 12.07 | loss 447.5746\n",
            "| epoch  11 | 30000/116677 batches | ms/batch 12.91 | loss 506.0109\n",
            "| epoch  11 | 31000/116677 batches | ms/batch 11.95 | loss 436.5360\n",
            "| epoch  11 | 32000/116677 batches | ms/batch 12.35 | loss 465.4849\n",
            "| epoch  11 | 33000/116677 batches | ms/batch 12.53 | loss 486.8052\n",
            "| epoch  11 | 34000/116677 batches | ms/batch 11.91 | loss 431.0960\n",
            "| epoch  11 | 35000/116677 batches | ms/batch 12.73 | loss 497.5112\n",
            "| epoch  11 | 36000/116677 batches | ms/batch 12.44 | loss 473.8303\n",
            "| epoch  11 | 37000/116677 batches | ms/batch 12.18 | loss 455.5032\n",
            "| epoch  11 | 38000/116677 batches | ms/batch 12.52 | loss 477.8351\n",
            "| epoch  11 | 39000/116677 batches | ms/batch 12.41 | loss 470.7698\n",
            "| epoch  11 | 40000/116677 batches | ms/batch 12.64 | loss 481.4180\n",
            "| epoch  11 | 41000/116677 batches | ms/batch 12.05 | loss 443.3534\n",
            "| epoch  11 | 42000/116677 batches | ms/batch 12.27 | loss 466.6743\n",
            "| epoch  11 | 43000/116677 batches | ms/batch 12.50 | loss 480.9934\n",
            "| epoch  11 | 44000/116677 batches | ms/batch 11.84 | loss 434.2971\n",
            "| epoch  11 | 45000/116677 batches | ms/batch 12.61 | loss 488.3572\n",
            "| epoch  11 | 46000/116677 batches | ms/batch 12.02 | loss 444.4294\n",
            "| epoch  11 | 47000/116677 batches | ms/batch 12.42 | loss 472.2621\n",
            "| epoch  11 | 48000/116677 batches | ms/batch 12.55 | loss 486.6987\n",
            "| epoch  11 | 49000/116677 batches | ms/batch 12.21 | loss 460.3893\n",
            "| epoch  11 | 50000/116677 batches | ms/batch 12.05 | loss 447.0745\n",
            "| epoch  11 | 51000/116677 batches | ms/batch 12.15 | loss 451.1403\n",
            "| epoch  11 | 52000/116677 batches | ms/batch 12.19 | loss 462.3875\n",
            "| epoch  11 | 53000/116677 batches | ms/batch 11.91 | loss 435.4621\n",
            "| epoch  11 | 54000/116677 batches | ms/batch 12.01 | loss 434.9884\n",
            "| epoch  11 | 55000/116677 batches | ms/batch 12.46 | loss 474.6551\n",
            "| epoch  11 | 56000/116677 batches | ms/batch 12.45 | loss 473.5339\n",
            "| epoch  11 | 57000/116677 batches | ms/batch 12.81 | loss 500.8528\n",
            "| epoch  11 | 58000/116677 batches | ms/batch 12.40 | loss 473.4837\n",
            "| epoch  11 | 59000/116677 batches | ms/batch 12.76 | loss 491.5779\n",
            "| epoch  11 | 60000/116677 batches | ms/batch 12.51 | loss 474.8961\n",
            "| epoch  11 | 61000/116677 batches | ms/batch 12.46 | loss 472.6297\n",
            "| epoch  11 | 62000/116677 batches | ms/batch 13.04 | loss 513.7407\n",
            "| epoch  11 | 63000/116677 batches | ms/batch 12.17 | loss 454.5188\n",
            "| epoch  11 | 64000/116677 batches | ms/batch 12.22 | loss 451.8587\n",
            "| epoch  11 | 65000/116677 batches | ms/batch 12.90 | loss 492.3992\n",
            "| epoch  11 | 66000/116677 batches | ms/batch 13.06 | loss 497.9289\n",
            "| epoch  11 | 67000/116677 batches | ms/batch 12.15 | loss 440.3569\n",
            "| epoch  11 | 68000/116677 batches | ms/batch 12.53 | loss 479.0215\n",
            "| epoch  11 | 69000/116677 batches | ms/batch 12.81 | loss 497.3708\n",
            "| epoch  11 | 70000/116677 batches | ms/batch 12.03 | loss 438.2850\n",
            "| epoch  11 | 71000/116677 batches | ms/batch 12.61 | loss 472.1095\n",
            "| epoch  11 | 72000/116677 batches | ms/batch 12.21 | loss 453.1523\n",
            "| epoch  11 | 73000/116677 batches | ms/batch 12.31 | loss 455.8509\n",
            "| epoch  11 | 74000/116677 batches | ms/batch 11.89 | loss 428.7141\n",
            "| epoch  11 | 75000/116677 batches | ms/batch 12.23 | loss 453.3673\n",
            "| epoch  11 | 76000/116677 batches | ms/batch 13.38 | loss 529.3740\n",
            "| epoch  11 | 77000/116677 batches | ms/batch 13.15 | loss 522.7026\n",
            "| epoch  11 | 78000/116677 batches | ms/batch 12.36 | loss 466.1320\n",
            "| epoch  11 | 79000/116677 batches | ms/batch 12.90 | loss 494.8230\n",
            "| epoch  11 | 80000/116677 batches | ms/batch 12.33 | loss 457.0865\n",
            "| epoch  11 | 81000/116677 batches | ms/batch 12.70 | loss 480.0146\n",
            "| epoch  11 | 82000/116677 batches | ms/batch 12.16 | loss 445.3933\n",
            "| epoch  11 | 83000/116677 batches | ms/batch 12.67 | loss 478.3929\n",
            "| epoch  11 | 84000/116677 batches | ms/batch 12.74 | loss 485.2603\n",
            "| epoch  11 | 85000/116677 batches | ms/batch 12.00 | loss 438.2560\n",
            "| epoch  11 | 86000/116677 batches | ms/batch 11.93 | loss 425.1132\n",
            "| epoch  11 | 87000/116677 batches | ms/batch 12.06 | loss 445.1335\n",
            "| epoch  11 | 88000/116677 batches | ms/batch 12.61 | loss 482.4176\n",
            "| epoch  11 | 89000/116677 batches | ms/batch 13.41 | loss 526.0481\n",
            "| epoch  11 | 90000/116677 batches | ms/batch 12.39 | loss 456.1305\n",
            "| epoch  11 | 91000/116677 batches | ms/batch 13.02 | loss 501.6888\n",
            "| epoch  11 | 92000/116677 batches | ms/batch 13.47 | loss 536.3134\n",
            "| epoch  11 | 93000/116677 batches | ms/batch 12.75 | loss 485.4357\n",
            "| epoch  11 | 94000/116677 batches | ms/batch 12.13 | loss 445.1810\n",
            "| epoch  11 | 95000/116677 batches | ms/batch 12.87 | loss 494.6038\n",
            "| epoch  11 | 96000/116677 batches | ms/batch 12.18 | loss 445.3403\n",
            "| epoch  11 | 97000/116677 batches | ms/batch 12.68 | loss 482.9461\n",
            "| epoch  11 | 98000/116677 batches | ms/batch 13.17 | loss 515.5115\n",
            "| epoch  11 | 99000/116677 batches | ms/batch 12.47 | loss 459.2654\n",
            "| epoch  11 | 100000/116677 batches | ms/batch 12.08 | loss 436.6448\n",
            "| epoch  11 | 101000/116677 batches | ms/batch 12.75 | loss 484.3181\n",
            "| epoch  11 | 102000/116677 batches | ms/batch 12.02 | loss 430.3083\n",
            "| epoch  11 | 103000/116677 batches | ms/batch 12.32 | loss 448.4180\n",
            "| epoch  11 | 104000/116677 batches | ms/batch 13.31 | loss 524.0312\n",
            "| epoch  11 | 105000/116677 batches | ms/batch 12.90 | loss 484.1962\n",
            "| epoch  11 | 106000/116677 batches | ms/batch 12.68 | loss 468.9879\n",
            "| epoch  11 | 107000/116677 batches | ms/batch 12.55 | loss 470.1567\n",
            "| epoch  11 | 108000/116677 batches | ms/batch 12.61 | loss 473.1802\n",
            "| epoch  11 | 109000/116677 batches | ms/batch 12.82 | loss 487.9368\n",
            "| epoch  11 | 110000/116677 batches | ms/batch 12.04 | loss 434.9856\n",
            "| epoch  11 | 111000/116677 batches | ms/batch 12.09 | loss 432.8376\n",
            "| epoch  11 | 112000/116677 batches | ms/batch 12.22 | loss 446.0980\n",
            "| epoch  11 | 113000/116677 batches | ms/batch 12.03 | loss 427.6224\n",
            "| epoch  11 | 114000/116677 batches | ms/batch 12.42 | loss 464.7998\n",
            "| epoch  11 | 115000/116677 batches | ms/batch 12.44 | loss 448.2642\n",
            "| epoch  11 | 116000/116677 batches | ms/batch 12.72 | loss 482.2507\n",
            "| epoch  11 | 116677/116677 batches | ms/batch 12.32 | loss 451.3651\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 1524.16s | loss = 388.7504 | NDCG@10 = 16.8893 | Rec@10 = 14.2668 | Prec@10 = 11.3 | NDCG@100 = 27.9959 | Rec@100 = 50.9929 | Prec@100 = 5.475 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 1524.16s | loss = 361.6952 | NDCG@10 = 15.4983 | Rec@10 = 13.9707 | Prec@10 = 11.456 | NDCG@100 = 27.1892 | Rec@100 = 49.0536 | Prec@100 = 5.1696 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |  1000/116677 batches | ms/batch 12.37 | loss 456.2557\n",
            "| epoch  12 |  2000/116677 batches | ms/batch 12.65 | loss 470.3988\n",
            "| epoch  12 |  3000/116677 batches | ms/batch 12.42 | loss 458.4731\n",
            "| epoch  12 |  4000/116677 batches | ms/batch 12.07 | loss 429.4773\n",
            "| epoch  12 |  5000/116677 batches | ms/batch 12.30 | loss 445.8529\n",
            "| epoch  12 |  6000/116677 batches | ms/batch 12.28 | loss 447.1130\n",
            "| epoch  12 |  7000/116677 batches | ms/batch 12.25 | loss 447.6841\n",
            "| epoch  12 |  8000/116677 batches | ms/batch 12.46 | loss 459.7119\n",
            "| epoch  12 |  9000/116677 batches | ms/batch 12.42 | loss 462.0057\n",
            "| epoch  12 | 10000/116677 batches | ms/batch 12.62 | loss 476.7104\n",
            "| epoch  12 | 11000/116677 batches | ms/batch 12.71 | loss 474.2433\n",
            "| epoch  12 | 12000/116677 batches | ms/batch 13.29 | loss 520.0262\n",
            "| epoch  12 | 13000/116677 batches | ms/batch 12.67 | loss 479.8548\n",
            "| epoch  12 | 14000/116677 batches | ms/batch 12.83 | loss 490.5976\n",
            "| epoch  12 | 15000/116677 batches | ms/batch 12.37 | loss 443.3468\n",
            "| epoch  12 | 16000/116677 batches | ms/batch 12.92 | loss 496.3439\n",
            "| epoch  12 | 17000/116677 batches | ms/batch 12.26 | loss 441.1904\n",
            "| epoch  12 | 18000/116677 batches | ms/batch 12.85 | loss 481.8198\n",
            "| epoch  12 | 19000/116677 batches | ms/batch 12.16 | loss 437.6173\n",
            "| epoch  12 | 20000/116677 batches | ms/batch 13.01 | loss 496.3695\n",
            "| epoch  12 | 21000/116677 batches | ms/batch 12.79 | loss 473.0223\n",
            "| epoch  12 | 22000/116677 batches | ms/batch 12.75 | loss 477.3550\n",
            "| epoch  12 | 23000/116677 batches | ms/batch 12.13 | loss 443.2996\n",
            "| epoch  12 | 24000/116677 batches | ms/batch 12.35 | loss 459.8440\n",
            "| epoch  12 | 25000/116677 batches | ms/batch 12.21 | loss 444.0180\n",
            "| epoch  12 | 26000/116677 batches | ms/batch 12.64 | loss 484.3855\n",
            "| epoch  12 | 27000/116677 batches | ms/batch 12.88 | loss 493.2721\n",
            "| epoch  12 | 28000/116677 batches | ms/batch 12.28 | loss 454.0532\n",
            "| epoch  12 | 29000/116677 batches | ms/batch 12.72 | loss 484.4764\n",
            "| epoch  12 | 30000/116677 batches | ms/batch 12.79 | loss 490.6980\n",
            "| epoch  12 | 31000/116677 batches | ms/batch 11.75 | loss 420.9037\n",
            "| epoch  12 | 32000/116677 batches | ms/batch 12.10 | loss 447.2436\n",
            "| epoch  12 | 33000/116677 batches | ms/batch 12.38 | loss 466.7413\n",
            "| epoch  12 | 34000/116677 batches | ms/batch 13.01 | loss 498.9397\n",
            "| epoch  12 | 35000/116677 batches | ms/batch 12.60 | loss 478.0219\n",
            "| epoch  12 | 36000/116677 batches | ms/batch 12.98 | loss 510.8643\n",
            "| epoch  12 | 37000/116677 batches | ms/batch 12.25 | loss 462.3266\n",
            "| epoch  12 | 38000/116677 batches | ms/batch 12.86 | loss 499.4659\n",
            "| epoch  12 | 39000/116677 batches | ms/batch 11.78 | loss 418.1584\n",
            "| epoch  12 | 40000/116677 batches | ms/batch 12.41 | loss 465.8876\n",
            "| epoch  12 | 41000/116677 batches | ms/batch 12.51 | loss 470.9180\n",
            "| epoch  12 | 42000/116677 batches | ms/batch 11.68 | loss 405.1171\n",
            "| epoch  12 | 43000/116677 batches | ms/batch 12.48 | loss 466.6673\n",
            "| epoch  12 | 44000/116677 batches | ms/batch 12.09 | loss 438.5806\n",
            "| epoch  12 | 45000/116677 batches | ms/batch 12.49 | loss 476.5784\n",
            "| epoch  12 | 46000/116677 batches | ms/batch 12.34 | loss 465.4047\n",
            "| epoch  12 | 47000/116677 batches | ms/batch 12.48 | loss 474.5240\n",
            "| epoch  12 | 48000/116677 batches | ms/batch 12.66 | loss 488.6303\n",
            "| epoch  12 | 49000/116677 batches | ms/batch 12.27 | loss 460.9914\n",
            "| epoch  12 | 50000/116677 batches | ms/batch 12.50 | loss 474.6803\n",
            "| epoch  12 | 51000/116677 batches | ms/batch 11.89 | loss 433.4000\n",
            "| epoch  12 | 52000/116677 batches | ms/batch 12.33 | loss 465.1311\n",
            "| epoch  12 | 53000/116677 batches | ms/batch 12.68 | loss 482.8012\n",
            "| epoch  12 | 54000/116677 batches | ms/batch 12.36 | loss 466.2766\n",
            "| epoch  12 | 55000/116677 batches | ms/batch 12.66 | loss 487.0759\n",
            "| epoch  12 | 56000/116677 batches | ms/batch 12.81 | loss 498.1554\n",
            "| epoch  12 | 57000/116677 batches | ms/batch 12.68 | loss 487.4905\n",
            "| epoch  12 | 58000/116677 batches | ms/batch 11.43 | loss 398.5022\n",
            "| epoch  12 | 59000/116677 batches | ms/batch 12.69 | loss 486.8227\n",
            "| epoch  12 | 60000/116677 batches | ms/batch 12.22 | loss 449.1640\n",
            "| epoch  12 | 61000/116677 batches | ms/batch 13.05 | loss 518.1760\n",
            "| epoch  12 | 62000/116677 batches | ms/batch 12.16 | loss 447.2160\n",
            "| epoch  12 | 63000/116677 batches | ms/batch 12.69 | loss 494.1392\n",
            "| epoch  12 | 64000/116677 batches | ms/batch 12.83 | loss 489.5151\n",
            "| epoch  12 | 65000/116677 batches | ms/batch 12.61 | loss 440.6699\n",
            "| epoch  12 | 66000/116677 batches | ms/batch 12.83 | loss 484.0056\n",
            "| epoch  12 | 67000/116677 batches | ms/batch 12.37 | loss 448.1592\n",
            "| epoch  12 | 68000/116677 batches | ms/batch 12.41 | loss 468.0622\n",
            "| epoch  12 | 69000/116677 batches | ms/batch 12.79 | loss 494.1837\n",
            "| epoch  12 | 70000/116677 batches | ms/batch 11.95 | loss 436.7570\n",
            "| epoch  12 | 71000/116677 batches | ms/batch 12.24 | loss 458.5868\n",
            "| epoch  12 | 72000/116677 batches | ms/batch 12.32 | loss 470.1287\n",
            "| epoch  12 | 73000/116677 batches | ms/batch 11.96 | loss 432.1354\n",
            "| epoch  12 | 74000/116677 batches | ms/batch 11.94 | loss 438.7391\n",
            "| epoch  12 | 75000/116677 batches | ms/batch 12.24 | loss 460.1679\n",
            "| epoch  12 | 76000/116677 batches | ms/batch 12.66 | loss 487.5666\n",
            "| epoch  12 | 77000/116677 batches | ms/batch 12.23 | loss 456.2151\n",
            "| epoch  12 | 78000/116677 batches | ms/batch 12.03 | loss 445.4344\n",
            "| epoch  12 | 79000/116677 batches | ms/batch 12.47 | loss 475.4089\n",
            "| epoch  12 | 80000/116677 batches | ms/batch 11.91 | loss 436.5128\n",
            "| epoch  12 | 81000/116677 batches | ms/batch 12.06 | loss 448.4575\n",
            "| epoch  12 | 82000/116677 batches | ms/batch 12.59 | loss 484.8249\n",
            "| epoch  12 | 83000/116677 batches | ms/batch 12.73 | loss 501.4907\n",
            "| epoch  12 | 84000/116677 batches | ms/batch 12.28 | loss 459.5664\n",
            "| epoch  12 | 85000/116677 batches | ms/batch 12.39 | loss 470.5417\n",
            "| epoch  12 | 86000/116677 batches | ms/batch 12.74 | loss 488.3556\n",
            "| epoch  12 | 87000/116677 batches | ms/batch 12.68 | loss 492.9425\n",
            "| epoch  12 | 88000/116677 batches | ms/batch 12.32 | loss 452.8548\n",
            "| epoch  12 | 89000/116677 batches | ms/batch 12.63 | loss 480.7150\n",
            "| epoch  12 | 90000/116677 batches | ms/batch 12.35 | loss 465.7348\n",
            "| epoch  12 | 91000/116677 batches | ms/batch 11.86 | loss 430.4558\n",
            "| epoch  12 | 92000/116677 batches | ms/batch 12.20 | loss 441.6823\n",
            "| epoch  12 | 93000/116677 batches | ms/batch 12.22 | loss 452.9294\n",
            "| epoch  12 | 94000/116677 batches | ms/batch 11.97 | loss 443.3824\n",
            "| epoch  12 | 95000/116677 batches | ms/batch 11.92 | loss 437.1855\n",
            "| epoch  12 | 96000/116677 batches | ms/batch 13.03 | loss 519.4968\n",
            "| epoch  12 | 97000/116677 batches | ms/batch 12.41 | loss 466.4335\n",
            "| epoch  12 | 98000/116677 batches | ms/batch 12.42 | loss 470.3756\n",
            "| epoch  12 | 99000/116677 batches | ms/batch 12.72 | loss 491.2710\n",
            "| epoch  12 | 100000/116677 batches | ms/batch 12.62 | loss 483.2888\n",
            "| epoch  12 | 101000/116677 batches | ms/batch 11.98 | loss 443.6873\n",
            "| epoch  12 | 102000/116677 batches | ms/batch 12.57 | loss 483.2950\n",
            "| epoch  12 | 103000/116677 batches | ms/batch 12.52 | loss 480.4293\n",
            "| epoch  12 | 104000/116677 batches | ms/batch 12.60 | loss 487.2972\n",
            "| epoch  12 | 105000/116677 batches | ms/batch 12.28 | loss 457.9812\n",
            "| epoch  12 | 106000/116677 batches | ms/batch 12.90 | loss 499.2399\n",
            "| epoch  12 | 107000/116677 batches | ms/batch 12.25 | loss 460.2271\n",
            "| epoch  12 | 108000/116677 batches | ms/batch 12.31 | loss 461.1334\n",
            "| epoch  12 | 109000/116677 batches | ms/batch 12.11 | loss 452.7399\n",
            "| epoch  12 | 110000/116677 batches | ms/batch 11.67 | loss 420.8254\n",
            "| epoch  12 | 111000/116677 batches | ms/batch 12.70 | loss 491.0344\n",
            "| epoch  12 | 112000/116677 batches | ms/batch 12.58 | loss 478.3727\n",
            "| epoch  12 | 113000/116677 batches | ms/batch 12.26 | loss 450.6068\n",
            "| epoch  12 | 114000/116677 batches | ms/batch 12.71 | loss 496.7816\n",
            "| epoch  12 | 115000/116677 batches | ms/batch 13.27 | loss 529.6962\n",
            "| epoch  12 | 116000/116677 batches | ms/batch 12.55 | loss 475.9295\n",
            "| epoch  12 | 116677/116677 batches | ms/batch 12.70 | loss 484.4391\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 1524.52s | loss = 387.1082 | NDCG@10 = 15.5252 | Rec@10 = 12.9769 | Prec@10 = 11.75 | NDCG@100 = 26.7594 | Rec@100 = 50.1906 | Prec@100 = 5.56 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 1524.52s | loss = 361.2278 | NDCG@10 = 14.9413 | Rec@10 = 13.2627 | Prec@10 = 11.204 | NDCG@100 = 26.8627 | Rec@100 = 49.1362 | Prec@100 = 5.2373 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |  1000/116677 batches | ms/batch 12.41 | loss 463.3270\n",
            "| epoch  13 |  2000/116677 batches | ms/batch 12.86 | loss 488.9177\n",
            "| epoch  13 |  3000/116677 batches | ms/batch 12.50 | loss 470.9221\n",
            "| epoch  13 |  4000/116677 batches | ms/batch 12.39 | loss 470.5641\n",
            "| epoch  13 |  5000/116677 batches | ms/batch 12.78 | loss 487.2339\n",
            "| epoch  13 |  6000/116677 batches | ms/batch 12.96 | loss 506.4465\n",
            "| epoch  13 |  7000/116677 batches | ms/batch 12.12 | loss 447.1570\n",
            "| epoch  13 |  8000/116677 batches | ms/batch 12.09 | loss 446.1287\n",
            "| epoch  13 |  9000/116677 batches | ms/batch 12.49 | loss 472.3939\n",
            "| epoch  13 | 10000/116677 batches | ms/batch 13.37 | loss 531.3763\n",
            "| epoch  13 | 11000/116677 batches | ms/batch 12.66 | loss 485.1201\n",
            "| epoch  13 | 12000/116677 batches | ms/batch 12.54 | loss 471.2174\n",
            "| epoch  13 | 13000/116677 batches | ms/batch 12.56 | loss 474.3329\n",
            "| epoch  13 | 14000/116677 batches | ms/batch 12.39 | loss 462.7300\n",
            "| epoch  13 | 15000/116677 batches | ms/batch 12.15 | loss 436.6804\n",
            "| epoch  13 | 16000/116677 batches | ms/batch 12.35 | loss 466.0538\n",
            "| epoch  13 | 17000/116677 batches | ms/batch 12.14 | loss 441.1097\n",
            "| epoch  13 | 18000/116677 batches | ms/batch 12.55 | loss 471.3496\n",
            "| epoch  13 | 19000/116677 batches | ms/batch 12.93 | loss 495.8972\n",
            "| epoch  13 | 20000/116677 batches | ms/batch 12.39 | loss 455.1517\n",
            "| epoch  13 | 21000/116677 batches | ms/batch 12.25 | loss 452.3615\n",
            "| epoch  13 | 22000/116677 batches | ms/batch 12.43 | loss 464.7041\n",
            "| epoch  13 | 23000/116677 batches | ms/batch 12.06 | loss 441.2083\n",
            "| epoch  13 | 24000/116677 batches | ms/batch 11.76 | loss 425.8171\n",
            "| epoch  13 | 25000/116677 batches | ms/batch 12.71 | loss 490.5106\n",
            "| epoch  13 | 26000/116677 batches | ms/batch 12.16 | loss 456.9221\n",
            "| epoch  13 | 27000/116677 batches | ms/batch 11.87 | loss 428.9499\n",
            "| epoch  13 | 28000/116677 batches | ms/batch 12.62 | loss 478.5729\n",
            "| epoch  13 | 29000/116677 batches | ms/batch 12.80 | loss 501.6726\n",
            "| epoch  13 | 30000/116677 batches | ms/batch 12.36 | loss 464.3901\n",
            "| epoch  13 | 31000/116677 batches | ms/batch 12.32 | loss 469.4204\n",
            "| epoch  13 | 32000/116677 batches | ms/batch 11.82 | loss 428.0212\n",
            "| epoch  13 | 33000/116677 batches | ms/batch 11.89 | loss 435.7158\n",
            "| epoch  13 | 34000/116677 batches | ms/batch 12.11 | loss 445.3763\n",
            "| epoch  13 | 35000/116677 batches | ms/batch 12.24 | loss 454.0815\n",
            "| epoch  13 | 36000/116677 batches | ms/batch 12.78 | loss 500.4410\n",
            "| epoch  13 | 37000/116677 batches | ms/batch 12.78 | loss 496.4579\n",
            "| epoch  13 | 38000/116677 batches | ms/batch 12.38 | loss 470.5784\n",
            "| epoch  13 | 39000/116677 batches | ms/batch 12.66 | loss 487.9793\n",
            "| epoch  13 | 40000/116677 batches | ms/batch 12.34 | loss 463.6808\n",
            "| epoch  13 | 41000/116677 batches | ms/batch 12.49 | loss 467.1926\n",
            "| epoch  13 | 42000/116677 batches | ms/batch 11.84 | loss 431.9813\n",
            "| epoch  13 | 43000/116677 batches | ms/batch 12.31 | loss 459.0614\n",
            "| epoch  13 | 44000/116677 batches | ms/batch 12.68 | loss 491.7043\n",
            "| epoch  13 | 45000/116677 batches | ms/batch 12.50 | loss 465.6960\n",
            "| epoch  13 | 46000/116677 batches | ms/batch 12.34 | loss 465.8589\n",
            "| epoch  13 | 47000/116677 batches | ms/batch 12.46 | loss 462.2586\n",
            "| epoch  13 | 48000/116677 batches | ms/batch 12.29 | loss 462.2217\n",
            "| epoch  13 | 49000/116677 batches | ms/batch 12.52 | loss 479.3824\n",
            "| epoch  13 | 50000/116677 batches | ms/batch 12.24 | loss 457.2172\n",
            "| epoch  13 | 51000/116677 batches | ms/batch 12.57 | loss 483.9010\n",
            "| epoch  13 | 52000/116677 batches | ms/batch 12.09 | loss 453.5276\n",
            "| epoch  13 | 53000/116677 batches | ms/batch 12.55 | loss 479.7896\n",
            "| epoch  13 | 54000/116677 batches | ms/batch 12.64 | loss 482.1832\n",
            "| epoch  13 | 55000/116677 batches | ms/batch 12.37 | loss 465.8497\n",
            "| epoch  13 | 56000/116677 batches | ms/batch 11.85 | loss 432.5110\n",
            "| epoch  13 | 57000/116677 batches | ms/batch 12.51 | loss 477.1314\n",
            "| epoch  13 | 58000/116677 batches | ms/batch 12.45 | loss 473.6158\n",
            "| epoch  13 | 59000/116677 batches | ms/batch 11.87 | loss 427.9532\n",
            "| epoch  13 | 60000/116677 batches | ms/batch 12.44 | loss 466.7496\n",
            "| epoch  13 | 61000/116677 batches | ms/batch 12.40 | loss 468.1960\n",
            "| epoch  13 | 62000/116677 batches | ms/batch 12.87 | loss 507.0754\n",
            "| epoch  13 | 63000/116677 batches | ms/batch 12.02 | loss 447.6021\n",
            "| epoch  13 | 64000/116677 batches | ms/batch 12.53 | loss 475.5636\n",
            "| epoch  13 | 65000/116677 batches | ms/batch 12.39 | loss 471.3114\n",
            "| epoch  13 | 66000/116677 batches | ms/batch 12.36 | loss 463.6336\n",
            "| epoch  13 | 67000/116677 batches | ms/batch 12.68 | loss 485.0551\n",
            "| epoch  13 | 68000/116677 batches | ms/batch 12.57 | loss 481.0147\n",
            "| epoch  13 | 69000/116677 batches | ms/batch 12.37 | loss 464.4454\n",
            "| epoch  13 | 70000/116677 batches | ms/batch 12.43 | loss 454.0350\n",
            "| epoch  13 | 71000/116677 batches | ms/batch 12.33 | loss 462.7766\n",
            "| epoch  13 | 72000/116677 batches | ms/batch 12.23 | loss 449.7288\n",
            "| epoch  13 | 73000/116677 batches | ms/batch 12.52 | loss 479.1549\n",
            "| epoch  13 | 74000/116677 batches | ms/batch 12.04 | loss 444.0104\n",
            "| epoch  13 | 75000/116677 batches | ms/batch 12.19 | loss 452.3633\n",
            "| epoch  13 | 76000/116677 batches | ms/batch 12.40 | loss 465.2790\n",
            "| epoch  13 | 77000/116677 batches | ms/batch 13.10 | loss 518.6500\n",
            "| epoch  13 | 78000/116677 batches | ms/batch 12.28 | loss 458.9406\n",
            "| epoch  13 | 79000/116677 batches | ms/batch 11.68 | loss 422.7847\n",
            "| epoch  13 | 80000/116677 batches | ms/batch 12.59 | loss 478.8284\n",
            "| epoch  13 | 81000/116677 batches | ms/batch 12.91 | loss 509.3938\n",
            "| epoch  13 | 82000/116677 batches | ms/batch 12.98 | loss 514.9140\n",
            "| epoch  13 | 83000/116677 batches | ms/batch 12.04 | loss 446.9028\n",
            "| epoch  13 | 84000/116677 batches | ms/batch 12.22 | loss 461.2396\n",
            "| epoch  13 | 85000/116677 batches | ms/batch 12.46 | loss 478.1360\n",
            "| epoch  13 | 86000/116677 batches | ms/batch 12.52 | loss 479.8428\n",
            "| epoch  13 | 87000/116677 batches | ms/batch 11.60 | loss 413.1645\n",
            "| epoch  13 | 88000/116677 batches | ms/batch 12.61 | loss 487.0656\n",
            "| epoch  13 | 89000/116677 batches | ms/batch 12.15 | loss 454.0221\n",
            "| epoch  13 | 90000/116677 batches | ms/batch 12.09 | loss 449.0483\n",
            "| epoch  13 | 91000/116677 batches | ms/batch 12.06 | loss 444.4895\n",
            "| epoch  13 | 92000/116677 batches | ms/batch 12.50 | loss 477.4163\n",
            "| epoch  13 | 93000/116677 batches | ms/batch 12.20 | loss 451.8407\n",
            "| epoch  13 | 94000/116677 batches | ms/batch 12.63 | loss 494.9534\n",
            "| epoch  13 | 95000/116677 batches | ms/batch 12.52 | loss 460.4236\n",
            "| epoch  13 | 96000/116677 batches | ms/batch 12.46 | loss 477.5709\n",
            "| epoch  13 | 97000/116677 batches | ms/batch 12.65 | loss 492.1829\n",
            "| epoch  13 | 98000/116677 batches | ms/batch 11.61 | loss 414.2440\n",
            "| epoch  13 | 99000/116677 batches | ms/batch 12.32 | loss 469.2675\n",
            "| epoch  13 | 100000/116677 batches | ms/batch 12.42 | loss 473.2110\n",
            "| epoch  13 | 101000/116677 batches | ms/batch 12.19 | loss 461.1787\n",
            "| epoch  13 | 102000/116677 batches | ms/batch 12.65 | loss 486.6665\n",
            "| epoch  13 | 103000/116677 batches | ms/batch 12.40 | loss 470.7614\n",
            "| epoch  13 | 104000/116677 batches | ms/batch 12.54 | loss 478.4252\n",
            "| epoch  13 | 105000/116677 batches | ms/batch 12.64 | loss 481.3488\n",
            "| epoch  13 | 106000/116677 batches | ms/batch 12.46 | loss 474.7040\n",
            "| epoch  13 | 107000/116677 batches | ms/batch 13.07 | loss 518.8839\n",
            "| epoch  13 | 108000/116677 batches | ms/batch 12.39 | loss 474.3216\n",
            "| epoch  13 | 109000/116677 batches | ms/batch 12.69 | loss 490.7988\n",
            "| epoch  13 | 110000/116677 batches | ms/batch 12.29 | loss 456.4525\n",
            "| epoch  13 | 111000/116677 batches | ms/batch 12.00 | loss 446.1530\n",
            "| epoch  13 | 112000/116677 batches | ms/batch 12.27 | loss 461.2111\n",
            "| epoch  13 | 113000/116677 batches | ms/batch 12.01 | loss 440.7979\n",
            "| epoch  13 | 114000/116677 batches | ms/batch 11.85 | loss 428.6458\n",
            "| epoch  13 | 115000/116677 batches | ms/batch 12.43 | loss 479.9103\n",
            "| epoch  13 | 116000/116677 batches | ms/batch 12.47 | loss 478.9799\n",
            "| epoch  13 | 116677/116677 batches | ms/batch 11.85 | loss 434.2643\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 1518.03s | loss = 389.0185 | NDCG@10 = 16.5169 | Rec@10 = 14.0951 | Prec@10 = 12.45 | NDCG@100 = 27.1157 | Rec@100 = 49.9252 | Prec@100 = 5.52 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 1518.03s | loss = 362.2224 | NDCG@10 = 15.0909 | Rec@10 = 13.3434 | Prec@10 = 11.293 | NDCG@100 = 26.9995 | Rec@100 = 49.3385 | Prec@100 = 5.2735 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |  1000/116677 batches | ms/batch 12.40 | loss 464.2234\n",
            "| epoch  14 |  2000/116677 batches | ms/batch 11.95 | loss 431.4034\n",
            "| epoch  14 |  3000/116677 batches | ms/batch 12.47 | loss 461.9384\n",
            "| epoch  14 |  4000/116677 batches | ms/batch 12.65 | loss 477.5769\n",
            "| epoch  14 |  5000/116677 batches | ms/batch 12.81 | loss 492.0145\n",
            "| epoch  14 |  6000/116677 batches | ms/batch 12.83 | loss 497.9557\n",
            "| epoch  14 |  7000/116677 batches | ms/batch 12.16 | loss 447.7429\n",
            "| epoch  14 |  8000/116677 batches | ms/batch 12.75 | loss 492.3222\n",
            "| epoch  14 |  9000/116677 batches | ms/batch 12.57 | loss 469.6282\n",
            "| epoch  14 | 10000/116677 batches | ms/batch 12.62 | loss 477.9384\n",
            "| epoch  14 | 11000/116677 batches | ms/batch 12.66 | loss 479.7288\n",
            "| epoch  14 | 12000/116677 batches | ms/batch 12.67 | loss 484.8894\n",
            "| epoch  14 | 13000/116677 batches | ms/batch 12.07 | loss 441.6117\n",
            "| epoch  14 | 14000/116677 batches | ms/batch 12.31 | loss 457.2767\n",
            "| epoch  14 | 15000/116677 batches | ms/batch 12.50 | loss 470.4502\n",
            "| epoch  14 | 16000/116677 batches | ms/batch 12.33 | loss 456.2981\n",
            "| epoch  14 | 17000/116677 batches | ms/batch 12.41 | loss 469.2861\n",
            "| epoch  14 | 18000/116677 batches | ms/batch 12.02 | loss 442.2500\n",
            "| epoch  14 | 19000/116677 batches | ms/batch 12.24 | loss 457.9469\n",
            "| epoch  14 | 20000/116677 batches | ms/batch 12.36 | loss 472.4335\n",
            "| epoch  14 | 21000/116677 batches | ms/batch 12.17 | loss 457.4781\n",
            "| epoch  14 | 22000/116677 batches | ms/batch 12.76 | loss 486.0060\n",
            "| epoch  14 | 23000/116677 batches | ms/batch 12.62 | loss 473.6714\n",
            "| epoch  14 | 24000/116677 batches | ms/batch 11.67 | loss 416.7493\n",
            "| epoch  14 | 25000/116677 batches | ms/batch 12.29 | loss 460.2828\n",
            "| epoch  14 | 26000/116677 batches | ms/batch 13.28 | loss 530.3359\n",
            "| epoch  14 | 27000/116677 batches | ms/batch 12.35 | loss 463.9001\n",
            "| epoch  14 | 28000/116677 batches | ms/batch 12.32 | loss 460.7247\n",
            "| epoch  14 | 29000/116677 batches | ms/batch 12.19 | loss 454.9077\n",
            "| epoch  14 | 30000/116677 batches | ms/batch 12.26 | loss 456.6966\n",
            "| epoch  14 | 31000/116677 batches | ms/batch 12.61 | loss 487.2827\n",
            "| epoch  14 | 32000/116677 batches | ms/batch 12.06 | loss 447.9755\n",
            "| epoch  14 | 33000/116677 batches | ms/batch 12.83 | loss 500.6958\n",
            "| epoch  14 | 34000/116677 batches | ms/batch 12.45 | loss 475.0989\n",
            "| epoch  14 | 35000/116677 batches | ms/batch 12.17 | loss 451.8386\n",
            "| epoch  14 | 36000/116677 batches | ms/batch 12.15 | loss 446.8287\n",
            "| epoch  14 | 37000/116677 batches | ms/batch 12.66 | loss 494.2097\n",
            "| epoch  14 | 38000/116677 batches | ms/batch 12.46 | loss 473.6631\n",
            "| epoch  14 | 39000/116677 batches | ms/batch 12.20 | loss 459.9323\n",
            "| epoch  14 | 40000/116677 batches | ms/batch 12.99 | loss 507.2854\n",
            "| epoch  14 | 41000/116677 batches | ms/batch 12.45 | loss 465.4913\n",
            "| epoch  14 | 42000/116677 batches | ms/batch 12.35 | loss 456.0046\n",
            "| epoch  14 | 43000/116677 batches | ms/batch 12.25 | loss 456.2036\n",
            "| epoch  14 | 44000/116677 batches | ms/batch 12.09 | loss 448.5872\n",
            "| epoch  14 | 45000/116677 batches | ms/batch 12.31 | loss 458.4893\n",
            "| epoch  14 | 46000/116677 batches | ms/batch 12.68 | loss 482.8819\n",
            "| epoch  14 | 47000/116677 batches | ms/batch 12.11 | loss 435.1657\n",
            "| epoch  14 | 48000/116677 batches | ms/batch 12.75 | loss 472.7156\n",
            "| epoch  14 | 49000/116677 batches | ms/batch 12.11 | loss 442.7898\n",
            "| epoch  14 | 50000/116677 batches | ms/batch 12.73 | loss 485.0497\n",
            "| epoch  14 | 51000/116677 batches | ms/batch 12.26 | loss 457.7234\n",
            "| epoch  14 | 52000/116677 batches | ms/batch 12.29 | loss 455.5086\n",
            "| epoch  14 | 53000/116677 batches | ms/batch 12.34 | loss 459.4037\n",
            "| epoch  14 | 54000/116677 batches | ms/batch 12.84 | loss 497.1249\n",
            "| epoch  14 | 55000/116677 batches | ms/batch 12.85 | loss 493.0685\n",
            "| epoch  14 | 56000/116677 batches | ms/batch 12.43 | loss 461.0927\n",
            "| epoch  14 | 57000/116677 batches | ms/batch 12.27 | loss 448.9623\n",
            "| epoch  14 | 58000/116677 batches | ms/batch 12.98 | loss 502.3922\n",
            "| epoch  14 | 59000/116677 batches | ms/batch 12.59 | loss 469.9656\n",
            "| epoch  14 | 60000/116677 batches | ms/batch 12.33 | loss 452.4252\n",
            "| epoch  14 | 61000/116677 batches | ms/batch 12.44 | loss 456.4901\n",
            "| epoch  14 | 62000/116677 batches | ms/batch 11.23 | loss 373.8815\n",
            "| epoch  14 | 63000/116677 batches | ms/batch 13.14 | loss 517.0616\n",
            "| epoch  14 | 64000/116677 batches | ms/batch 12.44 | loss 466.7913\n",
            "| epoch  14 | 65000/116677 batches | ms/batch 12.62 | loss 475.8453\n",
            "| epoch  14 | 66000/116677 batches | ms/batch 12.56 | loss 474.6172\n",
            "| epoch  14 | 67000/116677 batches | ms/batch 12.09 | loss 437.2218\n",
            "| epoch  14 | 68000/116677 batches | ms/batch 12.33 | loss 459.0543\n",
            "| epoch  14 | 69000/116677 batches | ms/batch 12.11 | loss 445.8060\n",
            "| epoch  14 | 70000/116677 batches | ms/batch 12.73 | loss 479.5109\n",
            "| epoch  14 | 71000/116677 batches | ms/batch 12.82 | loss 482.9809\n",
            "| epoch  14 | 72000/116677 batches | ms/batch 12.77 | loss 472.2165\n",
            "| epoch  14 | 73000/116677 batches | ms/batch 12.66 | loss 476.9069\n",
            "| epoch  14 | 74000/116677 batches | ms/batch 12.59 | loss 470.3296\n",
            "| epoch  14 | 75000/116677 batches | ms/batch 12.24 | loss 445.0854\n",
            "| epoch  14 | 76000/116677 batches | ms/batch 12.65 | loss 468.6880\n",
            "| epoch  14 | 77000/116677 batches | ms/batch 12.52 | loss 463.4000\n",
            "| epoch  14 | 78000/116677 batches | ms/batch 12.69 | loss 473.5162\n",
            "| epoch  14 | 79000/116677 batches | ms/batch 12.35 | loss 453.6900\n",
            "| epoch  14 | 80000/116677 batches | ms/batch 12.35 | loss 451.7119\n",
            "| epoch  14 | 81000/116677 batches | ms/batch 12.64 | loss 470.4025\n",
            "| epoch  14 | 82000/116677 batches | ms/batch 12.83 | loss 479.9766\n",
            "| epoch  14 | 83000/116677 batches | ms/batch 13.23 | loss 507.9594\n",
            "| epoch  14 | 84000/116677 batches | ms/batch 12.19 | loss 442.1383\n",
            "| epoch  14 | 85000/116677 batches | ms/batch 13.24 | loss 507.8206\n",
            "| epoch  14 | 86000/116677 batches | ms/batch 12.53 | loss 463.6579\n",
            "| epoch  14 | 87000/116677 batches | ms/batch 12.89 | loss 483.6167\n",
            "| epoch  14 | 88000/116677 batches | ms/batch 12.44 | loss 462.1352\n",
            "| epoch  14 | 89000/116677 batches | ms/batch 12.57 | loss 461.2815\n",
            "| epoch  14 | 90000/116677 batches | ms/batch 13.18 | loss 511.9358\n",
            "| epoch  14 | 91000/116677 batches | ms/batch 12.17 | loss 441.8394\n",
            "| epoch  14 | 92000/116677 batches | ms/batch 12.36 | loss 451.4213\n",
            "| epoch  14 | 93000/116677 batches | ms/batch 12.68 | loss 467.9487\n",
            "| epoch  14 | 94000/116677 batches | ms/batch 12.95 | loss 493.9554\n",
            "| epoch  14 | 95000/116677 batches | ms/batch 12.05 | loss 436.3934\n",
            "| epoch  14 | 96000/116677 batches | ms/batch 12.62 | loss 475.1593\n",
            "| epoch  14 | 97000/116677 batches | ms/batch 12.90 | loss 475.5789\n",
            "| epoch  14 | 98000/116677 batches | ms/batch 12.51 | loss 471.2828\n",
            "| epoch  14 | 99000/116677 batches | ms/batch 11.69 | loss 413.0607\n",
            "| epoch  14 | 100000/116677 batches | ms/batch 13.17 | loss 514.8793\n",
            "| epoch  14 | 101000/116677 batches | ms/batch 11.99 | loss 433.6178\n",
            "| epoch  14 | 102000/116677 batches | ms/batch 12.31 | loss 454.2990\n",
            "| epoch  14 | 103000/116677 batches | ms/batch 12.49 | loss 465.1959\n",
            "| epoch  14 | 104000/116677 batches | ms/batch 12.62 | loss 475.8855\n",
            "| epoch  14 | 105000/116677 batches | ms/batch 12.13 | loss 441.0546\n",
            "| epoch  14 | 106000/116677 batches | ms/batch 12.60 | loss 471.6367\n",
            "| epoch  14 | 107000/116677 batches | ms/batch 12.42 | loss 459.9681\n",
            "| epoch  14 | 108000/116677 batches | ms/batch 12.40 | loss 462.7831\n",
            "| epoch  14 | 109000/116677 batches | ms/batch 13.55 | loss 538.8008\n",
            "| epoch  14 | 110000/116677 batches | ms/batch 13.01 | loss 500.1994\n",
            "| epoch  14 | 111000/116677 batches | ms/batch 12.78 | loss 480.3252\n",
            "| epoch  14 | 112000/116677 batches | ms/batch 12.21 | loss 437.7230\n",
            "| epoch  14 | 113000/116677 batches | ms/batch 12.50 | loss 452.4493\n",
            "| epoch  14 | 114000/116677 batches | ms/batch 12.22 | loss 444.5591\n",
            "| epoch  14 | 115000/116677 batches | ms/batch 12.60 | loss 472.1388\n",
            "| epoch  14 | 116000/116677 batches | ms/batch 12.28 | loss 450.0821\n",
            "| epoch  14 | 116677/116677 batches | ms/batch 13.06 | loss 500.6696\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 1531.29s | loss = 387.2558 | NDCG@10 = 15.6412 | Rec@10 = 13.3355 | Prec@10 = 11.55 | NDCG@100 = 27.539 | Rec@100 = 51.1979 | Prec@100 = 5.7 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 1531.29s | loss = 361.2479 | NDCG@10 = 15.2708 | Rec@10 = 13.5992 | Prec@10 = 11.358 | NDCG@100 = 27.1135 | Rec@100 = 49.3413 | Prec@100 = 5.216 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |  1000/116677 batches | ms/batch 12.88 | loss 489.6046\n",
            "| epoch  15 |  2000/116677 batches | ms/batch 12.27 | loss 447.5464\n",
            "| epoch  15 |  3000/116677 batches | ms/batch 11.94 | loss 427.5928\n",
            "| epoch  15 |  4000/116677 batches | ms/batch 12.46 | loss 462.4070\n",
            "| epoch  15 |  5000/116677 batches | ms/batch 12.66 | loss 481.2599\n",
            "| epoch  15 |  6000/116677 batches | ms/batch 13.14 | loss 509.5190\n",
            "| epoch  15 |  7000/116677 batches | ms/batch 12.85 | loss 491.0490\n",
            "| epoch  15 |  8000/116677 batches | ms/batch 12.59 | loss 476.1300\n",
            "| epoch  15 |  9000/116677 batches | ms/batch 12.89 | loss 485.3341\n",
            "| epoch  15 | 10000/116677 batches | ms/batch 12.89 | loss 490.7245\n",
            "| epoch  15 | 11000/116677 batches | ms/batch 12.17 | loss 436.6043\n",
            "| epoch  15 | 12000/116677 batches | ms/batch 12.97 | loss 498.4987\n",
            "| epoch  15 | 13000/116677 batches | ms/batch 12.56 | loss 469.1159\n",
            "| epoch  15 | 14000/116677 batches | ms/batch 12.60 | loss 467.6668\n",
            "| epoch  15 | 15000/116677 batches | ms/batch 12.90 | loss 484.1809\n",
            "| epoch  15 | 16000/116677 batches | ms/batch 12.80 | loss 486.6985\n",
            "| epoch  15 | 17000/116677 batches | ms/batch 12.25 | loss 448.2653\n",
            "| epoch  15 | 18000/116677 batches | ms/batch 12.75 | loss 491.2474\n",
            "| epoch  15 | 19000/116677 batches | ms/batch 12.14 | loss 442.0068\n",
            "| epoch  15 | 20000/116677 batches | ms/batch 12.60 | loss 474.3944\n",
            "| epoch  15 | 21000/116677 batches | ms/batch 12.19 | loss 440.0564\n",
            "| epoch  15 | 22000/116677 batches | ms/batch 13.17 | loss 504.4504\n",
            "| epoch  15 | 23000/116677 batches | ms/batch 12.70 | loss 477.6445\n",
            "| epoch  15 | 24000/116677 batches | ms/batch 12.88 | loss 481.9562\n",
            "| epoch  15 | 25000/116677 batches | ms/batch 12.06 | loss 440.1566\n",
            "| epoch  15 | 26000/116677 batches | ms/batch 12.70 | loss 480.1302\n",
            "| epoch  15 | 27000/116677 batches | ms/batch 12.78 | loss 485.9951\n",
            "| epoch  15 | 28000/116677 batches | ms/batch 12.67 | loss 471.9106\n",
            "| epoch  15 | 29000/116677 batches | ms/batch 12.27 | loss 453.5350\n",
            "| epoch  15 | 30000/116677 batches | ms/batch 12.31 | loss 454.4367\n",
            "| epoch  15 | 31000/116677 batches | ms/batch 12.32 | loss 457.3361\n",
            "| epoch  15 | 32000/116677 batches | ms/batch 11.43 | loss 395.0547\n",
            "| epoch  15 | 33000/116677 batches | ms/batch 13.03 | loss 504.4805\n",
            "| epoch  15 | 34000/116677 batches | ms/batch 12.58 | loss 468.3984\n",
            "| epoch  15 | 35000/116677 batches | ms/batch 12.95 | loss 494.4662\n",
            "| epoch  15 | 36000/116677 batches | ms/batch 12.03 | loss 429.4055\n",
            "| epoch  15 | 37000/116677 batches | ms/batch 12.74 | loss 479.9213\n",
            "| epoch  15 | 38000/116677 batches | ms/batch 12.52 | loss 466.7779\n",
            "| epoch  15 | 39000/116677 batches | ms/batch 12.87 | loss 486.7946\n",
            "| epoch  15 | 40000/116677 batches | ms/batch 12.95 | loss 496.0117\n",
            "| epoch  15 | 41000/116677 batches | ms/batch 12.21 | loss 438.0375\n",
            "| epoch  15 | 42000/116677 batches | ms/batch 12.38 | loss 460.0512\n",
            "| epoch  15 | 43000/116677 batches | ms/batch 12.80 | loss 490.9780\n",
            "| epoch  15 | 44000/116677 batches | ms/batch 12.88 | loss 491.4824\n",
            "| epoch  15 | 45000/116677 batches | ms/batch 12.33 | loss 447.1379\n",
            "| epoch  15 | 46000/116677 batches | ms/batch 13.18 | loss 503.9776\n",
            "| epoch  15 | 47000/116677 batches | ms/batch 12.75 | loss 478.0327\n",
            "| epoch  15 | 48000/116677 batches | ms/batch 13.00 | loss 488.5618\n",
            "| epoch  15 | 49000/116677 batches | ms/batch 13.07 | loss 496.8771\n",
            "| epoch  15 | 50000/116677 batches | ms/batch 12.20 | loss 435.2879\n",
            "| epoch  15 | 51000/116677 batches | ms/batch 12.60 | loss 470.0208\n",
            "| epoch  15 | 52000/116677 batches | ms/batch 11.98 | loss 437.3184\n",
            "| epoch  15 | 53000/116677 batches | ms/batch 13.28 | loss 525.9955\n",
            "| epoch  15 | 54000/116677 batches | ms/batch 12.28 | loss 451.5061\n",
            "| epoch  15 | 55000/116677 batches | ms/batch 12.51 | loss 472.6953\n",
            "| epoch  15 | 56000/116677 batches | ms/batch 12.64 | loss 481.9222\n",
            "| epoch  15 | 57000/116677 batches | ms/batch 12.48 | loss 469.7964\n",
            "| epoch  15 | 58000/116677 batches | ms/batch 12.46 | loss 466.3011\n",
            "| epoch  15 | 59000/116677 batches | ms/batch 11.83 | loss 422.0401\n",
            "| epoch  15 | 60000/116677 batches | ms/batch 12.79 | loss 489.9156\n",
            "| epoch  15 | 61000/116677 batches | ms/batch 11.77 | loss 420.4447\n",
            "| epoch  15 | 62000/116677 batches | ms/batch 12.18 | loss 446.8293\n",
            "| epoch  15 | 63000/116677 batches | ms/batch 12.37 | loss 466.0683\n",
            "| epoch  15 | 64000/116677 batches | ms/batch 12.08 | loss 445.5466\n",
            "| epoch  15 | 65000/116677 batches | ms/batch 12.44 | loss 470.8584\n",
            "| epoch  15 | 66000/116677 batches | ms/batch 12.15 | loss 449.1057\n",
            "| epoch  15 | 67000/116677 batches | ms/batch 13.37 | loss 535.0776\n",
            "| epoch  15 | 68000/116677 batches | ms/batch 12.52 | loss 475.3333\n",
            "| epoch  15 | 69000/116677 batches | ms/batch 12.47 | loss 469.5417\n",
            "| epoch  15 | 70000/116677 batches | ms/batch 12.19 | loss 453.9659\n",
            "| epoch  15 | 71000/116677 batches | ms/batch 12.49 | loss 473.2149\n",
            "| epoch  15 | 72000/116677 batches | ms/batch 12.80 | loss 494.4260\n",
            "| epoch  15 | 73000/116677 batches | ms/batch 13.11 | loss 493.0867\n",
            "| epoch  15 | 74000/116677 batches | ms/batch 12.01 | loss 435.2041\n",
            "| epoch  15 | 75000/116677 batches | ms/batch 12.29 | loss 455.1213\n",
            "| epoch  15 | 76000/116677 batches | ms/batch 11.85 | loss 435.3654\n",
            "| epoch  15 | 77000/116677 batches | ms/batch 12.02 | loss 442.1104\n",
            "| epoch  15 | 78000/116677 batches | ms/batch 11.59 | loss 409.1893\n",
            "| epoch  15 | 79000/116677 batches | ms/batch 12.49 | loss 471.5267\n",
            "| epoch  15 | 80000/116677 batches | ms/batch 12.57 | loss 481.2776\n",
            "| epoch  15 | 81000/116677 batches | ms/batch 12.44 | loss 473.2094\n",
            "| epoch  15 | 82000/116677 batches | ms/batch 12.15 | loss 455.5707\n",
            "| epoch  15 | 83000/116677 batches | ms/batch 12.25 | loss 456.1715\n",
            "| epoch  15 | 84000/116677 batches | ms/batch 12.37 | loss 464.9818\n",
            "| epoch  15 | 85000/116677 batches | ms/batch 11.84 | loss 431.8255\n",
            "| epoch  15 | 86000/116677 batches | ms/batch 12.50 | loss 471.6245\n",
            "| epoch  15 | 87000/116677 batches | ms/batch 12.50 | loss 476.6157\n",
            "| epoch  15 | 88000/116677 batches | ms/batch 12.06 | loss 442.0436\n",
            "| epoch  15 | 89000/116677 batches | ms/batch 12.30 | loss 466.2162\n",
            "| epoch  15 | 90000/116677 batches | ms/batch 12.68 | loss 490.9317\n",
            "| epoch  15 | 91000/116677 batches | ms/batch 12.52 | loss 481.8233\n",
            "| epoch  15 | 92000/116677 batches | ms/batch 12.22 | loss 453.3342\n",
            "| epoch  15 | 93000/116677 batches | ms/batch 11.68 | loss 414.8643\n",
            "| epoch  15 | 94000/116677 batches | ms/batch 12.52 | loss 478.7487\n",
            "| epoch  15 | 95000/116677 batches | ms/batch 12.47 | loss 469.1347\n",
            "| epoch  15 | 96000/116677 batches | ms/batch 13.00 | loss 515.8212\n",
            "| epoch  15 | 97000/116677 batches | ms/batch 12.04 | loss 442.0192\n",
            "| epoch  15 | 98000/116677 batches | ms/batch 12.71 | loss 486.1789\n",
            "| epoch  15 | 99000/116677 batches | ms/batch 12.15 | loss 436.6751\n",
            "| epoch  15 | 100000/116677 batches | ms/batch 12.31 | loss 461.7680\n",
            "| epoch  15 | 101000/116677 batches | ms/batch 12.50 | loss 475.0847\n",
            "| epoch  15 | 102000/116677 batches | ms/batch 12.72 | loss 495.2516\n",
            "| epoch  15 | 103000/116677 batches | ms/batch 12.66 | loss 483.7112\n",
            "| epoch  15 | 104000/116677 batches | ms/batch 12.70 | loss 490.0199\n",
            "| epoch  15 | 105000/116677 batches | ms/batch 12.34 | loss 461.0211\n",
            "| epoch  15 | 106000/116677 batches | ms/batch 12.48 | loss 469.9193\n",
            "| epoch  15 | 107000/116677 batches | ms/batch 12.26 | loss 462.0943\n",
            "| epoch  15 | 108000/116677 batches | ms/batch 12.78 | loss 490.1857\n",
            "| epoch  15 | 109000/116677 batches | ms/batch 12.74 | loss 492.2702\n",
            "| epoch  15 | 110000/116677 batches | ms/batch 12.52 | loss 474.5108\n",
            "| epoch  15 | 111000/116677 batches | ms/batch 12.25 | loss 458.3573\n",
            "| epoch  15 | 112000/116677 batches | ms/batch 11.91 | loss 428.9705\n",
            "| epoch  15 | 113000/116677 batches | ms/batch 12.43 | loss 464.0723\n",
            "| epoch  15 | 114000/116677 batches | ms/batch 11.75 | loss 423.2306\n",
            "| epoch  15 | 115000/116677 batches | ms/batch 12.12 | loss 446.0117\n",
            "| epoch  15 | 116000/116677 batches | ms/batch 12.41 | loss 474.7316\n",
            "| epoch  15 | 116677/116677 batches | ms/batch 11.46 | loss 403.5293\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 1527.91s | loss = 389.3115 | NDCG@10 = 15.7589 | Rec@10 = 13.8262 | Prec@10 = 11.5 | NDCG@100 = 26.817 | Rec@100 = 49.3091 | Prec@100 = 5.44 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 1527.91s | loss = 360.9343 | NDCG@10 = 15.2704 | Rec@10 = 13.5971 | Prec@10 = 11.324 | NDCG@100 = 27.1083 | Rec@100 = 49.3172 | Prec@100 = 5.2383 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |  1000/116677 batches | ms/batch 13.14 | loss 501.6195\n",
            "| epoch  16 |  2000/116677 batches | ms/batch 12.99 | loss 488.4219\n",
            "| epoch  16 |  3000/116677 batches | ms/batch 12.50 | loss 466.2620\n",
            "| epoch  16 |  4000/116677 batches | ms/batch 12.53 | loss 467.8572\n",
            "| epoch  16 |  5000/116677 batches | ms/batch 12.81 | loss 490.8277\n",
            "| epoch  16 |  6000/116677 batches | ms/batch 12.77 | loss 486.0734\n",
            "| epoch  16 |  7000/116677 batches | ms/batch 12.47 | loss 473.7491\n",
            "| epoch  16 |  8000/116677 batches | ms/batch 12.42 | loss 458.5178\n",
            "| epoch  16 |  9000/116677 batches | ms/batch 12.93 | loss 486.9546\n",
            "| epoch  16 | 10000/116677 batches | ms/batch 12.23 | loss 442.5515\n",
            "| epoch  16 | 11000/116677 batches | ms/batch 12.75 | loss 484.0885\n",
            "| epoch  16 | 12000/116677 batches | ms/batch 12.44 | loss 463.7749\n",
            "| epoch  16 | 13000/116677 batches | ms/batch 11.82 | loss 421.4615\n",
            "| epoch  16 | 14000/116677 batches | ms/batch 12.47 | loss 474.4121\n",
            "| epoch  16 | 15000/116677 batches | ms/batch 12.69 | loss 479.0815\n",
            "| epoch  16 | 16000/116677 batches | ms/batch 12.81 | loss 492.4692\n",
            "| epoch  16 | 17000/116677 batches | ms/batch 12.12 | loss 445.3927\n",
            "| epoch  16 | 18000/116677 batches | ms/batch 12.24 | loss 455.2833\n",
            "| epoch  16 | 19000/116677 batches | ms/batch 13.04 | loss 513.9139\n",
            "| epoch  16 | 20000/116677 batches | ms/batch 12.48 | loss 468.9648\n",
            "| epoch  16 | 21000/116677 batches | ms/batch 12.05 | loss 437.8563\n",
            "| epoch  16 | 22000/116677 batches | ms/batch 12.61 | loss 476.3329\n",
            "| epoch  16 | 23000/116677 batches | ms/batch 12.94 | loss 509.6805\n",
            "| epoch  16 | 24000/116677 batches | ms/batch 12.31 | loss 462.5703\n",
            "| epoch  16 | 25000/116677 batches | ms/batch 12.84 | loss 498.6257\n",
            "| epoch  16 | 26000/116677 batches | ms/batch 12.52 | loss 463.3733\n",
            "| epoch  16 | 27000/116677 batches | ms/batch 12.61 | loss 481.1402\n",
            "| epoch  16 | 28000/116677 batches | ms/batch 12.01 | loss 433.6327\n",
            "| epoch  16 | 29000/116677 batches | ms/batch 12.27 | loss 459.4676\n",
            "| epoch  16 | 30000/116677 batches | ms/batch 11.98 | loss 441.1293\n",
            "| epoch  16 | 31000/116677 batches | ms/batch 12.35 | loss 467.4614\n",
            "| epoch  16 | 32000/116677 batches | ms/batch 12.48 | loss 476.8159\n",
            "| epoch  16 | 33000/116677 batches | ms/batch 12.65 | loss 485.2392\n",
            "| epoch  16 | 34000/116677 batches | ms/batch 12.68 | loss 488.1750\n",
            "| epoch  16 | 35000/116677 batches | ms/batch 12.23 | loss 449.4459\n",
            "| epoch  16 | 36000/116677 batches | ms/batch 12.79 | loss 499.0306\n",
            "| epoch  16 | 37000/116677 batches | ms/batch 12.23 | loss 455.8546\n",
            "| epoch  16 | 38000/116677 batches | ms/batch 12.65 | loss 489.9108\n",
            "| epoch  16 | 39000/116677 batches | ms/batch 12.33 | loss 462.6446\n",
            "| epoch  16 | 40000/116677 batches | ms/batch 13.14 | loss 512.4153\n",
            "| epoch  16 | 41000/116677 batches | ms/batch 12.90 | loss 503.4782\n",
            "| epoch  16 | 42000/116677 batches | ms/batch 12.80 | loss 506.0637\n",
            "| epoch  16 | 43000/116677 batches | ms/batch 12.06 | loss 441.7429\n",
            "| epoch  16 | 44000/116677 batches | ms/batch 12.72 | loss 484.9863\n",
            "| epoch  16 | 45000/116677 batches | ms/batch 13.14 | loss 523.1550\n",
            "| epoch  16 | 46000/116677 batches | ms/batch 12.35 | loss 465.7943\n",
            "| epoch  16 | 47000/116677 batches | ms/batch 12.37 | loss 464.9079\n",
            "| epoch  16 | 48000/116677 batches | ms/batch 11.94 | loss 435.2360\n",
            "| epoch  16 | 49000/116677 batches | ms/batch 12.48 | loss 472.1572\n",
            "| epoch  16 | 50000/116677 batches | ms/batch 12.40 | loss 466.9490\n",
            "| epoch  16 | 51000/116677 batches | ms/batch 12.41 | loss 465.3876\n",
            "| epoch  16 | 52000/116677 batches | ms/batch 12.22 | loss 455.4412\n",
            "| epoch  16 | 53000/116677 batches | ms/batch 12.05 | loss 455.0254\n",
            "| epoch  16 | 54000/116677 batches | ms/batch 12.81 | loss 497.8380\n",
            "| epoch  16 | 55000/116677 batches | ms/batch 11.84 | loss 430.5101\n",
            "| epoch  16 | 56000/116677 batches | ms/batch 12.22 | loss 463.6674\n",
            "| epoch  16 | 57000/116677 batches | ms/batch 12.30 | loss 458.9845\n",
            "| epoch  16 | 58000/116677 batches | ms/batch 12.63 | loss 482.8050\n",
            "| epoch  16 | 59000/116677 batches | ms/batch 12.55 | loss 480.9486\n",
            "| epoch  16 | 60000/116677 batches | ms/batch 12.34 | loss 465.6266\n",
            "| epoch  16 | 61000/116677 batches | ms/batch 12.07 | loss 447.6803\n",
            "| epoch  16 | 62000/116677 batches | ms/batch 12.00 | loss 442.3350\n",
            "| epoch  16 | 63000/116677 batches | ms/batch 12.29 | loss 463.5561\n",
            "| epoch  16 | 64000/116677 batches | ms/batch 12.98 | loss 505.6541\n",
            "| epoch  16 | 65000/116677 batches | ms/batch 12.18 | loss 456.9407\n",
            "| epoch  16 | 66000/116677 batches | ms/batch 12.40 | loss 471.6395\n",
            "| epoch  16 | 67000/116677 batches | ms/batch 12.63 | loss 485.6823\n",
            "| epoch  16 | 68000/116677 batches | ms/batch 12.84 | loss 502.4966\n",
            "| epoch  16 | 69000/116677 batches | ms/batch 12.75 | loss 490.0195\n",
            "| epoch  16 | 70000/116677 batches | ms/batch 12.63 | loss 484.9927\n",
            "| epoch  16 | 71000/116677 batches | ms/batch 11.96 | loss 442.3270\n",
            "| epoch  16 | 72000/116677 batches | ms/batch 12.00 | loss 444.7907\n",
            "| epoch  16 | 73000/116677 batches | ms/batch 12.51 | loss 475.2086\n",
            "| epoch  16 | 74000/116677 batches | ms/batch 12.61 | loss 485.4791\n",
            "| epoch  16 | 75000/116677 batches | ms/batch 12.33 | loss 464.0494\n",
            "| epoch  16 | 76000/116677 batches | ms/batch 12.35 | loss 459.6045\n",
            "| epoch  16 | 77000/116677 batches | ms/batch 11.59 | loss 414.9926\n",
            "| epoch  16 | 78000/116677 batches | ms/batch 11.83 | loss 433.7177\n",
            "| epoch  16 | 79000/116677 batches | ms/batch 12.23 | loss 460.8545\n",
            "| epoch  16 | 80000/116677 batches | ms/batch 11.84 | loss 429.7781\n",
            "| epoch  16 | 81000/116677 batches | ms/batch 12.09 | loss 454.7057\n",
            "| epoch  16 | 82000/116677 batches | ms/batch 12.33 | loss 465.4965\n",
            "| epoch  16 | 83000/116677 batches | ms/batch 11.71 | loss 419.3181\n",
            "| epoch  16 | 84000/116677 batches | ms/batch 12.53 | loss 481.2144\n",
            "| epoch  16 | 85000/116677 batches | ms/batch 11.89 | loss 439.3423\n",
            "| epoch  16 | 86000/116677 batches | ms/batch 12.34 | loss 469.7756\n",
            "| epoch  16 | 87000/116677 batches | ms/batch 12.42 | loss 476.1875\n",
            "| epoch  16 | 88000/116677 batches | ms/batch 12.33 | loss 464.4911\n",
            "| epoch  16 | 89000/116677 batches | ms/batch 12.42 | loss 470.1479\n",
            "| epoch  16 | 90000/116677 batches | ms/batch 12.53 | loss 476.8692\n",
            "| epoch  16 | 91000/116677 batches | ms/batch 12.03 | loss 447.0172\n",
            "| epoch  16 | 92000/116677 batches | ms/batch 12.42 | loss 475.1544\n",
            "| epoch  16 | 93000/116677 batches | ms/batch 12.47 | loss 475.6212\n",
            "| epoch  16 | 94000/116677 batches | ms/batch 12.64 | loss 488.4448\n",
            "| epoch  16 | 95000/116677 batches | ms/batch 12.29 | loss 465.9951\n",
            "| epoch  16 | 96000/116677 batches | ms/batch 12.34 | loss 466.7776\n",
            "| epoch  16 | 97000/116677 batches | ms/batch 11.89 | loss 433.1656\n",
            "| epoch  16 | 98000/116677 batches | ms/batch 12.42 | loss 466.5024\n",
            "| epoch  16 | 99000/116677 batches | ms/batch 11.97 | loss 440.4889\n",
            "| epoch  16 | 100000/116677 batches | ms/batch 12.33 | loss 461.9622\n",
            "| epoch  16 | 101000/116677 batches | ms/batch 11.86 | loss 422.3274\n",
            "| epoch  16 | 102000/116677 batches | ms/batch 12.23 | loss 455.8877\n",
            "| epoch  16 | 103000/116677 batches | ms/batch 12.31 | loss 459.1232\n",
            "| epoch  16 | 104000/116677 batches | ms/batch 12.06 | loss 446.8165\n",
            "| epoch  16 | 105000/116677 batches | ms/batch 11.78 | loss 425.2363\n",
            "| epoch  16 | 106000/116677 batches | ms/batch 12.02 | loss 437.9592\n",
            "| epoch  16 | 107000/116677 batches | ms/batch 12.66 | loss 492.3433\n",
            "| epoch  16 | 108000/116677 batches | ms/batch 12.10 | loss 451.1669\n",
            "| epoch  16 | 109000/116677 batches | ms/batch 12.18 | loss 460.6706\n",
            "| epoch  16 | 110000/116677 batches | ms/batch 12.54 | loss 479.6270\n",
            "| epoch  16 | 111000/116677 batches | ms/batch 11.80 | loss 429.0597\n",
            "| epoch  16 | 112000/116677 batches | ms/batch 12.63 | loss 486.3922\n",
            "| epoch  16 | 113000/116677 batches | ms/batch 12.17 | loss 449.5103\n",
            "| epoch  16 | 114000/116677 batches | ms/batch 12.50 | loss 478.7029\n",
            "| epoch  16 | 115000/116677 batches | ms/batch 12.73 | loss 499.0978\n",
            "| epoch  16 | 116000/116677 batches | ms/batch 12.57 | loss 484.2071\n",
            "| epoch  16 | 116677/116677 batches | ms/batch 12.25 | loss 458.9787\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 1518.40s | loss = 388.2891 | NDCG@10 = 16.0114 | Rec@10 = 13.9923 | Prec@10 = 12.25 | NDCG@100 = 27.3652 | Rec@100 = 51.5587 | Prec@100 = 5.555 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 1518.40s | loss = 360.8326 | NDCG@10 = 15.3295 | Rec@10 = 13.6494 | Prec@10 = 11.447 | NDCG@100 = 27.1604 | Rec@100 = 49.3701 | Prec@100 = 5.2497 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |  1000/116677 batches | ms/batch 12.45 | loss 469.5285\n",
            "| epoch  17 |  2000/116677 batches | ms/batch 11.97 | loss 429.8434\n",
            "| epoch  17 |  3000/116677 batches | ms/batch 12.26 | loss 451.9096\n",
            "| epoch  17 |  4000/116677 batches | ms/batch 12.35 | loss 452.8592\n",
            "| epoch  17 |  5000/116677 batches | ms/batch 12.21 | loss 450.9367\n",
            "| epoch  17 |  6000/116677 batches | ms/batch 12.80 | loss 494.2110\n",
            "| epoch  17 |  7000/116677 batches | ms/batch 12.47 | loss 472.2381\n",
            "| epoch  17 |  8000/116677 batches | ms/batch 12.34 | loss 459.5906\n",
            "| epoch  17 |  9000/116677 batches | ms/batch 12.58 | loss 480.3119\n",
            "| epoch  17 | 10000/116677 batches | ms/batch 12.68 | loss 479.3005\n",
            "| epoch  17 | 11000/116677 batches | ms/batch 12.60 | loss 478.6027\n",
            "| epoch  17 | 12000/116677 batches | ms/batch 12.06 | loss 440.0947\n",
            "| epoch  17 | 13000/116677 batches | ms/batch 11.97 | loss 438.5346\n",
            "| epoch  17 | 14000/116677 batches | ms/batch 12.38 | loss 471.5390\n",
            "| epoch  17 | 15000/116677 batches | ms/batch 11.85 | loss 428.2880\n",
            "| epoch  17 | 16000/116677 batches | ms/batch 12.63 | loss 478.4322\n",
            "| epoch  17 | 17000/116677 batches | ms/batch 12.21 | loss 454.4807\n",
            "| epoch  17 | 18000/116677 batches | ms/batch 12.51 | loss 474.4872\n",
            "| epoch  17 | 19000/116677 batches | ms/batch 12.53 | loss 484.7773\n",
            "| epoch  17 | 20000/116677 batches | ms/batch 11.98 | loss 438.1051\n",
            "| epoch  17 | 21000/116677 batches | ms/batch 11.62 | loss 419.0429\n",
            "| epoch  17 | 22000/116677 batches | ms/batch 11.94 | loss 437.7007\n",
            "| epoch  17 | 23000/116677 batches | ms/batch 12.34 | loss 459.7574\n",
            "| epoch  17 | 24000/116677 batches | ms/batch 12.30 | loss 465.1072\n",
            "| epoch  17 | 25000/116677 batches | ms/batch 12.74 | loss 493.4058\n",
            "| epoch  17 | 26000/116677 batches | ms/batch 12.72 | loss 490.4009\n",
            "| epoch  17 | 27000/116677 batches | ms/batch 12.02 | loss 442.7076\n",
            "| epoch  17 | 28000/116677 batches | ms/batch 11.99 | loss 441.9625\n",
            "| epoch  17 | 29000/116677 batches | ms/batch 12.38 | loss 458.4988\n",
            "| epoch  17 | 30000/116677 batches | ms/batch 13.01 | loss 511.9032\n",
            "| epoch  17 | 31000/116677 batches | ms/batch 11.74 | loss 429.6367\n",
            "| epoch  17 | 32000/116677 batches | ms/batch 13.05 | loss 514.5249\n",
            "| epoch  17 | 33000/116677 batches | ms/batch 12.24 | loss 459.4819\n",
            "| epoch  17 | 34000/116677 batches | ms/batch 11.90 | loss 435.2992\n",
            "| epoch  17 | 35000/116677 batches | ms/batch 12.62 | loss 486.1892\n",
            "| epoch  17 | 36000/116677 batches | ms/batch 12.39 | loss 467.6129\n",
            "| epoch  17 | 37000/116677 batches | ms/batch 12.49 | loss 480.0098\n",
            "| epoch  17 | 38000/116677 batches | ms/batch 11.64 | loss 421.1428\n",
            "| epoch  17 | 39000/116677 batches | ms/batch 12.46 | loss 475.4449\n",
            "| epoch  17 | 40000/116677 batches | ms/batch 11.97 | loss 437.9208\n",
            "| epoch  17 | 41000/116677 batches | ms/batch 12.29 | loss 461.0807\n",
            "| epoch  17 | 42000/116677 batches | ms/batch 11.79 | loss 427.7649\n",
            "| epoch  17 | 43000/116677 batches | ms/batch 12.60 | loss 481.5583\n",
            "| epoch  17 | 44000/116677 batches | ms/batch 13.36 | loss 544.2160\n",
            "| epoch  17 | 45000/116677 batches | ms/batch 12.90 | loss 505.1670\n",
            "| epoch  17 | 46000/116677 batches | ms/batch 12.04 | loss 448.0568\n",
            "| epoch  17 | 47000/116677 batches | ms/batch 11.53 | loss 411.3866\n",
            "| epoch  17 | 48000/116677 batches | ms/batch 12.60 | loss 481.3841\n",
            "| epoch  17 | 49000/116677 batches | ms/batch 13.18 | loss 525.8138\n",
            "| epoch  17 | 50000/116677 batches | ms/batch 12.25 | loss 461.7827\n",
            "| epoch  17 | 51000/116677 batches | ms/batch 12.46 | loss 474.8289\n",
            "| epoch  17 | 52000/116677 batches | ms/batch 11.85 | loss 433.7891\n",
            "| epoch  17 | 53000/116677 batches | ms/batch 12.02 | loss 443.1918\n",
            "| epoch  17 | 54000/116677 batches | ms/batch 12.47 | loss 466.9339\n",
            "| epoch  17 | 55000/116677 batches | ms/batch 12.29 | loss 457.0537\n",
            "| epoch  17 | 56000/116677 batches | ms/batch 12.29 | loss 459.8849\n",
            "| epoch  17 | 57000/116677 batches | ms/batch 12.41 | loss 474.9911\n",
            "| epoch  17 | 58000/116677 batches | ms/batch 12.66 | loss 491.1272\n",
            "| epoch  17 | 59000/116677 batches | ms/batch 12.15 | loss 456.7750\n",
            "| epoch  17 | 60000/116677 batches | ms/batch 12.31 | loss 465.5703\n",
            "| epoch  17 | 61000/116677 batches | ms/batch 12.21 | loss 460.7033\n",
            "| epoch  17 | 62000/116677 batches | ms/batch 12.92 | loss 500.0907\n",
            "| epoch  17 | 63000/116677 batches | ms/batch 12.41 | loss 470.0858\n",
            "| epoch  17 | 64000/116677 batches | ms/batch 12.42 | loss 472.2162\n",
            "| epoch  17 | 65000/116677 batches | ms/batch 12.71 | loss 496.1997\n",
            "| epoch  17 | 66000/116677 batches | ms/batch 12.27 | loss 468.9432\n",
            "| epoch  17 | 67000/116677 batches | ms/batch 12.61 | loss 485.5244\n",
            "| epoch  17 | 68000/116677 batches | ms/batch 12.08 | loss 442.3241\n",
            "| epoch  17 | 69000/116677 batches | ms/batch 12.18 | loss 454.5597\n",
            "| epoch  17 | 70000/116677 batches | ms/batch 12.63 | loss 484.2166\n",
            "| epoch  17 | 71000/116677 batches | ms/batch 12.35 | loss 465.9196\n",
            "| epoch  17 | 72000/116677 batches | ms/batch 12.06 | loss 448.6652\n",
            "| epoch  17 | 73000/116677 batches | ms/batch 11.89 | loss 431.3526\n",
            "| epoch  17 | 74000/116677 batches | ms/batch 11.46 | loss 404.8956\n",
            "| epoch  17 | 75000/116677 batches | ms/batch 12.47 | loss 475.5994\n",
            "| epoch  17 | 76000/116677 batches | ms/batch 12.21 | loss 460.7514\n",
            "| epoch  17 | 77000/116677 batches | ms/batch 12.27 | loss 460.4860\n",
            "| epoch  17 | 78000/116677 batches | ms/batch 12.46 | loss 476.2506\n",
            "| epoch  17 | 79000/116677 batches | ms/batch 12.00 | loss 435.3092\n",
            "| epoch  17 | 80000/116677 batches | ms/batch 12.33 | loss 455.6953\n",
            "| epoch  17 | 81000/116677 batches | ms/batch 12.10 | loss 447.5659\n",
            "| epoch  17 | 82000/116677 batches | ms/batch 12.86 | loss 502.5586\n",
            "| epoch  17 | 83000/116677 batches | ms/batch 11.97 | loss 441.7558\n",
            "| epoch  17 | 84000/116677 batches | ms/batch 12.37 | loss 463.0200\n",
            "| epoch  17 | 85000/116677 batches | ms/batch 12.20 | loss 458.2161\n",
            "| epoch  17 | 86000/116677 batches | ms/batch 12.18 | loss 454.8006\n",
            "| epoch  17 | 87000/116677 batches | ms/batch 12.32 | loss 466.3297\n",
            "| epoch  17 | 88000/116677 batches | ms/batch 12.37 | loss 466.3474\n",
            "| epoch  17 | 89000/116677 batches | ms/batch 12.36 | loss 469.1090\n",
            "| epoch  17 | 90000/116677 batches | ms/batch 12.90 | loss 503.5002\n",
            "| epoch  17 | 91000/116677 batches | ms/batch 12.52 | loss 484.7833\n",
            "| epoch  17 | 92000/116677 batches | ms/batch 12.29 | loss 466.1546\n",
            "| epoch  17 | 93000/116677 batches | ms/batch 12.45 | loss 479.7858\n",
            "| epoch  17 | 94000/116677 batches | ms/batch 12.71 | loss 493.8639\n",
            "| epoch  17 | 95000/116677 batches | ms/batch 12.66 | loss 491.7746\n",
            "| epoch  17 | 96000/116677 batches | ms/batch 12.43 | loss 470.1725\n",
            "| epoch  17 | 97000/116677 batches | ms/batch 12.48 | loss 476.5887\n",
            "| epoch  17 | 98000/116677 batches | ms/batch 12.84 | loss 505.4227\n",
            "| epoch  17 | 99000/116677 batches | ms/batch 12.65 | loss 491.7732\n",
            "| epoch  17 | 100000/116677 batches | ms/batch 13.23 | loss 529.7910\n",
            "| epoch  17 | 101000/116677 batches | ms/batch 12.29 | loss 459.5636\n",
            "| epoch  17 | 102000/116677 batches | ms/batch 12.14 | loss 449.4505\n",
            "| epoch  17 | 103000/116677 batches | ms/batch 12.42 | loss 470.3863\n",
            "| epoch  17 | 104000/116677 batches | ms/batch 12.49 | loss 467.0304\n",
            "| epoch  17 | 105000/116677 batches | ms/batch 12.72 | loss 476.4373\n",
            "| epoch  17 | 106000/116677 batches | ms/batch 11.88 | loss 426.1044\n",
            "| epoch  17 | 107000/116677 batches | ms/batch 12.56 | loss 469.7196\n",
            "| epoch  17 | 108000/116677 batches | ms/batch 13.12 | loss 511.8462\n",
            "| epoch  17 | 109000/116677 batches | ms/batch 12.34 | loss 464.5399\n",
            "| epoch  17 | 110000/116677 batches | ms/batch 12.60 | loss 479.1340\n",
            "| epoch  17 | 111000/116677 batches | ms/batch 12.21 | loss 450.1079\n",
            "| epoch  17 | 112000/116677 batches | ms/batch 12.71 | loss 488.0766\n",
            "| epoch  17 | 113000/116677 batches | ms/batch 12.96 | loss 496.4521\n",
            "| epoch  17 | 114000/116677 batches | ms/batch 12.89 | loss 483.5045\n",
            "| epoch  17 | 115000/116677 batches | ms/batch 12.88 | loss 494.5363\n",
            "| epoch  17 | 116000/116677 batches | ms/batch 12.43 | loss 457.7770\n",
            "| epoch  17 | 116677/116677 batches | ms/batch 12.50 | loss 464.1612\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 1518.13s | loss = 388.7774 | NDCG@10 = 15.8552 | Rec@10 = 13.6711 | Prec@10 = 11.35 | NDCG@100 = 27.2765 | Rec@100 = 49.8334 | Prec@100 = 5.365 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 1518.13s | loss = 361.2135 | NDCG@10 = 14.8307 | Rec@10 = 13.1617 | Prec@10 = 11.035 | NDCG@100 = 26.6573 | Rec@100 = 48.7959 | Prec@100 = 5.154 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |  1000/116677 batches | ms/batch 12.13 | loss 440.8658\n",
            "| epoch  18 |  2000/116677 batches | ms/batch 12.80 | loss 492.3155\n",
            "| epoch  18 |  3000/116677 batches | ms/batch 12.35 | loss 448.5603\n",
            "| epoch  18 |  4000/116677 batches | ms/batch 12.47 | loss 455.7898\n",
            "| epoch  18 |  5000/116677 batches | ms/batch 12.37 | loss 453.9398\n",
            "| epoch  18 |  6000/116677 batches | ms/batch 12.46 | loss 455.5821\n",
            "| epoch  18 |  7000/116677 batches | ms/batch 13.26 | loss 498.2182\n",
            "| epoch  18 |  8000/116677 batches | ms/batch 12.40 | loss 454.7709\n",
            "| epoch  18 |  9000/116677 batches | ms/batch 13.07 | loss 504.9930\n",
            "| epoch  18 | 10000/116677 batches | ms/batch 13.26 | loss 512.9010\n",
            "| epoch  18 | 11000/116677 batches | ms/batch 12.71 | loss 481.0533\n",
            "| epoch  18 | 12000/116677 batches | ms/batch 12.04 | loss 427.2645\n",
            "| epoch  18 | 13000/116677 batches | ms/batch 12.37 | loss 448.6404\n",
            "| epoch  18 | 14000/116677 batches | ms/batch 12.89 | loss 489.1963\n",
            "| epoch  18 | 15000/116677 batches | ms/batch 12.20 | loss 443.4577\n",
            "| epoch  18 | 16000/116677 batches | ms/batch 12.47 | loss 460.0250\n",
            "| epoch  18 | 17000/116677 batches | ms/batch 12.68 | loss 468.9405\n",
            "| epoch  18 | 18000/116677 batches | ms/batch 12.12 | loss 438.2540\n",
            "| epoch  18 | 19000/116677 batches | ms/batch 12.20 | loss 439.2881\n",
            "| epoch  18 | 20000/116677 batches | ms/batch 12.29 | loss 451.5296\n",
            "| epoch  18 | 21000/116677 batches | ms/batch 13.13 | loss 497.3861\n",
            "| epoch  18 | 22000/116677 batches | ms/batch 12.54 | loss 460.1225\n",
            "| epoch  18 | 23000/116677 batches | ms/batch 12.89 | loss 480.8499\n",
            "| epoch  18 | 24000/116677 batches | ms/batch 12.48 | loss 449.8746\n",
            "| epoch  18 | 25000/116677 batches | ms/batch 12.69 | loss 474.3516\n",
            "| epoch  18 | 26000/116677 batches | ms/batch 12.14 | loss 443.8657\n",
            "| epoch  18 | 27000/116677 batches | ms/batch 12.52 | loss 463.8332\n",
            "| epoch  18 | 28000/116677 batches | ms/batch 12.36 | loss 453.7886\n",
            "| epoch  18 | 29000/116677 batches | ms/batch 12.61 | loss 461.3200\n",
            "| epoch  18 | 30000/116677 batches | ms/batch 12.74 | loss 470.5224\n",
            "| epoch  18 | 31000/116677 batches | ms/batch 12.58 | loss 458.7995\n",
            "| epoch  18 | 32000/116677 batches | ms/batch 12.28 | loss 441.2382\n",
            "| epoch  18 | 33000/116677 batches | ms/batch 12.52 | loss 463.3884\n",
            "| epoch  18 | 34000/116677 batches | ms/batch 12.77 | loss 484.6346\n",
            "| epoch  18 | 35000/116677 batches | ms/batch 12.76 | loss 487.9152\n",
            "| epoch  18 | 36000/116677 batches | ms/batch 12.77 | loss 471.4595\n",
            "| epoch  18 | 37000/116677 batches | ms/batch 12.93 | loss 494.5892\n",
            "| epoch  18 | 38000/116677 batches | ms/batch 12.46 | loss 465.2079\n",
            "| epoch  18 | 39000/116677 batches | ms/batch 12.76 | loss 487.3983\n",
            "| epoch  18 | 40000/116677 batches | ms/batch 12.37 | loss 463.6860\n",
            "| epoch  18 | 41000/116677 batches | ms/batch 12.87 | loss 490.1812\n",
            "| epoch  18 | 42000/116677 batches | ms/batch 12.03 | loss 432.7163\n",
            "| epoch  18 | 43000/116677 batches | ms/batch 12.26 | loss 448.9449\n",
            "| epoch  18 | 44000/116677 batches | ms/batch 12.84 | loss 487.9969\n",
            "| epoch  18 | 45000/116677 batches | ms/batch 12.31 | loss 452.2087\n",
            "| epoch  18 | 46000/116677 batches | ms/batch 12.70 | loss 478.3347\n",
            "| epoch  18 | 47000/116677 batches | ms/batch 12.86 | loss 496.0394\n",
            "| epoch  18 | 48000/116677 batches | ms/batch 12.29 | loss 455.0598\n",
            "| epoch  18 | 49000/116677 batches | ms/batch 12.99 | loss 500.9893\n",
            "| epoch  18 | 50000/116677 batches | ms/batch 12.67 | loss 479.6134\n",
            "| epoch  18 | 51000/116677 batches | ms/batch 12.30 | loss 450.3210\n",
            "| epoch  18 | 52000/116677 batches | ms/batch 12.68 | loss 471.7070\n",
            "| epoch  18 | 53000/116677 batches | ms/batch 13.01 | loss 493.3763\n",
            "| epoch  18 | 54000/116677 batches | ms/batch 13.32 | loss 517.9675\n",
            "| epoch  18 | 55000/116677 batches | ms/batch 12.58 | loss 468.0854\n",
            "| epoch  18 | 56000/116677 batches | ms/batch 12.55 | loss 456.8562\n",
            "| epoch  18 | 57000/116677 batches | ms/batch 12.46 | loss 461.5820\n",
            "| epoch  18 | 58000/116677 batches | ms/batch 12.54 | loss 477.5254\n",
            "| epoch  18 | 59000/116677 batches | ms/batch 12.64 | loss 480.4866\n",
            "| epoch  18 | 60000/116677 batches | ms/batch 12.30 | loss 454.7448\n",
            "| epoch  18 | 61000/116677 batches | ms/batch 12.59 | loss 476.5208\n",
            "| epoch  18 | 62000/116677 batches | ms/batch 12.94 | loss 495.7076\n",
            "| epoch  18 | 63000/116677 batches | ms/batch 12.41 | loss 470.0060\n",
            "| epoch  18 | 64000/116677 batches | ms/batch 12.15 | loss 452.3419\n",
            "| epoch  18 | 65000/116677 batches | ms/batch 12.44 | loss 458.7543\n",
            "| epoch  18 | 66000/116677 batches | ms/batch 12.64 | loss 482.2581\n",
            "| epoch  18 | 67000/116677 batches | ms/batch 12.20 | loss 455.5078\n",
            "| epoch  18 | 68000/116677 batches | ms/batch 12.23 | loss 448.7573\n",
            "| epoch  18 | 69000/116677 batches | ms/batch 12.93 | loss 505.9510\n",
            "| epoch  18 | 70000/116677 batches | ms/batch 11.90 | loss 432.6312\n",
            "| epoch  18 | 71000/116677 batches | ms/batch 12.20 | loss 455.2776\n",
            "| epoch  18 | 72000/116677 batches | ms/batch 12.88 | loss 500.6021\n",
            "| epoch  18 | 73000/116677 batches | ms/batch 12.15 | loss 449.7223\n",
            "| epoch  18 | 74000/116677 batches | ms/batch 12.55 | loss 477.2539\n",
            "| epoch  18 | 75000/116677 batches | ms/batch 12.19 | loss 453.5678\n",
            "| epoch  18 | 76000/116677 batches | ms/batch 12.78 | loss 498.3585\n",
            "| epoch  18 | 77000/116677 batches | ms/batch 12.74 | loss 490.2328\n",
            "| epoch  18 | 78000/116677 batches | ms/batch 12.35 | loss 462.7738\n",
            "| epoch  18 | 79000/116677 batches | ms/batch 12.81 | loss 499.0290\n",
            "| epoch  18 | 80000/116677 batches | ms/batch 11.86 | loss 429.9433\n",
            "| epoch  18 | 81000/116677 batches | ms/batch 12.57 | loss 465.1920\n",
            "| epoch  18 | 82000/116677 batches | ms/batch 12.33 | loss 462.7838\n",
            "| epoch  18 | 83000/116677 batches | ms/batch 12.46 | loss 475.0675\n",
            "| epoch  18 | 84000/116677 batches | ms/batch 12.40 | loss 463.7863\n",
            "| epoch  18 | 85000/116677 batches | ms/batch 12.12 | loss 445.0796\n",
            "| epoch  18 | 86000/116677 batches | ms/batch 12.59 | loss 476.1772\n",
            "| epoch  18 | 87000/116677 batches | ms/batch 12.63 | loss 474.8139\n",
            "| epoch  18 | 88000/116677 batches | ms/batch 12.16 | loss 448.3553\n",
            "| epoch  18 | 89000/116677 batches | ms/batch 12.01 | loss 434.4996\n",
            "| epoch  18 | 90000/116677 batches | ms/batch 12.79 | loss 488.2180\n",
            "| epoch  18 | 91000/116677 batches | ms/batch 11.86 | loss 423.9135\n",
            "| epoch  18 | 92000/116677 batches | ms/batch 12.08 | loss 440.3864\n",
            "| epoch  18 | 93000/116677 batches | ms/batch 12.22 | loss 454.6454\n",
            "| epoch  18 | 94000/116677 batches | ms/batch 12.38 | loss 453.9945\n",
            "| epoch  18 | 95000/116677 batches | ms/batch 12.62 | loss 478.8001\n",
            "| epoch  18 | 96000/116677 batches | ms/batch 12.45 | loss 467.6992\n",
            "| epoch  18 | 97000/116677 batches | ms/batch 12.76 | loss 492.4746\n",
            "| epoch  18 | 98000/116677 batches | ms/batch 12.63 | loss 478.7932\n",
            "| epoch  18 | 99000/116677 batches | ms/batch 12.62 | loss 481.2650\n",
            "| epoch  18 | 100000/116677 batches | ms/batch 12.50 | loss 460.9651\n",
            "| epoch  18 | 101000/116677 batches | ms/batch 12.02 | loss 430.8862\n",
            "| epoch  18 | 102000/116677 batches | ms/batch 12.60 | loss 472.8330\n",
            "| epoch  18 | 103000/116677 batches | ms/batch 12.31 | loss 455.2830\n",
            "| epoch  18 | 104000/116677 batches | ms/batch 12.41 | loss 459.6908\n",
            "| epoch  18 | 105000/116677 batches | ms/batch 12.05 | loss 437.4869\n",
            "| epoch  18 | 106000/116677 batches | ms/batch 12.83 | loss 468.1364\n",
            "| epoch  18 | 107000/116677 batches | ms/batch 12.54 | loss 467.2478\n",
            "| epoch  18 | 108000/116677 batches | ms/batch 12.81 | loss 493.5222\n",
            "| epoch  18 | 109000/116677 batches | ms/batch 12.47 | loss 469.5047\n",
            "| epoch  18 | 110000/116677 batches | ms/batch 12.42 | loss 459.1982\n",
            "| epoch  18 | 111000/116677 batches | ms/batch 12.73 | loss 480.7131\n",
            "| epoch  18 | 112000/116677 batches | ms/batch 12.10 | loss 443.6139\n",
            "| epoch  18 | 113000/116677 batches | ms/batch 12.43 | loss 461.4380\n",
            "| epoch  18 | 114000/116677 batches | ms/batch 12.56 | loss 464.9088\n",
            "| epoch  18 | 115000/116677 batches | ms/batch 12.13 | loss 446.3429\n",
            "| epoch  18 | 116000/116677 batches | ms/batch 13.28 | loss 513.6870\n",
            "| epoch  18 | 116677/116677 batches | ms/batch 12.35 | loss 454.3724\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 1534.15s | loss = 388.7243 | NDCG@10 = 15.2976 | Rec@10 = 13.3557 | Prec@10 = 11.05 | NDCG@100 = 27.022 | Rec@100 = 50.615 | Prec@100 = 5.435 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 1534.15s | loss = 361.2215 | NDCG@10 = 15.2059 | Rec@10 = 13.533 | Prec@10 = 11.41 | NDCG@100 = 27.076 | Rec@100 = 49.327 | Prec@100 = 5.2681 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |  1000/116677 batches | ms/batch 12.54 | loss 464.0776\n",
            "| epoch  19 |  2000/116677 batches | ms/batch 12.83 | loss 482.5761\n",
            "| epoch  19 |  3000/116677 batches | ms/batch 12.34 | loss 444.8563\n",
            "| epoch  19 |  4000/116677 batches | ms/batch 13.01 | loss 488.2935\n",
            "| epoch  19 |  5000/116677 batches | ms/batch 12.48 | loss 457.8782\n",
            "| epoch  19 |  6000/116677 batches | ms/batch 12.05 | loss 427.4231\n",
            "| epoch  19 |  7000/116677 batches | ms/batch 12.58 | loss 465.6508\n",
            "| epoch  19 |  8000/116677 batches | ms/batch 12.20 | loss 432.1046\n",
            "| epoch  19 |  9000/116677 batches | ms/batch 12.39 | loss 458.9862\n",
            "| epoch  19 | 10000/116677 batches | ms/batch 12.34 | loss 446.0087\n",
            "| epoch  19 | 11000/116677 batches | ms/batch 12.83 | loss 490.6317\n",
            "| epoch  19 | 12000/116677 batches | ms/batch 12.56 | loss 468.4509\n",
            "| epoch  19 | 13000/116677 batches | ms/batch 12.34 | loss 455.2442\n",
            "| epoch  19 | 14000/116677 batches | ms/batch 12.08 | loss 431.2424\n",
            "| epoch  19 | 15000/116677 batches | ms/batch 13.14 | loss 499.7326\n",
            "| epoch  19 | 16000/116677 batches | ms/batch 13.32 | loss 503.7780\n",
            "| epoch  19 | 17000/116677 batches | ms/batch 12.56 | loss 458.5830\n",
            "| epoch  19 | 18000/116677 batches | ms/batch 12.81 | loss 481.7059\n",
            "| epoch  19 | 19000/116677 batches | ms/batch 12.28 | loss 446.4876\n",
            "| epoch  19 | 20000/116677 batches | ms/batch 12.63 | loss 466.4805\n",
            "| epoch  19 | 21000/116677 batches | ms/batch 12.43 | loss 460.4387\n",
            "| epoch  19 | 22000/116677 batches | ms/batch 12.55 | loss 467.8887\n",
            "| epoch  19 | 23000/116677 batches | ms/batch 12.73 | loss 481.6973\n",
            "| epoch  19 | 24000/116677 batches | ms/batch 12.15 | loss 445.0453\n",
            "| epoch  19 | 25000/116677 batches | ms/batch 12.26 | loss 444.6439\n",
            "| epoch  19 | 26000/116677 batches | ms/batch 12.68 | loss 473.6747\n",
            "| epoch  19 | 27000/116677 batches | ms/batch 12.36 | loss 459.7816\n",
            "| epoch  19 | 28000/116677 batches | ms/batch 12.41 | loss 462.0922\n",
            "| epoch  19 | 29000/116677 batches | ms/batch 12.56 | loss 466.3597\n",
            "| epoch  19 | 30000/116677 batches | ms/batch 12.38 | loss 462.5488\n",
            "| epoch  19 | 31000/116677 batches | ms/batch 11.92 | loss 424.3448\n",
            "| epoch  19 | 32000/116677 batches | ms/batch 12.14 | loss 441.4765\n",
            "| epoch  19 | 33000/116677 batches | ms/batch 12.88 | loss 484.8730\n",
            "| epoch  19 | 34000/116677 batches | ms/batch 13.29 | loss 535.7987\n",
            "| epoch  19 | 35000/116677 batches | ms/batch 12.73 | loss 490.2671\n",
            "| epoch  19 | 36000/116677 batches | ms/batch 13.06 | loss 507.6501\n",
            "| epoch  19 | 37000/116677 batches | ms/batch 12.16 | loss 454.4641\n",
            "| epoch  19 | 38000/116677 batches | ms/batch 12.31 | loss 459.8698\n",
            "| epoch  19 | 39000/116677 batches | ms/batch 12.45 | loss 469.2500\n",
            "| epoch  19 | 40000/116677 batches | ms/batch 13.01 | loss 503.3092\n",
            "| epoch  19 | 41000/116677 batches | ms/batch 12.32 | loss 458.1450\n",
            "| epoch  19 | 42000/116677 batches | ms/batch 12.53 | loss 463.4424\n",
            "| epoch  19 | 43000/116677 batches | ms/batch 13.30 | loss 526.3580\n",
            "| epoch  19 | 44000/116677 batches | ms/batch 12.59 | loss 479.5263\n",
            "| epoch  19 | 45000/116677 batches | ms/batch 12.73 | loss 486.4893\n",
            "| epoch  19 | 46000/116677 batches | ms/batch 11.87 | loss 428.7535\n",
            "| epoch  19 | 47000/116677 batches | ms/batch 12.51 | loss 474.1339\n",
            "| epoch  19 | 48000/116677 batches | ms/batch 12.86 | loss 489.7511\n",
            "| epoch  19 | 49000/116677 batches | ms/batch 12.77 | loss 484.4849\n",
            "| epoch  19 | 50000/116677 batches | ms/batch 12.74 | loss 480.9375\n",
            "| epoch  19 | 51000/116677 batches | ms/batch 12.67 | loss 481.4560\n",
            "| epoch  19 | 52000/116677 batches | ms/batch 12.62 | loss 480.2825\n",
            "| epoch  19 | 53000/116677 batches | ms/batch 12.22 | loss 451.5328\n",
            "| epoch  19 | 54000/116677 batches | ms/batch 12.22 | loss 449.5049\n",
            "| epoch  19 | 55000/116677 batches | ms/batch 12.21 | loss 444.2939\n",
            "| epoch  19 | 56000/116677 batches | ms/batch 12.02 | loss 440.7781\n",
            "| epoch  19 | 57000/116677 batches | ms/batch 12.97 | loss 497.7161\n",
            "| epoch  19 | 58000/116677 batches | ms/batch 11.96 | loss 414.1531\n",
            "| epoch  19 | 59000/116677 batches | ms/batch 12.80 | loss 464.1128\n",
            "| epoch  19 | 60000/116677 batches | ms/batch 12.74 | loss 475.2513\n",
            "| epoch  19 | 61000/116677 batches | ms/batch 13.69 | loss 519.5408\n",
            "| epoch  19 | 62000/116677 batches | ms/batch 12.80 | loss 469.6585\n",
            "| epoch  19 | 63000/116677 batches | ms/batch 12.81 | loss 482.4533\n",
            "| epoch  19 | 64000/116677 batches | ms/batch 12.25 | loss 438.4945\n",
            "| epoch  19 | 65000/116677 batches | ms/batch 12.39 | loss 449.9803\n",
            "| epoch  19 | 66000/116677 batches | ms/batch 11.46 | loss 389.1414\n",
            "| epoch  19 | 67000/116677 batches | ms/batch 12.50 | loss 457.6637\n",
            "| epoch  19 | 68000/116677 batches | ms/batch 12.80 | loss 474.1905\n",
            "| epoch  19 | 69000/116677 batches | ms/batch 12.88 | loss 487.5157\n",
            "| epoch  19 | 70000/116677 batches | ms/batch 12.51 | loss 463.6187\n",
            "| epoch  19 | 71000/116677 batches | ms/batch 12.54 | loss 472.5027\n",
            "| epoch  19 | 72000/116677 batches | ms/batch 12.27 | loss 445.8433\n",
            "| epoch  19 | 73000/116677 batches | ms/batch 12.41 | loss 454.2357\n",
            "| epoch  19 | 74000/116677 batches | ms/batch 12.44 | loss 451.9187\n",
            "| epoch  19 | 75000/116677 batches | ms/batch 12.44 | loss 457.2906\n",
            "| epoch  19 | 76000/116677 batches | ms/batch 12.40 | loss 453.8286\n",
            "| epoch  19 | 77000/116677 batches | ms/batch 12.08 | loss 433.4402\n",
            "| epoch  19 | 78000/116677 batches | ms/batch 12.71 | loss 481.5372\n",
            "| epoch  19 | 79000/116677 batches | ms/batch 11.96 | loss 429.5153\n",
            "| epoch  19 | 80000/116677 batches | ms/batch 13.03 | loss 506.6722\n",
            "| epoch  19 | 81000/116677 batches | ms/batch 12.34 | loss 456.9354\n",
            "| epoch  19 | 82000/116677 batches | ms/batch 12.07 | loss 428.5038\n",
            "| epoch  19 | 83000/116677 batches | ms/batch 13.02 | loss 498.7049\n",
            "| epoch  19 | 84000/116677 batches | ms/batch 12.86 | loss 489.0701\n",
            "| epoch  19 | 85000/116677 batches | ms/batch 12.87 | loss 497.3650\n",
            "| epoch  19 | 86000/116677 batches | ms/batch 12.82 | loss 499.3467\n",
            "| epoch  19 | 87000/116677 batches | ms/batch 12.87 | loss 488.7174\n",
            "| epoch  19 | 88000/116677 batches | ms/batch 12.24 | loss 441.8854\n",
            "| epoch  19 | 89000/116677 batches | ms/batch 11.98 | loss 422.2921\n",
            "| epoch  19 | 90000/116677 batches | ms/batch 13.07 | loss 509.8578\n",
            "| epoch  19 | 91000/116677 batches | ms/batch 13.18 | loss 485.2154\n",
            "| epoch  19 | 92000/116677 batches | ms/batch 13.40 | loss 521.1957\n",
            "| epoch  19 | 93000/116677 batches | ms/batch 13.29 | loss 508.2810\n",
            "| epoch  19 | 94000/116677 batches | ms/batch 12.45 | loss 460.1922\n",
            "| epoch  19 | 95000/116677 batches | ms/batch 12.56 | loss 470.4915\n",
            "| epoch  19 | 96000/116677 batches | ms/batch 13.13 | loss 508.8210\n",
            "| epoch  19 | 97000/116677 batches | ms/batch 12.41 | loss 466.1811\n",
            "| epoch  19 | 98000/116677 batches | ms/batch 12.17 | loss 444.7541\n",
            "| epoch  19 | 99000/116677 batches | ms/batch 12.54 | loss 468.9568\n",
            "| epoch  19 | 100000/116677 batches | ms/batch 12.15 | loss 442.9563\n",
            "| epoch  19 | 101000/116677 batches | ms/batch 12.27 | loss 454.1644\n",
            "| epoch  19 | 102000/116677 batches | ms/batch 11.94 | loss 431.7474\n",
            "| epoch  19 | 103000/116677 batches | ms/batch 12.07 | loss 445.8655\n",
            "| epoch  19 | 104000/116677 batches | ms/batch 12.32 | loss 457.1870\n",
            "| epoch  19 | 105000/116677 batches | ms/batch 12.34 | loss 456.3690\n",
            "| epoch  19 | 106000/116677 batches | ms/batch 12.27 | loss 447.9274\n",
            "| epoch  19 | 107000/116677 batches | ms/batch 13.04 | loss 493.2505\n",
            "| epoch  19 | 108000/116677 batches | ms/batch 13.04 | loss 503.8521\n",
            "| epoch  19 | 109000/116677 batches | ms/batch 12.66 | loss 484.2456\n",
            "| epoch  19 | 110000/116677 batches | ms/batch 13.07 | loss 505.7533\n",
            "| epoch  19 | 111000/116677 batches | ms/batch 11.81 | loss 421.8766\n",
            "| epoch  19 | 112000/116677 batches | ms/batch 12.46 | loss 460.6843\n",
            "| epoch  19 | 113000/116677 batches | ms/batch 12.35 | loss 447.4199\n",
            "| epoch  19 | 114000/116677 batches | ms/batch 11.85 | loss 420.1942\n",
            "| epoch  19 | 115000/116677 batches | ms/batch 13.15 | loss 518.5790\n",
            "| epoch  19 | 116000/116677 batches | ms/batch 12.12 | loss 449.1898\n",
            "| epoch  19 | 116677/116677 batches | ms/batch 12.67 | loss 480.6205\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 1537.44s | loss = 388.3149 | NDCG@10 = 15.883 | Rec@10 = 13.2352 | Prec@10 = 11.35 | NDCG@100 = 27.564 | Rec@100 = 50.2452 | Prec@100 = 5.38 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 1537.44s | loss = 361.1089 | NDCG@10 = 14.9165 | Rec@10 = 13.3911 | Prec@10 = 11.138 | NDCG@100 = 26.8192 | Rec@100 = 49.038 | Prec@100 = 5.1786 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |  1000/116677 batches | ms/batch 12.35 | loss 452.3351\n",
            "| epoch  20 |  2000/116677 batches | ms/batch 12.45 | loss 457.7059\n",
            "| epoch  20 |  3000/116677 batches | ms/batch 12.92 | loss 486.4272\n",
            "| epoch  20 |  4000/116677 batches | ms/batch 12.50 | loss 460.4194\n",
            "| epoch  20 |  5000/116677 batches | ms/batch 12.63 | loss 464.6498\n",
            "| epoch  20 |  6000/116677 batches | ms/batch 13.18 | loss 510.5273\n",
            "| epoch  20 |  7000/116677 batches | ms/batch 12.07 | loss 424.3178\n",
            "| epoch  20 |  8000/116677 batches | ms/batch 12.36 | loss 445.7627\n",
            "| epoch  20 |  9000/116677 batches | ms/batch 13.17 | loss 491.5317\n",
            "| epoch  20 | 10000/116677 batches | ms/batch 12.03 | loss 426.4520\n",
            "| epoch  20 | 11000/116677 batches | ms/batch 12.37 | loss 461.3478\n",
            "| epoch  20 | 12000/116677 batches | ms/batch 12.84 | loss 486.6161\n",
            "| epoch  20 | 13000/116677 batches | ms/batch 12.71 | loss 479.5502\n",
            "| epoch  20 | 14000/116677 batches | ms/batch 12.51 | loss 462.6613\n",
            "| epoch  20 | 15000/116677 batches | ms/batch 12.48 | loss 452.2797\n",
            "| epoch  20 | 16000/116677 batches | ms/batch 12.23 | loss 439.1530\n",
            "| epoch  20 | 17000/116677 batches | ms/batch 12.59 | loss 465.2132\n",
            "| epoch  20 | 18000/116677 batches | ms/batch 12.43 | loss 463.7669\n",
            "| epoch  20 | 19000/116677 batches | ms/batch 12.84 | loss 486.4777\n",
            "| epoch  20 | 20000/116677 batches | ms/batch 12.54 | loss 467.5133\n",
            "| epoch  20 | 21000/116677 batches | ms/batch 12.49 | loss 457.7693\n",
            "| epoch  20 | 22000/116677 batches | ms/batch 12.10 | loss 428.7473\n",
            "| epoch  20 | 23000/116677 batches | ms/batch 12.98 | loss 499.2140\n",
            "| epoch  20 | 24000/116677 batches | ms/batch 12.38 | loss 453.8867\n",
            "| epoch  20 | 25000/116677 batches | ms/batch 12.89 | loss 490.6679\n",
            "| epoch  20 | 26000/116677 batches | ms/batch 12.00 | loss 430.5070\n",
            "| epoch  20 | 27000/116677 batches | ms/batch 12.32 | loss 448.1362\n",
            "| epoch  20 | 28000/116677 batches | ms/batch 12.34 | loss 447.9585\n",
            "| epoch  20 | 29000/116677 batches | ms/batch 12.38 | loss 455.5363\n",
            "| epoch  20 | 30000/116677 batches | ms/batch 12.69 | loss 477.8102\n",
            "| epoch  20 | 31000/116677 batches | ms/batch 13.31 | loss 515.7612\n",
            "| epoch  20 | 32000/116677 batches | ms/batch 12.20 | loss 442.8613\n",
            "| epoch  20 | 33000/116677 batches | ms/batch 12.75 | loss 486.8563\n",
            "| epoch  20 | 34000/116677 batches | ms/batch 12.49 | loss 448.8536\n",
            "| epoch  20 | 35000/116677 batches | ms/batch 12.35 | loss 454.3376\n",
            "| epoch  20 | 36000/116677 batches | ms/batch 12.67 | loss 475.5256\n",
            "| epoch  20 | 37000/116677 batches | ms/batch 12.58 | loss 469.6406\n",
            "| epoch  20 | 38000/116677 batches | ms/batch 12.91 | loss 488.7099\n",
            "| epoch  20 | 39000/116677 batches | ms/batch 12.39 | loss 443.8011\n",
            "| epoch  20 | 40000/116677 batches | ms/batch 12.42 | loss 452.8238\n",
            "| epoch  20 | 41000/116677 batches | ms/batch 12.62 | loss 467.0991\n",
            "| epoch  20 | 42000/116677 batches | ms/batch 12.52 | loss 465.4457\n",
            "| epoch  20 | 43000/116677 batches | ms/batch 12.50 | loss 465.4388\n",
            "| epoch  20 | 44000/116677 batches | ms/batch 12.99 | loss 493.9012\n",
            "| epoch  20 | 45000/116677 batches | ms/batch 12.46 | loss 461.9088\n",
            "| epoch  20 | 46000/116677 batches | ms/batch 12.36 | loss 452.0947\n",
            "| epoch  20 | 47000/116677 batches | ms/batch 12.48 | loss 460.2979\n",
            "| epoch  20 | 48000/116677 batches | ms/batch 12.23 | loss 441.5598\n",
            "| epoch  20 | 49000/116677 batches | ms/batch 12.06 | loss 432.8038\n",
            "| epoch  20 | 50000/116677 batches | ms/batch 11.99 | loss 432.9998\n",
            "| epoch  20 | 51000/116677 batches | ms/batch 11.82 | loss 423.8852\n",
            "| epoch  20 | 52000/116677 batches | ms/batch 12.89 | loss 495.2188\n",
            "| epoch  20 | 53000/116677 batches | ms/batch 12.76 | loss 489.0718\n",
            "| epoch  20 | 54000/116677 batches | ms/batch 12.48 | loss 458.8298\n",
            "| epoch  20 | 55000/116677 batches | ms/batch 12.62 | loss 475.3707\n",
            "| epoch  20 | 56000/116677 batches | ms/batch 12.54 | loss 470.8272\n",
            "| epoch  20 | 57000/116677 batches | ms/batch 12.03 | loss 432.6824\n",
            "| epoch  20 | 58000/116677 batches | ms/batch 12.74 | loss 478.9011\n",
            "| epoch  20 | 59000/116677 batches | ms/batch 12.63 | loss 460.4040\n",
            "| epoch  20 | 60000/116677 batches | ms/batch 12.65 | loss 471.1747\n",
            "| epoch  20 | 61000/116677 batches | ms/batch 12.31 | loss 442.8344\n",
            "| epoch  20 | 62000/116677 batches | ms/batch 12.76 | loss 479.6575\n",
            "| epoch  20 | 63000/116677 batches | ms/batch 12.95 | loss 492.1399\n",
            "| epoch  20 | 64000/116677 batches | ms/batch 13.11 | loss 501.0725\n",
            "| epoch  20 | 65000/116677 batches | ms/batch 12.13 | loss 438.2401\n",
            "| epoch  20 | 66000/116677 batches | ms/batch 11.94 | loss 424.4191\n",
            "| epoch  20 | 67000/116677 batches | ms/batch 13.24 | loss 510.8336\n",
            "| epoch  20 | 68000/116677 batches | ms/batch 12.81 | loss 495.8690\n",
            "| epoch  20 | 69000/116677 batches | ms/batch 12.48 | loss 463.5624\n",
            "| epoch  20 | 70000/116677 batches | ms/batch 12.17 | loss 444.3595\n",
            "| epoch  20 | 71000/116677 batches | ms/batch 12.57 | loss 468.1187\n",
            "| epoch  20 | 72000/116677 batches | ms/batch 13.33 | loss 520.8763\n",
            "| epoch  20 | 73000/116677 batches | ms/batch 12.66 | loss 472.2452\n",
            "| epoch  20 | 74000/116677 batches | ms/batch 12.83 | loss 490.1205\n",
            "| epoch  20 | 75000/116677 batches | ms/batch 12.49 | loss 462.4592\n",
            "| epoch  20 | 76000/116677 batches | ms/batch 12.89 | loss 490.9169\n",
            "| epoch  20 | 77000/116677 batches | ms/batch 11.85 | loss 420.9498\n",
            "| epoch  20 | 78000/116677 batches | ms/batch 12.69 | loss 481.3182\n",
            "| epoch  20 | 79000/116677 batches | ms/batch 13.00 | loss 499.6299\n",
            "| epoch  20 | 80000/116677 batches | ms/batch 12.52 | loss 471.0501\n",
            "| epoch  20 | 81000/116677 batches | ms/batch 12.41 | loss 463.5776\n",
            "| epoch  20 | 82000/116677 batches | ms/batch 12.59 | loss 475.9665\n",
            "| epoch  20 | 83000/116677 batches | ms/batch 12.62 | loss 470.2699\n",
            "| epoch  20 | 84000/116677 batches | ms/batch 12.53 | loss 461.5497\n",
            "| epoch  20 | 85000/116677 batches | ms/batch 12.70 | loss 484.3728\n",
            "| epoch  20 | 86000/116677 batches | ms/batch 12.70 | loss 473.4397\n",
            "| epoch  20 | 87000/116677 batches | ms/batch 12.50 | loss 469.4197\n",
            "| epoch  20 | 88000/116677 batches | ms/batch 13.00 | loss 494.2921\n",
            "| epoch  20 | 89000/116677 batches | ms/batch 12.80 | loss 487.9066\n",
            "| epoch  20 | 90000/116677 batches | ms/batch 13.17 | loss 516.5900\n",
            "| epoch  20 | 91000/116677 batches | ms/batch 12.62 | loss 470.9270\n",
            "| epoch  20 | 92000/116677 batches | ms/batch 12.10 | loss 430.2054\n",
            "| epoch  20 | 93000/116677 batches | ms/batch 12.41 | loss 455.9107\n",
            "| epoch  20 | 94000/116677 batches | ms/batch 12.36 | loss 453.0567\n",
            "| epoch  20 | 95000/116677 batches | ms/batch 12.64 | loss 475.5122\n",
            "| epoch  20 | 96000/116677 batches | ms/batch 12.38 | loss 454.9974\n",
            "| epoch  20 | 97000/116677 batches | ms/batch 12.42 | loss 459.8333\n",
            "| epoch  20 | 98000/116677 batches | ms/batch 13.14 | loss 502.8925\n",
            "| epoch  20 | 99000/116677 batches | ms/batch 12.88 | loss 485.5260\n",
            "| epoch  20 | 100000/116677 batches | ms/batch 12.17 | loss 435.7916\n",
            "| epoch  20 | 101000/116677 batches | ms/batch 12.64 | loss 474.7641\n",
            "| epoch  20 | 102000/116677 batches | ms/batch 12.62 | loss 481.7970\n",
            "| epoch  20 | 103000/116677 batches | ms/batch 12.44 | loss 463.1253\n",
            "| epoch  20 | 104000/116677 batches | ms/batch 11.79 | loss 421.0154\n",
            "| epoch  20 | 105000/116677 batches | ms/batch 12.87 | loss 485.2756\n",
            "| epoch  20 | 106000/116677 batches | ms/batch 12.44 | loss 464.4175\n",
            "| epoch  20 | 107000/116677 batches | ms/batch 12.97 | loss 505.3239\n",
            "| epoch  20 | 108000/116677 batches | ms/batch 12.91 | loss 486.4781\n",
            "| epoch  20 | 109000/116677 batches | ms/batch 12.33 | loss 451.9657\n",
            "| epoch  20 | 110000/116677 batches | ms/batch 12.05 | loss 432.6077\n",
            "| epoch  20 | 111000/116677 batches | ms/batch 12.86 | loss 493.8323\n",
            "| epoch  20 | 112000/116677 batches | ms/batch 13.08 | loss 494.3315\n",
            "| epoch  20 | 113000/116677 batches | ms/batch 12.36 | loss 456.4570\n",
            "| epoch  20 | 114000/116677 batches | ms/batch 12.04 | loss 433.1748\n",
            "| epoch  20 | 115000/116677 batches | ms/batch 12.57 | loss 465.7265\n",
            "| epoch  20 | 116000/116677 batches | ms/batch 13.11 | loss 506.5367\n",
            "| epoch  20 | 116677/116677 batches | ms/batch 11.98 | loss 432.0595\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 1539.02s | loss = 389.1985 | NDCG@10 = 15.3265 | Rec@10 = 13.7717 | Prec@10 = 11.25 | NDCG@100 = 25.9516 | Rec@100 = 48.5774 | Prec@100 = 5.24 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 1539.02s | loss = 361.6257 | NDCG@10 = 14.8126 | Rec@10 = 13.2223 | Prec@10 = 10.927 | NDCG@100 = 26.6517 | Rec@100 = 48.7051 | Prec@100 = 5.1377 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  21 |  1000/116677 batches | ms/batch 12.88 | loss 487.6091\n",
            "| epoch  21 |  2000/116677 batches | ms/batch 12.67 | loss 468.6799\n",
            "| epoch  21 |  3000/116677 batches | ms/batch 13.24 | loss 516.3464\n",
            "| epoch  21 |  4000/116677 batches | ms/batch 12.95 | loss 491.0520\n",
            "| epoch  21 |  5000/116677 batches | ms/batch 12.87 | loss 493.0673\n",
            "| epoch  21 |  6000/116677 batches | ms/batch 12.14 | loss 436.9036\n",
            "| epoch  21 |  7000/116677 batches | ms/batch 12.32 | loss 452.9694\n",
            "| epoch  21 |  8000/116677 batches | ms/batch 12.68 | loss 477.2880\n",
            "| epoch  21 |  9000/116677 batches | ms/batch 12.35 | loss 451.1618\n",
            "| epoch  21 | 10000/116677 batches | ms/batch 13.07 | loss 495.1991\n",
            "| epoch  21 | 11000/116677 batches | ms/batch 12.22 | loss 443.4199\n",
            "| epoch  21 | 12000/116677 batches | ms/batch 12.03 | loss 430.9948\n",
            "| epoch  21 | 13000/116677 batches | ms/batch 12.98 | loss 497.9548\n",
            "| epoch  21 | 14000/116677 batches | ms/batch 13.14 | loss 501.6132\n",
            "| epoch  21 | 15000/116677 batches | ms/batch 12.83 | loss 492.4703\n",
            "| epoch  21 | 16000/116677 batches | ms/batch 12.80 | loss 487.3996\n",
            "| epoch  21 | 17000/116677 batches | ms/batch 12.93 | loss 491.6488\n",
            "| epoch  21 | 18000/116677 batches | ms/batch 12.45 | loss 465.1974\n",
            "| epoch  21 | 19000/116677 batches | ms/batch 12.31 | loss 445.2905\n",
            "| epoch  21 | 20000/116677 batches | ms/batch 13.08 | loss 496.7727\n",
            "| epoch  21 | 21000/116677 batches | ms/batch 12.85 | loss 476.8313\n",
            "| epoch  21 | 22000/116677 batches | ms/batch 11.94 | loss 424.7122\n",
            "| epoch  21 | 23000/116677 batches | ms/batch 12.20 | loss 438.1017\n",
            "| epoch  21 | 24000/116677 batches | ms/batch 12.68 | loss 478.5947\n",
            "| epoch  21 | 25000/116677 batches | ms/batch 12.51 | loss 461.3824\n",
            "| epoch  21 | 26000/116677 batches | ms/batch 11.73 | loss 406.3260\n",
            "| epoch  21 | 27000/116677 batches | ms/batch 12.53 | loss 462.3661\n",
            "| epoch  21 | 28000/116677 batches | ms/batch 12.56 | loss 463.3854\n",
            "| epoch  21 | 29000/116677 batches | ms/batch 12.28 | loss 446.9591\n",
            "| epoch  21 | 30000/116677 batches | ms/batch 12.41 | loss 454.8626\n",
            "| epoch  21 | 31000/116677 batches | ms/batch 12.58 | loss 472.3698\n",
            "| epoch  21 | 32000/116677 batches | ms/batch 13.12 | loss 512.0561\n",
            "| epoch  21 | 33000/116677 batches | ms/batch 12.38 | loss 459.3891\n",
            "| epoch  21 | 34000/116677 batches | ms/batch 12.55 | loss 462.1411\n",
            "| epoch  21 | 35000/116677 batches | ms/batch 13.12 | loss 496.3757\n",
            "| epoch  21 | 36000/116677 batches | ms/batch 12.33 | loss 454.1074\n",
            "| epoch  21 | 37000/116677 batches | ms/batch 12.32 | loss 444.7506\n",
            "| epoch  21 | 38000/116677 batches | ms/batch 12.45 | loss 448.5486\n",
            "| epoch  21 | 39000/116677 batches | ms/batch 13.48 | loss 527.0917\n",
            "| epoch  21 | 40000/116677 batches | ms/batch 12.46 | loss 447.8873\n",
            "| epoch  21 | 41000/116677 batches | ms/batch 12.71 | loss 480.5170\n",
            "| epoch  21 | 42000/116677 batches | ms/batch 12.11 | loss 440.9703\n",
            "| epoch  21 | 43000/116677 batches | ms/batch 12.49 | loss 466.9392\n",
            "| epoch  21 | 44000/116677 batches | ms/batch 13.06 | loss 496.5695\n",
            "| epoch  21 | 45000/116677 batches | ms/batch 12.44 | loss 460.5873\n",
            "| epoch  21 | 46000/116677 batches | ms/batch 12.25 | loss 441.8522\n",
            "| epoch  21 | 47000/116677 batches | ms/batch 12.89 | loss 490.0049\n",
            "| epoch  21 | 48000/116677 batches | ms/batch 12.28 | loss 449.2768\n",
            "| epoch  21 | 49000/116677 batches | ms/batch 12.59 | loss 471.3919\n",
            "| epoch  21 | 50000/116677 batches | ms/batch 12.38 | loss 458.0093\n",
            "| epoch  21 | 51000/116677 batches | ms/batch 12.56 | loss 462.7786\n",
            "| epoch  21 | 52000/116677 batches | ms/batch 12.96 | loss 487.4227\n",
            "| epoch  21 | 53000/116677 batches | ms/batch 12.25 | loss 442.0041\n",
            "| epoch  21 | 54000/116677 batches | ms/batch 12.28 | loss 448.1084\n",
            "| epoch  21 | 55000/116677 batches | ms/batch 12.28 | loss 455.2844\n",
            "| epoch  21 | 56000/116677 batches | ms/batch 12.30 | loss 451.8741\n",
            "| epoch  21 | 57000/116677 batches | ms/batch 13.02 | loss 503.6219\n",
            "| epoch  21 | 58000/116677 batches | ms/batch 12.20 | loss 448.5200\n",
            "| epoch  21 | 59000/116677 batches | ms/batch 13.20 | loss 501.8345\n",
            "| epoch  21 | 60000/116677 batches | ms/batch 12.47 | loss 458.8217\n",
            "| epoch  21 | 61000/116677 batches | ms/batch 12.55 | loss 467.4588\n",
            "| epoch  21 | 62000/116677 batches | ms/batch 12.88 | loss 484.3174\n",
            "| epoch  21 | 63000/116677 batches | ms/batch 12.55 | loss 467.8575\n",
            "| epoch  21 | 64000/116677 batches | ms/batch 12.39 | loss 457.1927\n",
            "| epoch  21 | 65000/116677 batches | ms/batch 12.44 | loss 467.2305\n",
            "| epoch  21 | 66000/116677 batches | ms/batch 12.76 | loss 484.4329\n",
            "| epoch  21 | 67000/116677 batches | ms/batch 12.57 | loss 475.2789\n",
            "| epoch  21 | 68000/116677 batches | ms/batch 12.66 | loss 477.3821\n",
            "| epoch  21 | 69000/116677 batches | ms/batch 12.19 | loss 444.1610\n",
            "| epoch  21 | 70000/116677 batches | ms/batch 13.24 | loss 518.2713\n",
            "| epoch  21 | 71000/116677 batches | ms/batch 12.66 | loss 476.6410\n",
            "| epoch  21 | 72000/116677 batches | ms/batch 12.61 | loss 461.7135\n",
            "| epoch  21 | 73000/116677 batches | ms/batch 12.23 | loss 445.3336\n",
            "| epoch  21 | 74000/116677 batches | ms/batch 12.38 | loss 456.4440\n",
            "| epoch  21 | 75000/116677 batches | ms/batch 12.55 | loss 465.0900\n",
            "| epoch  21 | 76000/116677 batches | ms/batch 12.77 | loss 487.5250\n",
            "| epoch  21 | 77000/116677 batches | ms/batch 12.90 | loss 494.8989\n",
            "| epoch  21 | 78000/116677 batches | ms/batch 12.60 | loss 472.1856\n",
            "| epoch  21 | 79000/116677 batches | ms/batch 12.21 | loss 442.6126\n",
            "| epoch  21 | 80000/116677 batches | ms/batch 12.43 | loss 462.7353\n",
            "| epoch  21 | 81000/116677 batches | ms/batch 12.90 | loss 501.3861\n",
            "| epoch  21 | 82000/116677 batches | ms/batch 12.11 | loss 446.0036\n",
            "| epoch  21 | 83000/116677 batches | ms/batch 12.24 | loss 446.4751\n",
            "| epoch  21 | 84000/116677 batches | ms/batch 12.24 | loss 439.7323\n",
            "| epoch  21 | 85000/116677 batches | ms/batch 12.44 | loss 453.0936\n",
            "| epoch  21 | 86000/116677 batches | ms/batch 12.22 | loss 449.6473\n",
            "| epoch  21 | 87000/116677 batches | ms/batch 12.74 | loss 478.3301\n",
            "| epoch  21 | 88000/116677 batches | ms/batch 12.64 | loss 471.2243\n",
            "| epoch  21 | 89000/116677 batches | ms/batch 12.80 | loss 485.7455\n",
            "| epoch  21 | 90000/116677 batches | ms/batch 12.42 | loss 464.3241\n",
            "| epoch  21 | 91000/116677 batches | ms/batch 12.00 | loss 427.5934\n",
            "| epoch  21 | 92000/116677 batches | ms/batch 12.38 | loss 458.6810\n",
            "| epoch  21 | 93000/116677 batches | ms/batch 12.77 | loss 487.1932\n",
            "| epoch  21 | 94000/116677 batches | ms/batch 12.32 | loss 455.5072\n",
            "| epoch  21 | 95000/116677 batches | ms/batch 12.55 | loss 471.5276\n",
            "| epoch  21 | 96000/116677 batches | ms/batch 12.27 | loss 447.0223\n",
            "| epoch  21 | 97000/116677 batches | ms/batch 12.33 | loss 450.8769\n",
            "| epoch  21 | 98000/116677 batches | ms/batch 12.63 | loss 465.9743\n",
            "| epoch  21 | 99000/116677 batches | ms/batch 12.39 | loss 457.4643\n",
            "| epoch  21 | 100000/116677 batches | ms/batch 12.56 | loss 468.1014\n",
            "| epoch  21 | 101000/116677 batches | ms/batch 12.51 | loss 467.0164\n",
            "| epoch  21 | 102000/116677 batches | ms/batch 12.48 | loss 461.6099\n",
            "| epoch  21 | 103000/116677 batches | ms/batch 12.70 | loss 478.8377\n",
            "| epoch  21 | 104000/116677 batches | ms/batch 12.52 | loss 462.0418\n",
            "| epoch  21 | 105000/116677 batches | ms/batch 13.02 | loss 499.9852\n",
            "| epoch  21 | 106000/116677 batches | ms/batch 11.85 | loss 421.3518\n",
            "| epoch  21 | 107000/116677 batches | ms/batch 13.02 | loss 501.9503\n",
            "| epoch  21 | 108000/116677 batches | ms/batch 12.47 | loss 463.8336\n",
            "| epoch  21 | 109000/116677 batches | ms/batch 12.32 | loss 438.5894\n",
            "| epoch  21 | 110000/116677 batches | ms/batch 12.12 | loss 437.3081\n",
            "| epoch  21 | 111000/116677 batches | ms/batch 12.84 | loss 483.5544\n",
            "| epoch  21 | 112000/116677 batches | ms/batch 12.43 | loss 461.6018\n",
            "| epoch  21 | 113000/116677 batches | ms/batch 11.84 | loss 425.1829\n",
            "| epoch  21 | 114000/116677 batches | ms/batch 12.44 | loss 465.5547\n",
            "| epoch  21 | 115000/116677 batches | ms/batch 12.62 | loss 475.7938\n",
            "| epoch  21 | 116000/116677 batches | ms/batch 12.84 | loss 496.0690\n",
            "| epoch  21 | 116677/116677 batches | ms/batch 12.90 | loss 485.8569\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 1537.92s | loss = 388.2619 | NDCG@10 = 15.0623 | Rec@10 = 13.502 | Prec@10 = 11.55 | NDCG@100 = 26.626 | Rec@100 = 50.1592 | Prec@100 = 5.5 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 1537.92s | loss = 360.7931 | NDCG@10 = 15.3196 | Rec@10 = 13.5913 | Prec@10 = 11.427 | NDCG@100 = 27.1603 | Rec@100 = 49.3903 | Prec@100 = 5.2511 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  22 |  1000/116677 batches | ms/batch 13.06 | loss 497.3605\n",
            "| epoch  22 |  2000/116677 batches | ms/batch 13.36 | loss 525.9272\n",
            "| epoch  22 |  3000/116677 batches | ms/batch 12.52 | loss 458.2713\n",
            "| epoch  22 |  4000/116677 batches | ms/batch 11.98 | loss 422.0023\n",
            "| epoch  22 |  5000/116677 batches | ms/batch 12.58 | loss 467.8094\n",
            "| epoch  22 |  6000/116677 batches | ms/batch 12.71 | loss 474.5450\n",
            "| epoch  22 |  7000/116677 batches | ms/batch 12.45 | loss 458.3398\n",
            "| epoch  22 |  8000/116677 batches | ms/batch 12.62 | loss 472.1479\n",
            "| epoch  22 |  9000/116677 batches | ms/batch 12.32 | loss 450.4738\n",
            "| epoch  22 | 10000/116677 batches | ms/batch 12.53 | loss 468.7224\n",
            "| epoch  22 | 11000/116677 batches | ms/batch 12.25 | loss 430.6492\n",
            "| epoch  22 | 12000/116677 batches | ms/batch 12.83 | loss 479.3739\n",
            "| epoch  22 | 13000/116677 batches | ms/batch 12.98 | loss 480.0954\n",
            "| epoch  22 | 14000/116677 batches | ms/batch 12.57 | loss 463.9565\n",
            "| epoch  22 | 15000/116677 batches | ms/batch 12.73 | loss 473.8725\n",
            "| epoch  22 | 16000/116677 batches | ms/batch 12.31 | loss 447.0029\n",
            "| epoch  22 | 17000/116677 batches | ms/batch 12.72 | loss 473.8354\n",
            "| epoch  22 | 18000/116677 batches | ms/batch 12.98 | loss 484.8409\n",
            "| epoch  22 | 19000/116677 batches | ms/batch 11.81 | loss 409.0976\n",
            "| epoch  22 | 20000/116677 batches | ms/batch 12.42 | loss 443.7826\n",
            "| epoch  22 | 21000/116677 batches | ms/batch 12.50 | loss 456.6292\n",
            "| epoch  22 | 22000/116677 batches | ms/batch 13.18 | loss 505.0469\n",
            "| epoch  22 | 23000/116677 batches | ms/batch 12.61 | loss 464.3837\n",
            "| epoch  22 | 24000/116677 batches | ms/batch 12.60 | loss 468.2631\n",
            "| epoch  22 | 25000/116677 batches | ms/batch 12.93 | loss 481.5213\n",
            "| epoch  22 | 26000/116677 batches | ms/batch 12.32 | loss 443.4047\n",
            "| epoch  22 | 27000/116677 batches | ms/batch 13.28 | loss 520.3237\n",
            "| epoch  22 | 28000/116677 batches | ms/batch 12.49 | loss 463.5240\n",
            "| epoch  22 | 29000/116677 batches | ms/batch 11.87 | loss 425.3173\n",
            "| epoch  22 | 30000/116677 batches | ms/batch 12.55 | loss 460.6707\n",
            "| epoch  22 | 31000/116677 batches | ms/batch 12.61 | loss 472.4454\n",
            "| epoch  22 | 32000/116677 batches | ms/batch 12.53 | loss 462.5989\n",
            "| epoch  22 | 33000/116677 batches | ms/batch 12.80 | loss 477.2292\n",
            "| epoch  22 | 34000/116677 batches | ms/batch 12.73 | loss 483.5753\n",
            "| epoch  22 | 35000/116677 batches | ms/batch 12.49 | loss 458.0164\n",
            "| epoch  22 | 36000/116677 batches | ms/batch 12.27 | loss 440.9951\n",
            "| epoch  22 | 37000/116677 batches | ms/batch 12.08 | loss 431.7099\n",
            "| epoch  22 | 38000/116677 batches | ms/batch 12.64 | loss 474.8287\n",
            "| epoch  22 | 39000/116677 batches | ms/batch 13.13 | loss 508.6157\n",
            "| epoch  22 | 40000/116677 batches | ms/batch 12.45 | loss 459.3715\n",
            "| epoch  22 | 41000/116677 batches | ms/batch 12.86 | loss 491.6011\n",
            "| epoch  22 | 42000/116677 batches | ms/batch 12.48 | loss 459.7058\n",
            "| epoch  22 | 43000/116677 batches | ms/batch 12.56 | loss 470.7805\n",
            "| epoch  22 | 44000/116677 batches | ms/batch 12.35 | loss 452.0543\n",
            "| epoch  22 | 45000/116677 batches | ms/batch 12.77 | loss 478.6550\n",
            "| epoch  22 | 46000/116677 batches | ms/batch 12.73 | loss 476.4985\n",
            "| epoch  22 | 47000/116677 batches | ms/batch 12.78 | loss 483.2176\n",
            "| epoch  22 | 48000/116677 batches | ms/batch 12.29 | loss 457.2422\n",
            "| epoch  22 | 49000/116677 batches | ms/batch 12.53 | loss 465.2016\n",
            "| epoch  22 | 50000/116677 batches | ms/batch 12.78 | loss 480.9945\n",
            "| epoch  22 | 51000/116677 batches | ms/batch 12.56 | loss 468.5666\n",
            "| epoch  22 | 52000/116677 batches | ms/batch 13.09 | loss 496.6543\n",
            "| epoch  22 | 53000/116677 batches | ms/batch 12.86 | loss 491.6328\n",
            "| epoch  22 | 54000/116677 batches | ms/batch 13.16 | loss 509.4626\n",
            "| epoch  22 | 55000/116677 batches | ms/batch 12.46 | loss 464.5126\n",
            "| epoch  22 | 56000/116677 batches | ms/batch 12.96 | loss 495.3866\n",
            "| epoch  22 | 57000/116677 batches | ms/batch 12.65 | loss 472.0695\n",
            "| epoch  22 | 58000/116677 batches | ms/batch 12.00 | loss 423.0954\n",
            "| epoch  22 | 59000/116677 batches | ms/batch 12.38 | loss 462.4312\n",
            "| epoch  22 | 60000/116677 batches | ms/batch 12.31 | loss 453.5980\n",
            "| epoch  22 | 61000/116677 batches | ms/batch 12.77 | loss 476.4106\n",
            "| epoch  22 | 62000/116677 batches | ms/batch 12.10 | loss 442.3125\n",
            "| epoch  22 | 63000/116677 batches | ms/batch 12.51 | loss 470.3982\n",
            "| epoch  22 | 64000/116677 batches | ms/batch 12.69 | loss 476.9605\n",
            "| epoch  22 | 65000/116677 batches | ms/batch 12.72 | loss 478.2344\n",
            "| epoch  22 | 66000/116677 batches | ms/batch 13.39 | loss 530.7397\n",
            "| epoch  22 | 67000/116677 batches | ms/batch 12.61 | loss 478.0819\n",
            "| epoch  22 | 68000/116677 batches | ms/batch 12.46 | loss 461.2364\n",
            "| epoch  22 | 69000/116677 batches | ms/batch 12.92 | loss 492.1636\n",
            "| epoch  22 | 70000/116677 batches | ms/batch 13.14 | loss 509.3956\n",
            "| epoch  22 | 71000/116677 batches | ms/batch 12.53 | loss 467.0128\n",
            "| epoch  22 | 72000/116677 batches | ms/batch 12.18 | loss 443.5424\n",
            "| epoch  22 | 73000/116677 batches | ms/batch 12.18 | loss 446.1226\n",
            "| epoch  22 | 74000/116677 batches | ms/batch 11.82 | loss 418.1840\n",
            "| epoch  22 | 75000/116677 batches | ms/batch 12.30 | loss 448.9507\n",
            "| epoch  22 | 76000/116677 batches | ms/batch 11.95 | loss 429.1991\n",
            "| epoch  22 | 77000/116677 batches | ms/batch 12.58 | loss 463.9723\n",
            "| epoch  22 | 78000/116677 batches | ms/batch 12.37 | loss 457.2026\n",
            "| epoch  22 | 79000/116677 batches | ms/batch 12.37 | loss 458.0498\n",
            "| epoch  22 | 80000/116677 batches | ms/batch 13.05 | loss 505.9916\n",
            "| epoch  22 | 81000/116677 batches | ms/batch 12.71 | loss 476.3412\n",
            "| epoch  22 | 82000/116677 batches | ms/batch 12.32 | loss 452.5377\n",
            "| epoch  22 | 83000/116677 batches | ms/batch 11.63 | loss 406.1893\n",
            "| epoch  22 | 84000/116677 batches | ms/batch 12.41 | loss 453.4559\n",
            "| epoch  22 | 85000/116677 batches | ms/batch 13.06 | loss 500.5490\n",
            "| epoch  22 | 86000/116677 batches | ms/batch 12.56 | loss 465.4088\n",
            "| epoch  22 | 87000/116677 batches | ms/batch 12.35 | loss 455.2618\n",
            "| epoch  22 | 88000/116677 batches | ms/batch 12.58 | loss 471.6726\n",
            "| epoch  22 | 89000/116677 batches | ms/batch 12.56 | loss 467.6321\n",
            "| epoch  22 | 90000/116677 batches | ms/batch 13.00 | loss 495.2986\n",
            "| epoch  22 | 91000/116677 batches | ms/batch 12.06 | loss 435.8951\n",
            "| epoch  22 | 92000/116677 batches | ms/batch 12.04 | loss 431.2666\n",
            "| epoch  22 | 93000/116677 batches | ms/batch 11.88 | loss 429.0325\n",
            "| epoch  22 | 94000/116677 batches | ms/batch 13.31 | loss 530.0764\n",
            "| epoch  22 | 95000/116677 batches | ms/batch 12.47 | loss 466.5007\n",
            "| epoch  22 | 96000/116677 batches | ms/batch 12.43 | loss 468.2778\n",
            "| epoch  22 | 97000/116677 batches | ms/batch 12.10 | loss 434.2504\n",
            "| epoch  22 | 98000/116677 batches | ms/batch 12.18 | loss 450.8752\n",
            "| epoch  22 | 99000/116677 batches | ms/batch 12.16 | loss 449.8212\n",
            "| epoch  22 | 100000/116677 batches | ms/batch 12.48 | loss 468.8807\n",
            "| epoch  22 | 101000/116677 batches | ms/batch 12.31 | loss 454.7439\n",
            "| epoch  22 | 102000/116677 batches | ms/batch 12.58 | loss 476.4576\n",
            "| epoch  22 | 103000/116677 batches | ms/batch 12.65 | loss 484.8354\n",
            "| epoch  22 | 104000/116677 batches | ms/batch 13.31 | loss 522.4169\n",
            "| epoch  22 | 105000/116677 batches | ms/batch 12.52 | loss 471.2657\n",
            "| epoch  22 | 106000/116677 batches | ms/batch 12.87 | loss 491.5141\n",
            "| epoch  22 | 107000/116677 batches | ms/batch 12.49 | loss 461.8235\n",
            "| epoch  22 | 108000/116677 batches | ms/batch 12.25 | loss 450.7913\n",
            "| epoch  22 | 109000/116677 batches | ms/batch 12.76 | loss 479.1864\n",
            "| epoch  22 | 110000/116677 batches | ms/batch 12.20 | loss 428.7983\n",
            "| epoch  22 | 111000/116677 batches | ms/batch 12.36 | loss 454.1220\n",
            "| epoch  22 | 112000/116677 batches | ms/batch 12.35 | loss 462.8364\n",
            "| epoch  22 | 113000/116677 batches | ms/batch 12.46 | loss 463.1929\n",
            "| epoch  22 | 114000/116677 batches | ms/batch 12.52 | loss 465.7107\n",
            "| epoch  22 | 115000/116677 batches | ms/batch 12.92 | loss 492.3797\n",
            "| epoch  22 | 116000/116677 batches | ms/batch 12.37 | loss 450.1194\n",
            "| epoch  22 | 116677/116677 batches | ms/batch 12.51 | loss 460.7545\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 1538.32s | loss = 389.3965 | NDCG@10 = 15.3951 | Rec@10 = 12.9813 | Prec@10 = 10.95 | NDCG@100 = 26.898 | Rec@100 = 50.407 | Prec@100 = 5.61 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 1538.32s | loss = 361.8526 | NDCG@10 = 14.9244 | Rec@10 = 13.2684 | Prec@10 = 11.182 | NDCG@100 = 26.8805 | Rec@100 = 49.0647 | Prec@100 = 5.258 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  23 |  1000/116677 batches | ms/batch 12.28 | loss 448.5886\n",
            "| epoch  23 |  2000/116677 batches | ms/batch 11.92 | loss 424.9592\n",
            "| epoch  23 |  3000/116677 batches | ms/batch 12.24 | loss 447.0772\n",
            "| epoch  23 |  4000/116677 batches | ms/batch 12.17 | loss 441.8029\n",
            "| epoch  23 |  5000/116677 batches | ms/batch 12.08 | loss 438.7838\n",
            "| epoch  23 |  6000/116677 batches | ms/batch 12.12 | loss 443.0522\n",
            "| epoch  23 |  7000/116677 batches | ms/batch 11.81 | loss 414.8340\n",
            "| epoch  23 |  8000/116677 batches | ms/batch 12.51 | loss 468.0465\n",
            "| epoch  23 |  9000/116677 batches | ms/batch 12.61 | loss 478.2796\n",
            "| epoch  23 | 10000/116677 batches | ms/batch 12.56 | loss 465.9911\n",
            "| epoch  23 | 11000/116677 batches | ms/batch 11.86 | loss 419.8387\n",
            "| epoch  23 | 12000/116677 batches | ms/batch 12.41 | loss 448.9203\n",
            "| epoch  23 | 13000/116677 batches | ms/batch 12.86 | loss 472.7006\n",
            "| epoch  23 | 14000/116677 batches | ms/batch 12.51 | loss 466.3075\n",
            "| epoch  23 | 15000/116677 batches | ms/batch 13.28 | loss 515.8886\n",
            "| epoch  23 | 16000/116677 batches | ms/batch 13.12 | loss 505.1154\n",
            "| epoch  23 | 17000/116677 batches | ms/batch 12.74 | loss 476.9309\n",
            "| epoch  23 | 18000/116677 batches | ms/batch 12.59 | loss 464.5598\n",
            "| epoch  23 | 19000/116677 batches | ms/batch 13.03 | loss 502.6042\n",
            "| epoch  23 | 20000/116677 batches | ms/batch 12.66 | loss 476.9262\n",
            "| epoch  23 | 21000/116677 batches | ms/batch 12.51 | loss 464.5607\n",
            "| epoch  23 | 22000/116677 batches | ms/batch 12.79 | loss 476.3149\n",
            "| epoch  23 | 23000/116677 batches | ms/batch 13.05 | loss 503.4766\n",
            "| epoch  23 | 24000/116677 batches | ms/batch 12.84 | loss 482.3171\n",
            "| epoch  23 | 25000/116677 batches | ms/batch 12.91 | loss 490.1980\n",
            "| epoch  23 | 26000/116677 batches | ms/batch 12.61 | loss 464.1848\n",
            "| epoch  23 | 27000/116677 batches | ms/batch 11.89 | loss 418.1866\n",
            "| epoch  23 | 28000/116677 batches | ms/batch 12.02 | loss 433.5662\n",
            "| epoch  23 | 29000/116677 batches | ms/batch 12.76 | loss 484.7687\n",
            "| epoch  23 | 30000/116677 batches | ms/batch 11.83 | loss 419.3171\n",
            "| epoch  23 | 31000/116677 batches | ms/batch 12.78 | loss 486.4185\n",
            "| epoch  23 | 32000/116677 batches | ms/batch 12.72 | loss 473.5250\n",
            "| epoch  23 | 33000/116677 batches | ms/batch 12.52 | loss 464.1441\n",
            "| epoch  23 | 34000/116677 batches | ms/batch 12.43 | loss 457.8582\n",
            "| epoch  23 | 35000/116677 batches | ms/batch 12.83 | loss 483.3441\n",
            "| epoch  23 | 36000/116677 batches | ms/batch 12.60 | loss 451.5460\n",
            "| epoch  23 | 37000/116677 batches | ms/batch 13.31 | loss 469.7372\n",
            "| epoch  23 | 38000/116677 batches | ms/batch 13.17 | loss 505.5465\n",
            "| epoch  23 | 39000/116677 batches | ms/batch 12.69 | loss 477.5510\n",
            "| epoch  23 | 40000/116677 batches | ms/batch 12.69 | loss 475.8838\n",
            "| epoch  23 | 41000/116677 batches | ms/batch 12.30 | loss 448.3521\n",
            "| epoch  23 | 42000/116677 batches | ms/batch 12.96 | loss 497.2816\n",
            "| epoch  23 | 43000/116677 batches | ms/batch 13.10 | loss 507.3732\n",
            "| epoch  23 | 44000/116677 batches | ms/batch 12.26 | loss 446.8478\n",
            "| epoch  23 | 45000/116677 batches | ms/batch 12.88 | loss 484.6324\n",
            "| epoch  23 | 46000/116677 batches | ms/batch 12.45 | loss 453.3054\n",
            "| epoch  23 | 47000/116677 batches | ms/batch 12.99 | loss 499.1862\n",
            "| epoch  23 | 48000/116677 batches | ms/batch 12.58 | loss 468.3440\n",
            "| epoch  23 | 49000/116677 batches | ms/batch 12.16 | loss 445.0322\n",
            "| epoch  23 | 50000/116677 batches | ms/batch 12.45 | loss 461.2657\n",
            "| epoch  23 | 51000/116677 batches | ms/batch 12.73 | loss 473.3505\n",
            "| epoch  23 | 52000/116677 batches | ms/batch 12.08 | loss 436.9757\n",
            "| epoch  23 | 53000/116677 batches | ms/batch 12.47 | loss 461.7798\n",
            "| epoch  23 | 54000/116677 batches | ms/batch 12.81 | loss 482.4476\n",
            "| epoch  23 | 55000/116677 batches | ms/batch 12.72 | loss 483.0966\n",
            "| epoch  23 | 56000/116677 batches | ms/batch 13.10 | loss 510.9715\n",
            "| epoch  23 | 57000/116677 batches | ms/batch 12.48 | loss 461.8739\n",
            "| epoch  23 | 58000/116677 batches | ms/batch 12.16 | loss 440.1561\n",
            "| epoch  23 | 59000/116677 batches | ms/batch 12.53 | loss 474.7548\n",
            "| epoch  23 | 60000/116677 batches | ms/batch 12.21 | loss 450.5607\n",
            "| epoch  23 | 61000/116677 batches | ms/batch 12.75 | loss 484.6334\n",
            "| epoch  23 | 62000/116677 batches | ms/batch 12.92 | loss 490.7904\n",
            "| epoch  23 | 63000/116677 batches | ms/batch 12.25 | loss 449.0213\n",
            "| epoch  23 | 64000/116677 batches | ms/batch 12.50 | loss 462.0125\n",
            "| epoch  23 | 65000/116677 batches | ms/batch 12.58 | loss 482.0601\n",
            "| epoch  23 | 66000/116677 batches | ms/batch 12.16 | loss 448.9637\n",
            "| epoch  23 | 67000/116677 batches | ms/batch 12.61 | loss 473.7095\n",
            "| epoch  23 | 68000/116677 batches | ms/batch 11.99 | loss 427.2097\n",
            "| epoch  23 | 69000/116677 batches | ms/batch 13.29 | loss 523.4510\n",
            "| epoch  23 | 70000/116677 batches | ms/batch 12.90 | loss 479.2235\n",
            "| epoch  23 | 71000/116677 batches | ms/batch 12.46 | loss 447.3762\n",
            "| epoch  23 | 72000/116677 batches | ms/batch 12.86 | loss 472.4051\n",
            "| epoch  23 | 73000/116677 batches | ms/batch 13.03 | loss 478.5307\n",
            "| epoch  23 | 74000/116677 batches | ms/batch 12.39 | loss 451.1361\n",
            "| epoch  23 | 75000/116677 batches | ms/batch 11.91 | loss 419.3160\n",
            "| epoch  23 | 76000/116677 batches | ms/batch 12.06 | loss 434.6507\n",
            "| epoch  23 | 77000/116677 batches | ms/batch 12.91 | loss 485.6132\n",
            "| epoch  23 | 78000/116677 batches | ms/batch 12.86 | loss 484.9216\n",
            "| epoch  23 | 79000/116677 batches | ms/batch 12.61 | loss 468.3614\n",
            "| epoch  23 | 80000/116677 batches | ms/batch 12.77 | loss 474.4155\n",
            "| epoch  23 | 81000/116677 batches | ms/batch 13.22 | loss 508.8576\n",
            "| epoch  23 | 82000/116677 batches | ms/batch 12.65 | loss 474.4266\n",
            "| epoch  23 | 83000/116677 batches | ms/batch 13.08 | loss 499.2088\n",
            "| epoch  23 | 84000/116677 batches | ms/batch 12.33 | loss 453.6845\n",
            "| epoch  23 | 85000/116677 batches | ms/batch 11.99 | loss 424.3229\n",
            "| epoch  23 | 86000/116677 batches | ms/batch 12.87 | loss 493.2612\n",
            "| epoch  23 | 87000/116677 batches | ms/batch 12.91 | loss 487.6330\n",
            "| epoch  23 | 88000/116677 batches | ms/batch 12.73 | loss 483.8737\n",
            "| epoch  23 | 89000/116677 batches | ms/batch 12.55 | loss 473.7447\n",
            "| epoch  23 | 90000/116677 batches | ms/batch 12.89 | loss 496.1908\n",
            "| epoch  23 | 91000/116677 batches | ms/batch 12.70 | loss 484.8470\n",
            "| epoch  23 | 92000/116677 batches | ms/batch 12.62 | loss 479.4022\n",
            "| epoch  23 | 93000/116677 batches | ms/batch 12.04 | loss 443.7681\n",
            "| epoch  23 | 94000/116677 batches | ms/batch 12.04 | loss 439.4337\n",
            "| epoch  23 | 95000/116677 batches | ms/batch 12.33 | loss 461.3021\n",
            "| epoch  23 | 96000/116677 batches | ms/batch 12.49 | loss 469.5432\n",
            "| epoch  23 | 97000/116677 batches | ms/batch 12.37 | loss 464.7303\n",
            "| epoch  23 | 98000/116677 batches | ms/batch 12.36 | loss 460.3367\n",
            "| epoch  23 | 99000/116677 batches | ms/batch 12.11 | loss 449.8176\n",
            "| epoch  23 | 100000/116677 batches | ms/batch 11.97 | loss 434.9960\n",
            "| epoch  23 | 101000/116677 batches | ms/batch 12.16 | loss 451.2391\n",
            "| epoch  23 | 102000/116677 batches | ms/batch 11.90 | loss 431.3438\n",
            "| epoch  23 | 103000/116677 batches | ms/batch 12.60 | loss 478.4977\n",
            "| epoch  23 | 104000/116677 batches | ms/batch 12.06 | loss 442.7571\n",
            "| epoch  23 | 105000/116677 batches | ms/batch 12.18 | loss 451.9974\n",
            "| epoch  23 | 106000/116677 batches | ms/batch 12.65 | loss 487.9160\n",
            "| epoch  23 | 107000/116677 batches | ms/batch 12.14 | loss 452.0863\n",
            "| epoch  23 | 108000/116677 batches | ms/batch 12.18 | loss 449.4272\n",
            "| epoch  23 | 109000/116677 batches | ms/batch 12.51 | loss 466.2580\n",
            "| epoch  23 | 110000/116677 batches | ms/batch 12.87 | loss 502.4686\n",
            "| epoch  23 | 111000/116677 batches | ms/batch 12.22 | loss 450.2370\n",
            "| epoch  23 | 112000/116677 batches | ms/batch 12.41 | loss 454.8021\n",
            "| epoch  23 | 113000/116677 batches | ms/batch 12.54 | loss 472.7099\n",
            "| epoch  23 | 114000/116677 batches | ms/batch 13.08 | loss 518.4818\n",
            "| epoch  23 | 115000/116677 batches | ms/batch 12.87 | loss 494.6477\n",
            "| epoch  23 | 116000/116677 batches | ms/batch 11.89 | loss 432.8962\n",
            "| epoch  23 | 116677/116677 batches | ms/batch 12.55 | loss 483.1035\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 1535.45s | loss = 388.967 | NDCG@10 = 17.2692 | Rec@10 = 14.718 | Prec@10 = 12.3 | NDCG@100 = 28.2234 | Rec@100 = 50.4857 | Prec@100 = 5.44 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 1535.45s | loss = 361.0312 | NDCG@10 = 15.3305 | Rec@10 = 13.7122 | Prec@10 = 11.274 | NDCG@100 = 27.1376 | Rec@100 = 49.1134 | Prec@100 = 5.2067 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  24 |  1000/116677 batches | ms/batch 12.53 | loss 468.7114\n",
            "| epoch  24 |  2000/116677 batches | ms/batch 12.17 | loss 447.8157\n",
            "| epoch  24 |  3000/116677 batches | ms/batch 11.93 | loss 424.5316\n",
            "| epoch  24 |  4000/116677 batches | ms/batch 12.12 | loss 440.8712\n",
            "| epoch  24 |  5000/116677 batches | ms/batch 13.11 | loss 512.8667\n",
            "| epoch  24 |  6000/116677 batches | ms/batch 13.19 | loss 511.1845\n",
            "| epoch  24 |  7000/116677 batches | ms/batch 11.84 | loss 425.1918\n",
            "| epoch  24 |  8000/116677 batches | ms/batch 12.06 | loss 437.1329\n",
            "| epoch  24 |  9000/116677 batches | ms/batch 11.94 | loss 437.1835\n",
            "| epoch  24 | 10000/116677 batches | ms/batch 11.90 | loss 430.6885\n",
            "| epoch  24 | 11000/116677 batches | ms/batch 13.15 | loss 515.5712\n",
            "| epoch  24 | 12000/116677 batches | ms/batch 11.77 | loss 416.5633\n",
            "| epoch  24 | 13000/116677 batches | ms/batch 12.11 | loss 442.0665\n",
            "| epoch  24 | 14000/116677 batches | ms/batch 12.15 | loss 440.5371\n",
            "| epoch  24 | 15000/116677 batches | ms/batch 12.27 | loss 450.5936\n",
            "| epoch  24 | 16000/116677 batches | ms/batch 12.43 | loss 468.3423\n",
            "| epoch  24 | 17000/116677 batches | ms/batch 12.54 | loss 476.3439\n",
            "| epoch  24 | 18000/116677 batches | ms/batch 12.10 | loss 448.7392\n",
            "| epoch  24 | 19000/116677 batches | ms/batch 12.20 | loss 451.8334\n",
            "| epoch  24 | 20000/116677 batches | ms/batch 11.88 | loss 429.9192\n",
            "| epoch  24 | 21000/116677 batches | ms/batch 12.40 | loss 469.4601\n",
            "| epoch  24 | 22000/116677 batches | ms/batch 12.10 | loss 449.1792\n",
            "| epoch  24 | 23000/116677 batches | ms/batch 11.94 | loss 434.9677\n",
            "| epoch  24 | 24000/116677 batches | ms/batch 12.74 | loss 492.4304\n",
            "| epoch  24 | 25000/116677 batches | ms/batch 12.91 | loss 502.6258\n",
            "| epoch  24 | 26000/116677 batches | ms/batch 12.32 | loss 461.8974\n",
            "| epoch  24 | 27000/116677 batches | ms/batch 12.32 | loss 467.3665\n",
            "| epoch  24 | 28000/116677 batches | ms/batch 13.23 | loss 523.4336\n",
            "| epoch  24 | 29000/116677 batches | ms/batch 11.94 | loss 434.6255\n",
            "| epoch  24 | 30000/116677 batches | ms/batch 12.62 | loss 488.3076\n",
            "| epoch  24 | 31000/116677 batches | ms/batch 12.55 | loss 479.3672\n",
            "| epoch  24 | 32000/116677 batches | ms/batch 12.75 | loss 492.3289\n",
            "| epoch  24 | 33000/116677 batches | ms/batch 12.58 | loss 476.7348\n",
            "| epoch  24 | 34000/116677 batches | ms/batch 12.02 | loss 439.8694\n",
            "| epoch  24 | 35000/116677 batches | ms/batch 12.70 | loss 489.0869\n",
            "| epoch  24 | 36000/116677 batches | ms/batch 11.72 | loss 420.8700\n",
            "| epoch  24 | 37000/116677 batches | ms/batch 12.52 | loss 482.1996\n",
            "| epoch  24 | 38000/116677 batches | ms/batch 11.93 | loss 433.7112\n",
            "| epoch  24 | 39000/116677 batches | ms/batch 12.52 | loss 461.8643\n",
            "| epoch  24 | 40000/116677 batches | ms/batch 12.18 | loss 442.5594\n",
            "| epoch  24 | 41000/116677 batches | ms/batch 12.42 | loss 470.5421\n",
            "| epoch  24 | 42000/116677 batches | ms/batch 12.99 | loss 508.9161\n",
            "| epoch  24 | 43000/116677 batches | ms/batch 12.68 | loss 494.1889\n",
            "| epoch  24 | 44000/116677 batches | ms/batch 12.34 | loss 456.4041\n",
            "| epoch  24 | 45000/116677 batches | ms/batch 11.83 | loss 422.8345\n",
            "| epoch  24 | 46000/116677 batches | ms/batch 12.23 | loss 455.3466\n",
            "| epoch  24 | 47000/116677 batches | ms/batch 12.40 | loss 470.5743\n",
            "| epoch  24 | 48000/116677 batches | ms/batch 12.33 | loss 464.0474\n",
            "| epoch  24 | 49000/116677 batches | ms/batch 12.66 | loss 487.2856\n",
            "| epoch  24 | 50000/116677 batches | ms/batch 12.17 | loss 453.4716\n",
            "| epoch  24 | 51000/116677 batches | ms/batch 12.46 | loss 476.5663\n",
            "| epoch  24 | 52000/116677 batches | ms/batch 12.12 | loss 448.7771\n",
            "| epoch  24 | 53000/116677 batches | ms/batch 12.26 | loss 457.5603\n",
            "| epoch  24 | 54000/116677 batches | ms/batch 12.21 | loss 457.5410\n",
            "| epoch  24 | 55000/116677 batches | ms/batch 12.35 | loss 467.3658\n",
            "| epoch  24 | 56000/116677 batches | ms/batch 13.12 | loss 522.1252\n",
            "| epoch  24 | 57000/116677 batches | ms/batch 11.83 | loss 430.4825\n",
            "| epoch  24 | 58000/116677 batches | ms/batch 12.18 | loss 454.1716\n",
            "| epoch  24 | 59000/116677 batches | ms/batch 12.10 | loss 450.0684\n",
            "| epoch  24 | 60000/116677 batches | ms/batch 11.77 | loss 428.6550\n",
            "| epoch  24 | 61000/116677 batches | ms/batch 12.22 | loss 455.1846\n",
            "| epoch  24 | 62000/116677 batches | ms/batch 12.12 | loss 453.8824\n",
            "| epoch  24 | 63000/116677 batches | ms/batch 12.41 | loss 470.0192\n",
            "| epoch  24 | 64000/116677 batches | ms/batch 12.42 | loss 464.8754\n",
            "| epoch  24 | 65000/116677 batches | ms/batch 12.40 | loss 460.7658\n",
            "| epoch  24 | 66000/116677 batches | ms/batch 12.24 | loss 459.4467\n",
            "| epoch  24 | 67000/116677 batches | ms/batch 12.57 | loss 485.3032\n",
            "| epoch  24 | 68000/116677 batches | ms/batch 12.73 | loss 494.6760\n",
            "| epoch  24 | 69000/116677 batches | ms/batch 12.17 | loss 455.7519\n",
            "| epoch  24 | 70000/116677 batches | ms/batch 12.14 | loss 449.3722\n",
            "| epoch  24 | 71000/116677 batches | ms/batch 12.55 | loss 476.8174\n",
            "| epoch  24 | 72000/116677 batches | ms/batch 12.28 | loss 464.3996\n",
            "| epoch  24 | 73000/116677 batches | ms/batch 12.77 | loss 495.3673\n",
            "| epoch  24 | 74000/116677 batches | ms/batch 12.52 | loss 474.0817\n",
            "| epoch  24 | 75000/116677 batches | ms/batch 12.28 | loss 463.2343\n",
            "| epoch  24 | 76000/116677 batches | ms/batch 12.05 | loss 448.6308\n",
            "| epoch  24 | 77000/116677 batches | ms/batch 12.01 | loss 443.5681\n",
            "| epoch  24 | 78000/116677 batches | ms/batch 12.85 | loss 500.0398\n",
            "| epoch  24 | 79000/116677 batches | ms/batch 12.03 | loss 449.8880\n",
            "| epoch  24 | 80000/116677 batches | ms/batch 12.54 | loss 479.7798\n",
            "| epoch  24 | 81000/116677 batches | ms/batch 13.31 | loss 537.2170\n",
            "| epoch  24 | 82000/116677 batches | ms/batch 12.31 | loss 464.8835\n",
            "| epoch  24 | 83000/116677 batches | ms/batch 12.33 | loss 463.9161\n",
            "| epoch  24 | 84000/116677 batches | ms/batch 13.01 | loss 511.0579\n",
            "| epoch  24 | 85000/116677 batches | ms/batch 12.85 | loss 498.9610\n",
            "| epoch  24 | 86000/116677 batches | ms/batch 12.65 | loss 488.9743\n",
            "| epoch  24 | 87000/116677 batches | ms/batch 12.32 | loss 465.9596\n",
            "| epoch  24 | 88000/116677 batches | ms/batch 13.27 | loss 529.3599\n",
            "| epoch  24 | 89000/116677 batches | ms/batch 12.34 | loss 458.5706\n",
            "| epoch  24 | 90000/116677 batches | ms/batch 12.31 | loss 456.2459\n",
            "| epoch  24 | 91000/116677 batches | ms/batch 12.66 | loss 493.6842\n",
            "| epoch  24 | 92000/116677 batches | ms/batch 12.28 | loss 451.8605\n",
            "| epoch  24 | 93000/116677 batches | ms/batch 12.43 | loss 473.7123\n",
            "| epoch  24 | 94000/116677 batches | ms/batch 12.02 | loss 445.3520\n",
            "| epoch  24 | 95000/116677 batches | ms/batch 12.71 | loss 484.5230\n",
            "| epoch  24 | 96000/116677 batches | ms/batch 12.23 | loss 458.4985\n",
            "| epoch  24 | 97000/116677 batches | ms/batch 13.10 | loss 513.1387\n",
            "| epoch  24 | 98000/116677 batches | ms/batch 12.76 | loss 497.3362\n",
            "| epoch  24 | 99000/116677 batches | ms/batch 12.40 | loss 473.0776\n",
            "| epoch  24 | 100000/116677 batches | ms/batch 12.38 | loss 462.3212\n",
            "| epoch  24 | 101000/116677 batches | ms/batch 12.17 | loss 454.1999\n",
            "| epoch  24 | 102000/116677 batches | ms/batch 12.61 | loss 480.2721\n",
            "| epoch  24 | 103000/116677 batches | ms/batch 12.32 | loss 461.9885\n",
            "| epoch  24 | 104000/116677 batches | ms/batch 12.15 | loss 455.3373\n",
            "| epoch  24 | 105000/116677 batches | ms/batch 12.58 | loss 489.0596\n",
            "| epoch  24 | 106000/116677 batches | ms/batch 13.02 | loss 513.8792\n",
            "| epoch  24 | 107000/116677 batches | ms/batch 11.73 | loss 422.9106\n",
            "| epoch  24 | 108000/116677 batches | ms/batch 12.43 | loss 471.7797\n",
            "| epoch  24 | 109000/116677 batches | ms/batch 12.28 | loss 457.9338\n",
            "| epoch  24 | 110000/116677 batches | ms/batch 12.40 | loss 461.1362\n",
            "| epoch  24 | 111000/116677 batches | ms/batch 12.45 | loss 472.7773\n",
            "| epoch  24 | 112000/116677 batches | ms/batch 11.84 | loss 428.3748\n",
            "| epoch  24 | 113000/116677 batches | ms/batch 12.28 | loss 461.7495\n",
            "| epoch  24 | 114000/116677 batches | ms/batch 13.09 | loss 513.7582\n",
            "| epoch  24 | 115000/116677 batches | ms/batch 12.59 | loss 475.8241\n",
            "| epoch  24 | 116000/116677 batches | ms/batch 12.21 | loss 447.3498\n",
            "| epoch  24 | 116677/116677 batches | ms/batch 12.83 | loss 498.7211\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 1518.50s | loss = 388.3789 | NDCG@10 = 15.6551 | Rec@10 = 13.1703 | Prec@10 = 11.35 | NDCG@100 = 26.8242 | Rec@100 = 49.9614 | Prec@100 = 5.38 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 1518.50s | loss = 361.1194 | NDCG@10 = 14.7974 | Rec@10 = 13.3108 | Prec@10 = 11.087 | NDCG@100 = 26.7419 | Rec@100 = 49.1322 | Prec@100 = 5.1836 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  25 |  1000/116677 batches | ms/batch 12.19 | loss 441.0165\n",
            "| epoch  25 |  2000/116677 batches | ms/batch 12.07 | loss 431.9478\n",
            "| epoch  25 |  3000/116677 batches | ms/batch 12.39 | loss 460.6323\n",
            "| epoch  25 |  4000/116677 batches | ms/batch 12.64 | loss 472.5897\n",
            "| epoch  25 |  5000/116677 batches | ms/batch 12.18 | loss 440.7030\n",
            "| epoch  25 |  6000/116677 batches | ms/batch 12.78 | loss 485.3309\n",
            "| epoch  25 |  7000/116677 batches | ms/batch 12.36 | loss 458.4433\n",
            "| epoch  25 |  8000/116677 batches | ms/batch 12.82 | loss 491.5656\n",
            "| epoch  25 |  9000/116677 batches | ms/batch 12.14 | loss 441.0131\n",
            "| epoch  25 | 10000/116677 batches | ms/batch 12.70 | loss 478.2575\n",
            "| epoch  25 | 11000/116677 batches | ms/batch 12.96 | loss 500.4077\n",
            "| epoch  25 | 12000/116677 batches | ms/batch 12.09 | loss 433.4610\n",
            "| epoch  25 | 13000/116677 batches | ms/batch 12.39 | loss 450.0074\n",
            "| epoch  25 | 14000/116677 batches | ms/batch 12.81 | loss 484.8721\n",
            "| epoch  25 | 15000/116677 batches | ms/batch 12.54 | loss 467.5134\n",
            "| epoch  25 | 16000/116677 batches | ms/batch 12.26 | loss 451.4803\n",
            "| epoch  25 | 17000/116677 batches | ms/batch 12.55 | loss 458.8683\n",
            "| epoch  25 | 18000/116677 batches | ms/batch 12.71 | loss 476.8561\n",
            "| epoch  25 | 19000/116677 batches | ms/batch 12.63 | loss 475.7151\n",
            "| epoch  25 | 20000/116677 batches | ms/batch 12.13 | loss 439.7807\n",
            "| epoch  25 | 21000/116677 batches | ms/batch 12.09 | loss 447.0791\n",
            "| epoch  25 | 22000/116677 batches | ms/batch 12.39 | loss 464.8031\n",
            "| epoch  25 | 23000/116677 batches | ms/batch 12.29 | loss 458.4294\n",
            "| epoch  25 | 24000/116677 batches | ms/batch 12.16 | loss 444.1441\n",
            "| epoch  25 | 25000/116677 batches | ms/batch 13.13 | loss 514.3090\n",
            "| epoch  25 | 26000/116677 batches | ms/batch 12.65 | loss 484.3263\n",
            "| epoch  25 | 27000/116677 batches | ms/batch 12.57 | loss 478.1501\n",
            "| epoch  25 | 28000/116677 batches | ms/batch 12.70 | loss 476.2338\n",
            "| epoch  25 | 29000/116677 batches | ms/batch 12.20 | loss 446.6172\n",
            "| epoch  25 | 30000/116677 batches | ms/batch 12.67 | loss 478.0329\n",
            "| epoch  25 | 31000/116677 batches | ms/batch 12.83 | loss 493.2407\n",
            "| epoch  25 | 32000/116677 batches | ms/batch 12.81 | loss 482.5001\n",
            "| epoch  25 | 33000/116677 batches | ms/batch 12.81 | loss 487.5574\n",
            "| epoch  25 | 34000/116677 batches | ms/batch 12.02 | loss 433.6093\n",
            "| epoch  25 | 35000/116677 batches | ms/batch 11.96 | loss 427.9425\n",
            "| epoch  25 | 36000/116677 batches | ms/batch 12.18 | loss 446.8953\n",
            "| epoch  25 | 37000/116677 batches | ms/batch 12.30 | loss 452.5334\n",
            "| epoch  25 | 38000/116677 batches | ms/batch 12.02 | loss 443.0253\n",
            "| epoch  25 | 39000/116677 batches | ms/batch 12.75 | loss 487.4163\n",
            "| epoch  25 | 40000/116677 batches | ms/batch 12.40 | loss 461.5173\n",
            "| epoch  25 | 41000/116677 batches | ms/batch 12.20 | loss 447.0782\n",
            "| epoch  25 | 42000/116677 batches | ms/batch 12.07 | loss 429.7817\n",
            "| epoch  25 | 43000/116677 batches | ms/batch 12.18 | loss 447.0185\n",
            "| epoch  25 | 44000/116677 batches | ms/batch 12.96 | loss 507.8445\n",
            "| epoch  25 | 45000/116677 batches | ms/batch 12.76 | loss 484.0153\n",
            "| epoch  25 | 46000/116677 batches | ms/batch 12.24 | loss 456.1052\n",
            "| epoch  25 | 47000/116677 batches | ms/batch 12.66 | loss 482.7801\n",
            "| epoch  25 | 48000/116677 batches | ms/batch 11.95 | loss 437.0064\n",
            "| epoch  25 | 49000/116677 batches | ms/batch 12.40 | loss 470.6980\n",
            "| epoch  25 | 50000/116677 batches | ms/batch 12.64 | loss 492.4635\n",
            "| epoch  25 | 51000/116677 batches | ms/batch 13.04 | loss 513.5708\n",
            "| epoch  25 | 52000/116677 batches | ms/batch 12.09 | loss 443.5288\n",
            "| epoch  25 | 53000/116677 batches | ms/batch 12.93 | loss 506.9104\n",
            "| epoch  25 | 54000/116677 batches | ms/batch 11.96 | loss 434.3219\n",
            "| epoch  25 | 55000/116677 batches | ms/batch 13.15 | loss 523.9022\n",
            "| epoch  25 | 56000/116677 batches | ms/batch 12.61 | loss 486.0432\n",
            "| epoch  25 | 57000/116677 batches | ms/batch 12.12 | loss 443.6799\n",
            "| epoch  25 | 58000/116677 batches | ms/batch 12.02 | loss 438.5402\n",
            "| epoch  25 | 59000/116677 batches | ms/batch 13.04 | loss 510.9320\n",
            "| epoch  25 | 60000/116677 batches | ms/batch 12.31 | loss 467.5580\n",
            "| epoch  25 | 61000/116677 batches | ms/batch 11.98 | loss 436.8729\n",
            "| epoch  25 | 62000/116677 batches | ms/batch 11.83 | loss 429.6241\n",
            "| epoch  25 | 63000/116677 batches | ms/batch 12.17 | loss 451.1596\n",
            "| epoch  25 | 64000/116677 batches | ms/batch 12.87 | loss 505.0691\n",
            "| epoch  25 | 65000/116677 batches | ms/batch 12.43 | loss 467.7540\n",
            "| epoch  25 | 66000/116677 batches | ms/batch 13.12 | loss 517.4955\n",
            "| epoch  25 | 67000/116677 batches | ms/batch 13.41 | loss 528.8564\n",
            "| epoch  25 | 68000/116677 batches | ms/batch 11.94 | loss 441.1263\n",
            "| epoch  25 | 69000/116677 batches | ms/batch 12.01 | loss 443.0687\n",
            "| epoch  25 | 70000/116677 batches | ms/batch 12.37 | loss 473.8402\n",
            "| epoch  25 | 71000/116677 batches | ms/batch 12.15 | loss 446.8479\n",
            "| epoch  25 | 72000/116677 batches | ms/batch 12.62 | loss 491.9157\n",
            "| epoch  25 | 73000/116677 batches | ms/batch 12.40 | loss 465.6284\n",
            "| epoch  25 | 74000/116677 batches | ms/batch 12.60 | loss 484.4142\n",
            "| epoch  25 | 75000/116677 batches | ms/batch 12.61 | loss 482.4445\n",
            "| epoch  25 | 76000/116677 batches | ms/batch 11.80 | loss 427.8372\n",
            "| epoch  25 | 77000/116677 batches | ms/batch 12.72 | loss 491.3128\n",
            "| epoch  25 | 78000/116677 batches | ms/batch 12.08 | loss 447.1651\n",
            "| epoch  25 | 79000/116677 batches | ms/batch 12.55 | loss 477.8367\n",
            "| epoch  25 | 80000/116677 batches | ms/batch 12.17 | loss 452.3816\n",
            "| epoch  25 | 81000/116677 batches | ms/batch 12.20 | loss 456.8555\n",
            "| epoch  25 | 82000/116677 batches | ms/batch 12.62 | loss 492.2856\n",
            "| epoch  25 | 83000/116677 batches | ms/batch 12.57 | loss 481.3736\n",
            "| epoch  25 | 84000/116677 batches | ms/batch 12.37 | loss 464.0251\n",
            "| epoch  25 | 85000/116677 batches | ms/batch 12.52 | loss 477.8401\n",
            "| epoch  25 | 86000/116677 batches | ms/batch 12.49 | loss 474.7447\n",
            "| epoch  25 | 87000/116677 batches | ms/batch 12.13 | loss 450.4142\n",
            "| epoch  25 | 88000/116677 batches | ms/batch 12.36 | loss 465.4801\n",
            "| epoch  25 | 89000/116677 batches | ms/batch 11.69 | loss 421.6337\n",
            "| epoch  25 | 90000/116677 batches | ms/batch 12.45 | loss 473.6568\n",
            "| epoch  25 | 91000/116677 batches | ms/batch 11.94 | loss 433.5022\n",
            "| epoch  25 | 92000/116677 batches | ms/batch 12.07 | loss 432.9809\n",
            "| epoch  25 | 93000/116677 batches | ms/batch 12.74 | loss 493.5530\n",
            "| epoch  25 | 94000/116677 batches | ms/batch 12.16 | loss 455.8069\n",
            "| epoch  25 | 95000/116677 batches | ms/batch 12.53 | loss 475.0023\n",
            "| epoch  25 | 96000/116677 batches | ms/batch 12.30 | loss 463.0144\n",
            "| epoch  25 | 97000/116677 batches | ms/batch 12.61 | loss 478.9749\n",
            "| epoch  25 | 98000/116677 batches | ms/batch 12.50 | loss 479.3318\n",
            "| epoch  25 | 99000/116677 batches | ms/batch 12.68 | loss 489.4404\n",
            "| epoch  25 | 100000/116677 batches | ms/batch 13.02 | loss 514.3755\n",
            "| epoch  25 | 101000/116677 batches | ms/batch 12.42 | loss 473.7529\n",
            "| epoch  25 | 102000/116677 batches | ms/batch 12.46 | loss 475.6721\n",
            "| epoch  25 | 103000/116677 batches | ms/batch 12.37 | loss 471.6562\n",
            "| epoch  25 | 104000/116677 batches | ms/batch 12.21 | loss 456.7115\n",
            "| epoch  25 | 105000/116677 batches | ms/batch 11.90 | loss 435.6509\n",
            "| epoch  25 | 106000/116677 batches | ms/batch 12.62 | loss 488.1861\n",
            "| epoch  25 | 107000/116677 batches | ms/batch 12.24 | loss 453.5879\n",
            "| epoch  25 | 108000/116677 batches | ms/batch 12.68 | loss 488.6408\n",
            "| epoch  25 | 109000/116677 batches | ms/batch 12.10 | loss 449.6484\n",
            "| epoch  25 | 110000/116677 batches | ms/batch 12.29 | loss 453.4237\n",
            "| epoch  25 | 111000/116677 batches | ms/batch 12.45 | loss 475.4006\n",
            "| epoch  25 | 112000/116677 batches | ms/batch 12.31 | loss 464.3324\n",
            "| epoch  25 | 113000/116677 batches | ms/batch 12.07 | loss 447.4405\n",
            "| epoch  25 | 114000/116677 batches | ms/batch 12.39 | loss 470.0749\n",
            "| epoch  25 | 115000/116677 batches | ms/batch 12.77 | loss 493.2068\n",
            "| epoch  25 | 116000/116677 batches | ms/batch 12.16 | loss 444.1703\n",
            "| epoch  25 | 116677/116677 batches | ms/batch 12.72 | loss 474.2668\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 1522.29s | loss = 389.3894 | NDCG@10 = 14.8708 | Rec@10 = 13.0571 | Prec@10 = 11.0 | NDCG@100 = 26.2147 | Rec@100 = 48.8758 | Prec@100 = 5.335 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 1522.29s | loss = 361.2189 | NDCG@10 = 14.8963 | Rec@10 = 13.4081 | Prec@10 = 11.045 | NDCG@100 = 26.8198 | Rec@100 = 49.0922 | Prec@100 = 5.1384 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAFgCAYAAACmKdhBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPUDqnVhSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAFNCAYAAADGhTOiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBBCCCGEdAhFNCGEEEIIIR3y/wHHpQ9iGx+ELgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "=========================================================================================\n",
            "| End of training | loss = 355.5892 | NDCG@10 = 14.9908 | Rec@10 = 13.4782 | Prec@10 = 11.025 | NDCG@100 = 26.8433 | Rec@100 = 49.2444 | Prec@100 = 5.113 (TEST)\n",
            "=========================================================================================\n",
            "average runtime per epoch = 1525.7192 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpP8ZpVu_yaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}